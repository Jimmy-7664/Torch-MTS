PEMSBAY
Trainset:	x-(36465, 12, 325, 2)	y-(36465, 12, 325, 1)
Valset:  	x-(5209, 12, 325, 2)  	y-(5209, 12, 325, 1)
Testset:	x-(10419, 12, 325, 2)	y-(10419, 12, 325, 1)

Random seed = 233
--------- Transformer ---------
{
    "num_nodes": 325,
    "in_steps": 12,
    "out_steps": 12,
    "train_size": 0.7,
    "val_size": 0.1,
    "time_of_day": true,
    "lr": 0.001,
    "milestones": [
        10,
        40
    ],
    "batch_size": 64,
    "max_epochs": 200,
    "model_args": {
        "num_nodes": 325,
        "in_steps": 12,
        "out_steps": 12,
        "input_dim": 1,
        "output_dim": 1,
        "model_dim": 64,
        "feed_forward_dim": 256,
        "num_heads": 4,
        "num_layers": 3,
        "with_spatial": false
    }
}
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Transformer                              [64, 12, 325, 1]          --
├─Linear: 1-1                            [64, 12, 325, 64]         128
├─Linear: 1-2                            [64, 12, 325, 64]         128
├─ModuleList: 1-3                        --                        --
│    └─SelfAttentionLayer: 2-1           [64, 12, 325, 64]         --
│    │    └─AttentionLayer: 3-1          [64, 325, 12, 64]         16,640
│    │    └─Dropout: 3-2                 [64, 325, 12, 64]         --
│    │    └─LayerNorm: 3-3               [64, 325, 12, 64]         128
│    │    └─Sequential: 3-4              [64, 325, 12, 64]         33,088
│    │    └─Dropout: 3-5                 [64, 325, 12, 64]         --
│    │    └─LayerNorm: 3-6               [64, 325, 12, 64]         128
│    └─SelfAttentionLayer: 2-2           [64, 12, 325, 64]         --
│    │    └─AttentionLayer: 3-7          [64, 325, 12, 64]         16,640
│    │    └─Dropout: 3-8                 [64, 325, 12, 64]         --
│    │    └─LayerNorm: 3-9               [64, 325, 12, 64]         128
│    │    └─Sequential: 3-10             [64, 325, 12, 64]         33,088
│    │    └─Dropout: 3-11                [64, 325, 12, 64]         --
│    │    └─LayerNorm: 3-12              [64, 325, 12, 64]         128
│    └─SelfAttentionLayer: 2-3           [64, 12, 325, 64]         --
│    │    └─AttentionLayer: 3-13         [64, 325, 12, 64]         16,640
│    │    └─Dropout: 3-14                [64, 325, 12, 64]         --
│    │    └─LayerNorm: 3-15              [64, 325, 12, 64]         128
│    │    └─Sequential: 3-16             [64, 325, 12, 64]         33,088
│    │    └─Dropout: 3-17                [64, 325, 12, 64]         --
│    │    └─LayerNorm: 3-18              [64, 325, 12, 64]         128
├─Linear: 1-4                            [64, 64, 325, 12]         156
├─Linear: 1-5                            [64, 12, 325, 1]          65
==========================================================================================
Total params: 150,429
Trainable params: 150,429
Non-trainable params: 0
Total mult-adds (M): 9.63
==========================================================================================
Input size (MB): 2.00
Forward/backward pass size (MB): 4602.62
Params size (MB): 0.60
Estimated Total Size (MB): 4605.22
==========================================================================================

Loss: MaskedMAELoss

2024-04-20 09:18:54.217325 Epoch 1  	Train Loss = 2.51116 Val Loss = 2.36020
2024-04-20 09:19:51.446928 Epoch 2  	Train Loss = 2.02828 Val Loss = 2.20154
2024-04-20 09:20:48.662449 Epoch 3  	Train Loss = 1.97858 Val Loss = 2.18984
2024-04-20 09:21:45.983073 Epoch 4  	Train Loss = 1.94310 Val Loss = 2.21921
2024-04-20 09:22:43.282820 Epoch 5  	Train Loss = 1.92672 Val Loss = 2.10191
2024-04-20 09:23:40.640480 Epoch 6  	Train Loss = 1.90068 Val Loss = 2.09266
2024-04-20 09:24:38.110357 Epoch 7  	Train Loss = 1.87808 Val Loss = 2.04456
2024-04-20 09:25:35.678413 Epoch 8  	Train Loss = 1.88863 Val Loss = 2.15594
2024-04-20 09:26:33.220203 Epoch 9  	Train Loss = 1.87606 Val Loss = 2.08365
2024-04-20 09:27:30.770290 Epoch 10  	Train Loss = 1.85209 Val Loss = 2.07021
2024-04-20 09:28:28.174774 Epoch 11  	Train Loss = 1.81724 Val Loss = 2.00312
2024-04-20 09:29:25.780591 Epoch 12  	Train Loss = 1.81376 Val Loss = 2.00145
2024-04-20 09:30:23.346094 Epoch 13  	Train Loss = 1.81219 Val Loss = 2.00593
2024-04-20 09:31:20.575498 Epoch 14  	Train Loss = 1.81148 Val Loss = 1.99495
2024-04-20 09:32:18.001991 Epoch 15  	Train Loss = 1.81018 Val Loss = 1.99070
2024-04-20 09:33:15.526366 Epoch 16  	Train Loss = 1.80844 Val Loss = 2.00147
2024-04-20 09:34:12.959803 Epoch 17  	Train Loss = 1.80777 Val Loss = 1.99275
2024-04-20 09:35:10.537370 Epoch 18  	Train Loss = 1.80663 Val Loss = 2.00198
2024-04-20 09:36:07.951952 Epoch 19  	Train Loss = 1.80543 Val Loss = 1.99222
2024-04-20 09:37:05.202340 Epoch 20  	Train Loss = 1.80453 Val Loss = 1.98362
2024-04-20 09:38:02.609101 Epoch 21  	Train Loss = 1.80340 Val Loss = 1.98394
2024-04-20 09:39:00.126815 Epoch 22  	Train Loss = 1.80210 Val Loss = 1.99082
2024-04-20 09:39:57.646081 Epoch 23  	Train Loss = 1.80110 Val Loss = 1.99490
2024-04-20 09:40:55.141757 Epoch 24  	Train Loss = 1.80084 Val Loss = 1.98779
2024-04-20 09:41:52.618768 Epoch 25  	Train Loss = 1.80022 Val Loss = 1.98357
2024-04-20 09:42:50.053427 Epoch 26  	Train Loss = 1.79870 Val Loss = 1.97912
2024-04-20 09:43:47.602397 Epoch 27  	Train Loss = 1.79801 Val Loss = 1.98784
2024-04-20 09:44:45.154179 Epoch 28  	Train Loss = 1.79723 Val Loss = 1.98228
2024-04-20 09:45:42.637009 Epoch 29  	Train Loss = 1.79684 Val Loss = 1.99542
2024-04-20 09:46:40.105936 Epoch 30  	Train Loss = 1.79658 Val Loss = 1.98324
2024-04-20 09:47:37.355362 Epoch 31  	Train Loss = 1.79671 Val Loss = 1.98071
2024-04-20 09:48:34.698289 Epoch 32  	Train Loss = 1.79513 Val Loss = 1.98356
2024-04-20 09:49:32.119917 Epoch 33  	Train Loss = 1.79423 Val Loss = 1.98211
2024-04-20 09:50:29.511837 Epoch 34  	Train Loss = 1.79453 Val Loss = 1.97702
2024-04-20 09:51:26.861569 Epoch 35  	Train Loss = 1.79348 Val Loss = 1.97376
2024-04-20 09:52:24.137159 Epoch 36  	Train Loss = 1.79337 Val Loss = 1.97118
2024-04-20 09:53:21.435640 Epoch 37  	Train Loss = 1.79286 Val Loss = 1.97777
2024-04-20 09:54:18.751146 Epoch 38  	Train Loss = 1.79237 Val Loss = 1.97816
2024-04-20 09:55:16.169623 Epoch 39  	Train Loss = 1.79250 Val Loss = 1.98876
2024-04-20 09:56:13.555803 Epoch 40  	Train Loss = 1.79145 Val Loss = 1.97747
2024-04-20 09:57:10.891687 Epoch 41  	Train Loss = 1.78521 Val Loss = 1.96923
2024-04-20 09:58:08.368798 Epoch 42  	Train Loss = 1.78470 Val Loss = 1.96910
2024-04-20 09:59:05.806816 Epoch 43  	Train Loss = 1.78470 Val Loss = 1.96871
2024-04-20 10:00:03.039353 Epoch 44  	Train Loss = 1.78461 Val Loss = 1.96787
2024-04-20 10:01:00.439348 Epoch 45  	Train Loss = 1.78456 Val Loss = 1.96890
2024-04-20 10:01:57.894437 Epoch 46  	Train Loss = 1.78442 Val Loss = 1.96868
2024-04-20 10:02:55.249911 Epoch 47  	Train Loss = 1.78430 Val Loss = 1.97055
2024-04-20 10:03:52.617936 Epoch 48  	Train Loss = 1.78419 Val Loss = 1.97046
2024-04-20 10:04:49.970442 Epoch 49  	Train Loss = 1.78435 Val Loss = 1.96844
2024-04-20 10:05:47.498228 Epoch 50  	Train Loss = 1.78409 Val Loss = 1.96798
2024-04-20 10:06:44.943629 Epoch 51  	Train Loss = 1.78402 Val Loss = 1.97102
2024-04-20 10:07:42.394362 Epoch 52  	Train Loss = 1.78370 Val Loss = 1.97113
2024-04-20 10:08:39.791288 Epoch 53  	Train Loss = 1.78384 Val Loss = 1.96813
2024-04-20 10:09:37.036330 Epoch 54  	Train Loss = 1.78387 Val Loss = 1.96967
Early stopping at epoch: 54
Best at epoch 44:
Train Loss = 1.78461
Train MAE = 1.78441, RMSE = 4.12069, MAPE = 4.01391
Val Loss = 1.96787
Val MAE = 1.95597, RMSE = 4.60948, MAPE = 4.64148
Model checkpoint saved to: ../saved_models/Transformer/Transformer-PEMSBAY-2024-04-20-09-17-52.pt
--------- Test ---------
All Steps (1-12) MAE = 1.81642, RMSE = 4.25296, MAPE = 4.19131
Step 1 MAE = 0.89619, RMSE = 1.67404, MAPE = 1.73446
Step 2 MAE = 1.19005, RMSE = 2.42485, MAPE = 2.41458
Step 3 MAE = 1.41066, RMSE = 3.04137, MAPE = 2.96935
Step 4 MAE = 1.58584, RMSE = 3.52868, MAPE = 3.44089
Step 5 MAE = 1.73049, RMSE = 3.92230, MAPE = 3.85533
Step 6 MAE = 1.85638, RMSE = 4.23930, MAPE = 4.24113
Step 7 MAE = 1.96528, RMSE = 4.51961, MAPE = 4.56447
Step 8 MAE = 2.06492, RMSE = 4.75784, MAPE = 4.89226
Step 9 MAE = 2.15373, RMSE = 4.96757, MAPE = 5.17063
Step 10 MAE = 2.23606, RMSE = 5.15885, MAPE = 5.43528
Step 11 MAE = 2.31422, RMSE = 5.33941, MAPE = 5.67469
Step 12 MAE = 2.39313, RMSE = 5.51801, MAPE = 5.90262
Inference time: 5.84 s
