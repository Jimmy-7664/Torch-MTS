METRLA
Trainset:	x-(23974, 12, 207, 3)	y-(23974, 12, 207, 1)
Valset:  	x-(3425, 12, 207, 3)  	y-(3425, 12, 207, 1)
Testset:	x-(6850, 12, 207, 3)	y-(6850, 12, 207, 1)

--------- STMetaLSTM ---------
{
    "num_nodes": 207,
    "in_steps": 12,
    "out_steps": 12,
    "time_of_day": true,
    "day_of_week": true,
    "lr": 0.001,
    "weight_decay": 0,
    "milestones": [
        10,
        40
    ],
    "clip_grad": false,
    "batch_size": 64,
    "max_epochs": 200,
    "use_cl": false,
    "pass_device": true,
    "model_args": {
        "num_nodes": 207,
        "node_emb_file": "../data/METRLA/spatial_embeddings.npz",
        "in_steps": 12,
        "out_steps": 12,
        "input_dim": 1,
        "output_dim": 1,
        "lstm_hidden_dim": 64,
        "tod_embedding_dim": 24,
        "dow_embedding_dim": 7,
        "node_embedding_dim": 64,
        "learner_hidden_dim": 64,
        "z_dim": 32,
        "num_layers": 1,
        "seq2seq": false,
        "device": "cuda:0"
    }
}
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
STMetaLSTM                               [64, 12, 207, 1]          13,248
├─Sequential: 1-1                        [64, 207, 32]             --
│    └─Linear: 2-1                       [64, 207, 32]             416
│    └─Tanh: 2-2                         [64, 207, 32]             --
│    └─Linear: 2-3                       [64, 207, 32]             1,056
│    └─Tanh: 2-4                         [64, 207, 32]             --
│    └─Linear: 2-5                       [64, 207, 32]             1,056
├─Sequential: 1-2                        [64, 207, 32]             --
│    └─Linear: 2-6                       [64, 207, 32]             416
│    └─Tanh: 2-7                         [64, 207, 32]             --
│    └─Linear: 2-8                       [64, 207, 32]             1,056
│    └─Tanh: 2-9                         [64, 207, 32]             --
│    └─Linear: 2-10                      [64, 207, 32]             1,056
├─ModuleList: 1-3                        --                        --
│    └─STMetaLSTMEncoder: 2-11           [64, 12, 207, 64]         --
│    │    └─Sequential: 3-1              [64, 207, 256]            24,832
│    │    └─Sequential: 3-2              [64, 207, 16384]          1,073,152
│    │    └─Sequential: 3-3              [64, 207, 256]            24,832
│    │    └─STMetaLSTMCell: 3-4          [64, 207, 64]             --
│    │    └─STMetaLSTMCell: 3-5          [64, 207, 64]             --
│    │    └─STMetaLSTMCell: 3-6          [64, 207, 64]             --
│    │    └─STMetaLSTMCell: 3-7          [64, 207, 64]             --
│    │    └─STMetaLSTMCell: 3-8          [64, 207, 64]             --
│    │    └─STMetaLSTMCell: 3-9          [64, 207, 64]             --
│    │    └─STMetaLSTMCell: 3-10         [64, 207, 64]             --
│    │    └─STMetaLSTMCell: 3-11         [64, 207, 64]             --
│    │    └─STMetaLSTMCell: 3-12         [64, 207, 64]             --
│    │    └─STMetaLSTMCell: 3-13         [64, 207, 64]             --
│    │    └─STMetaLSTMCell: 3-14         [64, 207, 64]             --
│    │    └─STMetaLSTMCell: 3-15         [64, 207, 64]             --
├─Linear: 1-4                            [64, 207, 12]             780
==========================================================================================
Total params: 1,141,900
Trainable params: 1,141,900
Non-trainable params: 0
Total mult-adds (M): 72.23
==========================================================================================
Input size (MB): 1.91
Forward/backward pass size (MB): 1832.68
Params size (MB): 4.51
Estimated Total Size (MB): 1839.10
==========================================================================================

Loss: MaskedMAELoss

2023-04-16 10:42:19.539495 Epoch 1  	Train Loss = 3.91644 Val Loss = 3.27528
2023-04-16 10:43:14.368378 Epoch 2  	Train Loss = 3.35936 Val Loss = 3.16887
2023-04-16 10:44:09.188302 Epoch 3  	Train Loss = 3.23470 Val Loss = 3.09482
2023-04-16 10:45:04.237205 Epoch 4  	Train Loss = 3.14890 Val Loss = 3.05642
2023-04-16 10:45:59.248992 Epoch 5  	Train Loss = 3.09610 Val Loss = 3.04086
2023-04-16 10:46:54.304780 Epoch 6  	Train Loss = 3.06061 Val Loss = 3.00940
2023-04-16 10:47:49.261301 Epoch 7  	Train Loss = 3.03341 Val Loss = 2.99115
2023-04-16 10:48:44.222429 Epoch 8  	Train Loss = 3.00893 Val Loss = 3.00377
2023-04-16 10:49:39.202703 Epoch 9  	Train Loss = 2.98936 Val Loss = 2.97887
2023-04-16 10:50:34.137270 Epoch 10  	Train Loss = 2.97627 Val Loss = 2.99017
2023-04-16 10:51:29.129795 Epoch 11  	Train Loss = 2.92472 Val Loss = 2.97377
2023-04-16 10:52:24.108793 Epoch 12  	Train Loss = 2.91347 Val Loss = 2.96421
2023-04-16 10:53:19.073818 Epoch 13  	Train Loss = 2.90870 Val Loss = 2.96773
2023-04-16 10:54:14.022346 Epoch 14  	Train Loss = 2.90328 Val Loss = 2.98129
2023-04-16 10:55:08.934040 Epoch 15  	Train Loss = 2.89967 Val Loss = 2.97498
2023-04-16 10:56:03.883208 Epoch 16  	Train Loss = 2.89569 Val Loss = 2.96301
2023-04-16 10:56:58.855358 Epoch 17  	Train Loss = 2.89157 Val Loss = 2.97049
2023-04-16 10:57:53.832071 Epoch 18  	Train Loss = 2.88797 Val Loss = 2.97164
2023-04-16 10:58:48.827864 Epoch 19  	Train Loss = 2.88427 Val Loss = 2.96339
2023-04-16 10:59:43.764050 Epoch 20  	Train Loss = 2.88166 Val Loss = 2.97322
2023-04-16 11:00:38.840969 Epoch 21  	Train Loss = 2.87760 Val Loss = 2.96902
2023-04-16 11:01:33.781436 Epoch 22  	Train Loss = 2.87572 Val Loss = 2.96942
2023-04-16 11:02:28.685844 Epoch 23  	Train Loss = 2.87173 Val Loss = 2.96932
2023-04-16 11:03:23.598634 Epoch 24  	Train Loss = 2.86817 Val Loss = 2.97250
2023-04-16 11:04:18.452421 Epoch 25  	Train Loss = 2.86481 Val Loss = 2.97671
2023-04-16 11:05:13.345854 Epoch 26  	Train Loss = 2.86273 Val Loss = 2.97655
Early stopping at epoch: 26
Best at epoch 16:
Train Loss = 2.89569
Train RMSE = 5.85705, MAE = 2.85733, MAPE = 7.70985
Val Loss = 2.96301
Val RMSE = 6.42259, MAE = 3.02126, MAPE = 8.70339
--------- Test ---------
All Steps RMSE = 6.71735, MAE = 3.21834, MAPE = 9.32430
Step 1 RMSE = 4.18119, MAE = 2.34898, MAPE = 5.91609
Step 2 RMSE = 5.07559, MAE = 2.64718, MAPE = 6.99286
Step 3 RMSE = 5.67676, MAE = 2.85968, MAPE = 7.82516
Step 4 RMSE = 6.16024, MAE = 3.03213, MAPE = 8.54478
Step 5 RMSE = 6.55536, MAE = 3.17089, MAPE = 9.12143
Step 6 RMSE = 6.87708, MAE = 3.28623, MAPE = 9.60087
Step 7 RMSE = 7.11779, MAE = 3.38333, MAPE = 10.00646
Step 8 RMSE = 7.30009, MAE = 3.46289, MAPE = 10.30904
Step 9 RMSE = 7.46509, MAE = 3.53085, MAPE = 10.58184
Step 10 RMSE = 7.59397, MAE = 3.58529, MAPE = 10.80183
Step 11 RMSE = 7.70600, MAE = 3.63338, MAPE = 10.99836
Step 12 RMSE = 7.81396, MAE = 3.67933, MAPE = 11.19317
Inference time: 3.70 s
