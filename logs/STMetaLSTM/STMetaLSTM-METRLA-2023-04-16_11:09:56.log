METRLA
Trainset:	x-(23974, 12, 207, 3)	y-(23974, 12, 207, 1)
Valset:  	x-(3425, 12, 207, 3)  	y-(3425, 12, 207, 1)
Testset:	x-(6850, 12, 207, 3)	y-(6850, 12, 207, 1)

--------- STMetaLSTM ---------
{
    "num_nodes": 207,
    "in_steps": 12,
    "out_steps": 12,
    "time_of_day": true,
    "day_of_week": true,
    "lr": 0.001,
    "weight_decay": 0,
    "milestones": [
        10,
        40
    ],
    "clip_grad": false,
    "batch_size": 64,
    "max_epochs": 200,
    "use_cl": false,
    "pass_device": true,
    "model_args": {
        "num_nodes": 207,
        "node_emb_file": "../data/METRLA/spatial_embeddings.npz",
        "in_steps": 12,
        "out_steps": 12,
        "input_dim": 1,
        "output_dim": 1,
        "lstm_hidden_dim": 32,
        "tod_embedding_dim": 24,
        "dow_embedding_dim": 7,
        "node_embedding_dim": 64,
        "learner_hidden_dim": 64,
        "z_dim": 32,
        "num_layers": 1,
        "seq2seq": false,
        "device": "cuda:0"
    }
}
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
STMetaLSTM                               [64, 12, 207, 1]          13,248
├─Sequential: 1-1                        [64, 207, 32]             --
│    └─Linear: 2-1                       [64, 207, 32]             416
│    └─Tanh: 2-2                         [64, 207, 32]             --
│    └─Linear: 2-3                       [64, 207, 32]             1,056
│    └─Tanh: 2-4                         [64, 207, 32]             --
│    └─Linear: 2-5                       [64, 207, 32]             1,056
├─Sequential: 1-2                        [64, 207, 32]             --
│    └─Linear: 2-6                       [64, 207, 32]             416
│    └─Tanh: 2-7                         [64, 207, 32]             --
│    └─Linear: 2-8                       [64, 207, 32]             1,056
│    └─Tanh: 2-9                         [64, 207, 32]             --
│    └─Linear: 2-10                      [64, 207, 32]             1,056
├─ModuleList: 1-3                        --                        --
│    └─STMetaLSTMEncoder: 2-11           [64, 12, 207, 32]         --
│    │    └─Sequential: 3-1              [64, 207, 128]            16,512
│    │    └─Sequential: 3-2              [64, 207, 4096]           274,432
│    │    └─Sequential: 3-3              [64, 207, 128]            16,512
│    │    └─STMetaLSTMCell: 3-4          [64, 207, 32]             --
│    │    └─STMetaLSTMCell: 3-5          [64, 207, 32]             --
│    │    └─STMetaLSTMCell: 3-6          [64, 207, 32]             --
│    │    └─STMetaLSTMCell: 3-7          [64, 207, 32]             --
│    │    └─STMetaLSTMCell: 3-8          [64, 207, 32]             --
│    │    └─STMetaLSTMCell: 3-9          [64, 207, 32]             --
│    │    └─STMetaLSTMCell: 3-10         [64, 207, 32]             --
│    │    └─STMetaLSTMCell: 3-11         [64, 207, 32]             --
│    │    └─STMetaLSTMCell: 3-12         [64, 207, 32]             --
│    │    └─STMetaLSTMCell: 3-13         [64, 207, 32]             --
│    │    └─STMetaLSTMCell: 3-14         [64, 207, 32]             --
│    │    └─STMetaLSTMCell: 3-15         [64, 207, 32]             --
├─Linear: 1-4                            [64, 207, 12]             396
==========================================================================================
Total params: 326,156
Trainable params: 326,156
Non-trainable params: 0
Total mult-adds (M): 20.03
==========================================================================================
Input size (MB): 1.91
Forward/backward pass size (MB): 503.21
Params size (MB): 1.25
Estimated Total Size (MB): 506.37
==========================================================================================

Loss: MaskedMAELoss

2023-04-16 11:10:28.965894 Epoch 1  	Train Loss = 4.02758 Val Loss = 3.32146
2023-04-16 11:10:52.553998 Epoch 2  	Train Loss = 3.40367 Val Loss = 3.19353
2023-04-16 11:11:21.580489 Epoch 3  	Train Loss = 3.29685 Val Loss = 3.14026
2023-04-16 11:11:51.573097 Epoch 4  	Train Loss = 3.21823 Val Loss = 3.11262
2023-04-16 11:12:20.510850 Epoch 5  	Train Loss = 3.15970 Val Loss = 3.05723
2023-04-16 11:12:49.500624 Epoch 6  	Train Loss = 3.12309 Val Loss = 3.03408
2023-04-16 11:13:18.545976 Epoch 7  	Train Loss = 3.09279 Val Loss = 3.01899
2023-04-16 11:13:47.625399 Epoch 8  	Train Loss = 3.07297 Val Loss = 3.04325
2023-04-16 11:14:16.728365 Epoch 9  	Train Loss = 3.05226 Val Loss = 3.00449
2023-04-16 11:14:45.746877 Epoch 10  	Train Loss = 3.03561 Val Loss = 3.02851
2023-04-16 11:15:15.750770 Epoch 11  	Train Loss = 2.99698 Val Loss = 2.97584
2023-04-16 11:15:45.142941 Epoch 12  	Train Loss = 2.98833 Val Loss = 2.97872
2023-04-16 11:16:14.176038 Epoch 13  	Train Loss = 2.98473 Val Loss = 2.96834
2023-04-16 11:16:43.302680 Epoch 14  	Train Loss = 2.98106 Val Loss = 2.96748
2023-04-16 11:17:12.324229 Epoch 15  	Train Loss = 2.97910 Val Loss = 2.97537
2023-04-16 11:17:41.391863 Epoch 16  	Train Loss = 2.97658 Val Loss = 2.97906
2023-04-16 11:18:10.457735 Epoch 17  	Train Loss = 2.97357 Val Loss = 2.96784
2023-04-16 11:18:39.971170 Epoch 18  	Train Loss = 2.97191 Val Loss = 2.96803
2023-04-16 11:19:09.910246 Epoch 19  	Train Loss = 2.96818 Val Loss = 2.96939
2023-04-16 11:19:39.117291 Epoch 20  	Train Loss = 2.96704 Val Loss = 2.97102
2023-04-16 11:20:08.148672 Epoch 21  	Train Loss = 2.96504 Val Loss = 2.97134
2023-04-16 11:20:37.230157 Epoch 22  	Train Loss = 2.96226 Val Loss = 2.97014
2023-04-16 11:21:06.396723 Epoch 23  	Train Loss = 2.96011 Val Loss = 2.96975
2023-04-16 11:21:34.888823 Epoch 24  	Train Loss = 2.95883 Val Loss = 2.96593
2023-04-16 11:22:04.529737 Epoch 25  	Train Loss = 2.95655 Val Loss = 2.96801
2023-04-16 11:22:33.762035 Epoch 26  	Train Loss = 2.95485 Val Loss = 2.96279
2023-04-16 11:23:02.559855 Epoch 27  	Train Loss = 2.95372 Val Loss = 2.96535
2023-04-16 11:23:31.566388 Epoch 28  	Train Loss = 2.95089 Val Loss = 2.96863
2023-04-16 11:24:00.587547 Epoch 29  	Train Loss = 2.94915 Val Loss = 2.96600
2023-04-16 11:24:29.471831 Epoch 30  	Train Loss = 2.94834 Val Loss = 2.96739
2023-04-16 11:24:59.148952 Epoch 31  	Train Loss = 2.94542 Val Loss = 2.96628
2023-04-16 11:25:29.038862 Epoch 32  	Train Loss = 2.94333 Val Loss = 2.97581
2023-04-16 11:25:58.101333 Epoch 33  	Train Loss = 2.94316 Val Loss = 2.96440
2023-04-16 11:26:27.195662 Epoch 34  	Train Loss = 2.94043 Val Loss = 2.96958
2023-04-16 11:26:56.157442 Epoch 35  	Train Loss = 2.93933 Val Loss = 2.96396
2023-04-16 11:27:25.026071 Epoch 36  	Train Loss = 2.93727 Val Loss = 2.96376
Early stopping at epoch: 36
Best at epoch 26:
Train Loss = 2.95485
Train RMSE = 6.01466, MAE = 2.93418, MAPE = 8.00078
Val Loss = 2.96279
Val RMSE = 6.35565, MAE = 3.00968, MAPE = 8.70502
--------- Test ---------
All Steps RMSE = 6.65055, MAE = 3.21277, MAPE = 9.33530
Step 1 RMSE = 4.14965, MAE = 2.34615, MAPE = 5.88479
Step 2 RMSE = 5.03493, MAE = 2.64216, MAPE = 6.93883
Step 3 RMSE = 5.61560, MAE = 2.84713, MAPE = 7.74769
Step 4 RMSE = 6.06653, MAE = 3.01378, MAPE = 8.43788
Step 5 RMSE = 6.44520, MAE = 3.15318, MAPE = 9.04458
Step 6 RMSE = 6.76998, MAE = 3.26987, MAPE = 9.55303
Step 7 RMSE = 7.02505, MAE = 3.36812, MAPE = 9.96616
Step 8 RMSE = 7.21473, MAE = 3.45308, MAPE = 10.34009
Step 9 RMSE = 7.37677, MAE = 3.52882, MAPE = 10.66825
Step 10 RMSE = 7.53890, MAE = 3.59059, MAPE = 10.93453
Step 11 RMSE = 7.67854, MAE = 3.64506, MAPE = 11.15654
Step 12 RMSE = 7.80156, MAE = 3.69539, MAPE = 11.35133
Inference time: 2.29 s
