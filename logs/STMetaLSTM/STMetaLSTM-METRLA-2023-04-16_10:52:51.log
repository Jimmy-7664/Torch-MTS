METRLA
Trainset:	x-(23974, 12, 207, 3)	y-(23974, 12, 207, 1)
Valset:  	x-(3425, 12, 207, 3)  	y-(3425, 12, 207, 1)
Testset:	x-(6850, 12, 207, 3)	y-(6850, 12, 207, 1)

--------- STMetaLSTM ---------
{
    "num_nodes": 207,
    "in_steps": 12,
    "out_steps": 12,
    "time_of_day": true,
    "day_of_week": true,
    "lr": 0.001,
    "weight_decay": 0,
    "milestones": [
        10,
        40
    ],
    "clip_grad": false,
    "batch_size": 64,
    "max_epochs": 200,
    "use_cl": false,
    "pass_device": true,
    "model_args": {
        "num_nodes": 207,
        "node_emb_file": "../data/METRLA/spatial_embeddings.npz",
        "in_steps": 12,
        "out_steps": 12,
        "input_dim": 1,
        "output_dim": 1,
        "lstm_hidden_dim": 64,
        "tod_embedding_dim": 24,
        "dow_embedding_dim": 7,
        "node_embedding_dim": 64,
        "learner_hidden_dim": 128,
        "z_dim": 32,
        "num_layers": 1,
        "seq2seq": false,
        "device": "cuda:0"
    }
}
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
STMetaLSTM                               [64, 12, 207, 1]          13,248
├─Sequential: 1-1                        [64, 207, 32]             --
│    └─Linear: 2-1                       [64, 207, 32]             416
│    └─Tanh: 2-2                         [64, 207, 32]             --
│    └─Linear: 2-3                       [64, 207, 32]             1,056
│    └─Tanh: 2-4                         [64, 207, 32]             --
│    └─Linear: 2-5                       [64, 207, 32]             1,056
├─Sequential: 1-2                        [64, 207, 32]             --
│    └─Linear: 2-6                       [64, 207, 32]             416
│    └─Tanh: 2-7                         [64, 207, 32]             --
│    └─Linear: 2-8                       [64, 207, 32]             1,056
│    └─Tanh: 2-9                         [64, 207, 32]             --
│    └─Linear: 2-10                      [64, 207, 32]             1,056
├─ModuleList: 1-3                        --                        --
│    └─STMetaLSTMEncoder: 2-11           [64, 12, 207, 64]         --
│    │    └─Sequential: 3-1              [64, 207, 256]            49,408
│    │    └─Sequential: 3-2              [64, 207, 16384]          2,129,920
│    │    └─Sequential: 3-3              [64, 207, 256]            49,408
│    │    └─STMetaLSTMCell: 3-4          [64, 207, 64]             --
│    │    └─STMetaLSTMCell: 3-5          [64, 207, 64]             --
│    │    └─STMetaLSTMCell: 3-6          [64, 207, 64]             --
│    │    └─STMetaLSTMCell: 3-7          [64, 207, 64]             --
│    │    └─STMetaLSTMCell: 3-8          [64, 207, 64]             --
│    │    └─STMetaLSTMCell: 3-9          [64, 207, 64]             --
│    │    └─STMetaLSTMCell: 3-10         [64, 207, 64]             --
│    │    └─STMetaLSTMCell: 3-11         [64, 207, 64]             --
│    │    └─STMetaLSTMCell: 3-12         [64, 207, 64]             --
│    │    └─STMetaLSTMCell: 3-13         [64, 207, 64]             --
│    │    └─STMetaLSTMCell: 3-14         [64, 207, 64]             --
│    │    └─STMetaLSTMCell: 3-15         [64, 207, 64]             --
├─Linear: 1-4                            [64, 207, 12]             780
==========================================================================================
Total params: 2,247,820
Trainable params: 2,247,820
Non-trainable params: 0
Total mult-adds (M): 143.01
==========================================================================================
Input size (MB): 1.91
Forward/backward pass size (MB): 1853.02
Params size (MB): 8.94
Estimated Total Size (MB): 1863.87
==========================================================================================

Loss: MaskedMAELoss

2023-04-16 10:53:50.386403 Epoch 1  	Train Loss = 3.82663 Val Loss = 3.26683
2023-04-16 10:54:46.855778 Epoch 2  	Train Loss = 3.34740 Val Loss = 3.15880
2023-04-16 10:55:43.552003 Epoch 3  	Train Loss = 3.21368 Val Loss = 3.08912
2023-04-16 10:56:40.383420 Epoch 4  	Train Loss = 3.12735 Val Loss = 3.05799
2023-04-16 10:57:37.145656 Epoch 5  	Train Loss = 3.07282 Val Loss = 3.01456
2023-04-16 10:58:33.971909 Epoch 6  	Train Loss = 3.03676 Val Loss = 3.01666
2023-04-16 10:59:30.793665 Epoch 7  	Train Loss = 3.00892 Val Loss = 3.00969
2023-04-16 11:00:27.688216 Epoch 8  	Train Loss = 2.98623 Val Loss = 2.98120
2023-04-16 11:01:24.497715 Epoch 9  	Train Loss = 2.96429 Val Loss = 3.00996
2023-04-16 11:02:21.165381 Epoch 10  	Train Loss = 2.94806 Val Loss = 2.99670
2023-04-16 11:03:17.808680 Epoch 11  	Train Loss = 2.89109 Val Loss = 2.97527
2023-04-16 11:04:14.506287 Epoch 12  	Train Loss = 2.87678 Val Loss = 2.98496
2023-04-16 11:05:11.201012 Epoch 13  	Train Loss = 2.86965 Val Loss = 2.97517
2023-04-16 11:06:07.917625 Epoch 14  	Train Loss = 2.86460 Val Loss = 2.97492
2023-04-16 11:07:04.550623 Epoch 15  	Train Loss = 2.85857 Val Loss = 2.97941
2023-04-16 11:08:01.185176 Epoch 16  	Train Loss = 2.85361 Val Loss = 2.97868
2023-04-16 11:08:57.783938 Epoch 17  	Train Loss = 2.84840 Val Loss = 2.97328
2023-04-16 11:09:54.417465 Epoch 18  	Train Loss = 2.84376 Val Loss = 2.98888
2023-04-16 11:10:51.000092 Epoch 19  	Train Loss = 2.83965 Val Loss = 2.98291
2023-04-16 11:11:47.668561 Epoch 20  	Train Loss = 2.83465 Val Loss = 2.98820
2023-04-16 11:12:44.433222 Epoch 21  	Train Loss = 2.82978 Val Loss = 2.99029
2023-04-16 11:13:41.193107 Epoch 22  	Train Loss = 2.82702 Val Loss = 2.99292
2023-04-16 11:14:37.905797 Epoch 23  	Train Loss = 2.82151 Val Loss = 2.98635
2023-04-16 11:15:34.613674 Epoch 24  	Train Loss = 2.81824 Val Loss = 2.99370
2023-04-16 11:16:31.250452 Epoch 25  	Train Loss = 2.81390 Val Loss = 2.98837
2023-04-16 11:17:27.856230 Epoch 26  	Train Loss = 2.81052 Val Loss = 2.99332
2023-04-16 11:18:24.490800 Epoch 27  	Train Loss = 2.80640 Val Loss = 2.99300
Early stopping at epoch: 27
Best at epoch 17:
Train Loss = 2.84840
Train RMSE = 5.72181, MAE = 2.79897, MAPE = 7.55213
Val Loss = 2.97328
Val RMSE = 6.46970, MAE = 3.03946, MAPE = 8.78867
--------- Test ---------
All Steps RMSE = 6.76168, MAE = 3.23301, MAPE = 9.41544
Step 1 RMSE = 4.19109, MAE = 2.35372, MAPE = 5.95619
Step 2 RMSE = 5.08196, MAE = 2.65542, MAPE = 7.05765
Step 3 RMSE = 5.69563, MAE = 2.87243, MAPE = 7.91399
Step 4 RMSE = 6.18593, MAE = 3.04868, MAPE = 8.64676
Step 5 RMSE = 6.59509, MAE = 3.19218, MAPE = 9.25191
Step 6 RMSE = 6.93410, MAE = 3.31013, MAPE = 9.73826
Step 7 RMSE = 7.18608, MAE = 3.40533, MAPE = 10.12385
Step 8 RMSE = 7.36938, MAE = 3.48272, MAPE = 10.43789
Step 9 RMSE = 7.51992, MAE = 3.54694, MAPE = 10.69503
Step 10 RMSE = 7.64953, MAE = 3.60019, MAPE = 10.90239
Step 11 RMSE = 7.75946, MAE = 3.64313, MAPE = 11.04988
Step 12 RMSE = 7.85818, MAE = 3.68529, MAPE = 11.21167
Inference time: 3.81 s
