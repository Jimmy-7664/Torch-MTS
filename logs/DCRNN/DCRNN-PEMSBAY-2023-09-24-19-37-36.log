PEMSBAY
Trainset:	x-(36465, 12, 325, 2)	y-(36465, 12, 325, 1)
Valset:  	x-(5209, 12, 325, 2)  	y-(5209, 12, 325, 1)
Testset:	x-(10419, 12, 325, 2)	y-(10419, 12, 325, 1)

--------- DCRNN ---------
{
    "num_nodes": 325,
    "in_steps": 12,
    "out_steps": 12,
    "time_of_day": true,
    "runner": "dcrnn",
    "lr": 0.01,
    "eps": 0.001,
    "milestones": [
        20,
        30,
        40,
        50
    ],
    "clip_grad": 5,
    "batch_size": 64,
    "max_epochs": 200,
    "early_stop": 20,
    "pass_device": true,
    "model_args": {
        "num_nodes": 325,
        "adj_path": "../data/PEMSBAY/adj_mx_bay.pkl",
        "input_dim": 2,
        "output_dim": 1,
        "seq_len": 12,
        "horizon": 12,
        "rnn_units": 64,
        "num_rnn_layers": 2,
        "max_diffusion_step": 2,
        "filter_type": "dual_random_walk",
        "tf_decay_steps": 2000,
        "use_teacher_forcing": true,
        "device": "cuda:0"
    }
}
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
DCRNN                                    [64, 12, 325, 1]          --
├─EncoderModel: 1-1                      [64, 20800]               --
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-1               [64, 20800]               --
│    │    └─DCGRUCell: 3-2               [64, 20800]               --
├─EncoderModel: 1-2                      [64, 20800]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-3               [64, 20800]               (recursive)
│    │    └─DCGRUCell: 3-4               [64, 20800]               (recursive)
├─EncoderModel: 1-3                      [64, 20800]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-5               [64, 20800]               (recursive)
│    │    └─DCGRUCell: 3-6               [64, 20800]               (recursive)
├─EncoderModel: 1-4                      [64, 20800]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-7               [64, 20800]               (recursive)
│    │    └─DCGRUCell: 3-8               [64, 20800]               (recursive)
├─EncoderModel: 1-5                      [64, 20800]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-9               [64, 20800]               (recursive)
│    │    └─DCGRUCell: 3-10              [64, 20800]               (recursive)
├─EncoderModel: 1-6                      [64, 20800]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-11              [64, 20800]               (recursive)
│    │    └─DCGRUCell: 3-12              [64, 20800]               (recursive)
├─EncoderModel: 1-7                      [64, 20800]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-13              [64, 20800]               (recursive)
│    │    └─DCGRUCell: 3-14              [64, 20800]               (recursive)
├─EncoderModel: 1-8                      [64, 20800]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-15              [64, 20800]               (recursive)
│    │    └─DCGRUCell: 3-16              [64, 20800]               (recursive)
├─EncoderModel: 1-9                      [64, 20800]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-17              [64, 20800]               (recursive)
│    │    └─DCGRUCell: 3-18              [64, 20800]               (recursive)
├─EncoderModel: 1-10                     [64, 20800]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-19              [64, 20800]               (recursive)
│    │    └─DCGRUCell: 3-20              [64, 20800]               (recursive)
├─EncoderModel: 1-11                     [64, 20800]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-21              [64, 20800]               (recursive)
│    │    └─DCGRUCell: 3-22              [64, 20800]               (recursive)
├─EncoderModel: 1-12                     [64, 20800]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-23              [64, 20800]               (recursive)
│    │    └─DCGRUCell: 3-24              [64, 20800]               (recursive)
├─DecoderModel: 1-13                     [64, 325]                 --
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-25              [64, 20800]               --
│    │    └─DCGRUCell: 3-26              [64, 20800]               --
│    └─Linear: 2-14                      [20800, 1]                65
├─DecoderModel: 1-14                     [64, 325]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-27              [64, 20800]               (recursive)
│    │    └─DCGRUCell: 3-28              [64, 20800]               (recursive)
│    └─Linear: 2-16                      [20800, 1]                (recursive)
├─DecoderModel: 1-15                     [64, 325]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-29              [64, 20800]               (recursive)
│    │    └─DCGRUCell: 3-30              [64, 20800]               (recursive)
│    └─Linear: 2-18                      [20800, 1]                (recursive)
├─DecoderModel: 1-16                     [64, 325]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-31              [64, 20800]               (recursive)
│    │    └─DCGRUCell: 3-32              [64, 20800]               (recursive)
│    └─Linear: 2-20                      [20800, 1]                (recursive)
├─DecoderModel: 1-17                     [64, 325]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-33              [64, 20800]               (recursive)
│    │    └─DCGRUCell: 3-34              [64, 20800]               (recursive)
│    └─Linear: 2-22                      [20800, 1]                (recursive)
├─DecoderModel: 1-18                     [64, 325]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-35              [64, 20800]               (recursive)
│    │    └─DCGRUCell: 3-36              [64, 20800]               (recursive)
│    └─Linear: 2-24                      [20800, 1]                (recursive)
├─DecoderModel: 1-19                     [64, 325]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-37              [64, 20800]               (recursive)
│    │    └─DCGRUCell: 3-38              [64, 20800]               (recursive)
│    └─Linear: 2-26                      [20800, 1]                (recursive)
├─DecoderModel: 1-20                     [64, 325]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-39              [64, 20800]               (recursive)
│    │    └─DCGRUCell: 3-40              [64, 20800]               (recursive)
│    └─Linear: 2-28                      [20800, 1]                (recursive)
├─DecoderModel: 1-21                     [64, 325]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-41              [64, 20800]               (recursive)
│    │    └─DCGRUCell: 3-42              [64, 20800]               (recursive)
│    └─Linear: 2-30                      [20800, 1]                (recursive)
├─DecoderModel: 1-22                     [64, 325]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-43              [64, 20800]               (recursive)
│    │    └─DCGRUCell: 3-44              [64, 20800]               (recursive)
│    └─Linear: 2-32                      [20800, 1]                (recursive)
├─DecoderModel: 1-23                     [64, 325]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-45              [64, 20800]               (recursive)
│    │    └─DCGRUCell: 3-46              [64, 20800]               (recursive)
│    └─Linear: 2-34                      [20800, 1]                (recursive)
├─DecoderModel: 1-24                     [64, 325]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-47              [64, 20800]               (recursive)
│    │    └─DCGRUCell: 3-48              [64, 20800]               (recursive)
│    └─Linear: 2-36                      [20800, 1]                (recursive)
==========================================================================================
Total params: 65
Trainable params: 65
Non-trainable params: 0
Total mult-adds (T): 5.95
==========================================================================================
Input size (MB): 2.00
Forward/backward pass size (MB): 470.58
Params size (MB): 0.00
Estimated Total Size (MB): 472.58
==========================================================================================

Loss: MaskedMAELoss

2023-09-24 19:43:37.813502 Epoch 1  	Train Loss = 2.27285 Val Loss = 3.38964
2023-09-24 19:49:34.412712 Epoch 2  	Train Loss = 1.85103 Val Loss = 3.30155
2023-09-24 19:55:30.160850 Epoch 3  	Train Loss = 1.82304 Val Loss = 3.28934
2023-09-24 20:01:25.608983 Epoch 4  	Train Loss = 1.81471 Val Loss = 3.28645
2023-09-24 20:07:21.492761 Epoch 5  	Train Loss = 1.81128 Val Loss = 3.28487
2023-09-24 20:13:17.979804 Epoch 6  	Train Loss = 1.80926 Val Loss = 3.28009
2023-09-24 20:19:17.087009 Epoch 7  	Train Loss = 1.80873 Val Loss = 3.28933
2023-09-24 20:25:19.242371 Epoch 8  	Train Loss = 1.80890 Val Loss = 3.28681
2023-09-24 20:31:17.796710 Epoch 9  	Train Loss = 1.80860 Val Loss = 3.27934
2023-09-24 20:37:14.123850 Epoch 10  	Train Loss = 1.81005 Val Loss = 3.28161
2023-09-24 20:43:33.112326 Epoch 11  	Train Loss = 1.81163 Val Loss = 3.28564
2023-09-24 20:49:30.117898 Epoch 12  	Train Loss = 1.81264 Val Loss = 3.29261
2023-09-24 20:55:26.981766 Epoch 13  	Train Loss = 1.81303 Val Loss = 3.27494
2023-09-24 21:01:24.603823 Epoch 14  	Train Loss = 1.81737 Val Loss = 3.27974
2023-09-24 21:07:21.969118 Epoch 15  	Train Loss = 1.81907 Val Loss = 3.28573
2023-09-24 21:13:19.239512 Epoch 16  	Train Loss = 1.82553 Val Loss = 3.27030
2023-09-24 21:19:16.661382 Epoch 17  	Train Loss = 1.83077 Val Loss = 3.28245
2023-09-24 21:25:13.937890 Epoch 18  	Train Loss = 1.84216 Val Loss = 3.27541
2023-09-24 21:31:11.698620 Epoch 19  	Train Loss = 1.85526 Val Loss = 3.26146
2023-09-24 21:37:09.725537 Epoch 20  	Train Loss = 1.86972 Val Loss = 3.24045
2023-09-24 21:43:07.210881 Epoch 21  	Train Loss = 1.88486 Val Loss = 3.24175
2023-09-24 21:49:05.209406 Epoch 22  	Train Loss = 1.90405 Val Loss = 3.23438
2023-09-24 21:55:02.916936 Epoch 23  	Train Loss = 1.93412 Val Loss = 3.23359
2023-09-24 22:00:59.638891 Epoch 24  	Train Loss = 1.97391 Val Loss = 3.21658
2023-09-24 22:06:56.060604 Epoch 25  	Train Loss = 2.01551 Val Loss = 3.20606
2023-09-24 22:12:52.909085 Epoch 26  	Train Loss = 2.05506 Val Loss = 3.18447
2023-09-24 22:18:49.805532 Epoch 27  	Train Loss = 2.11425 Val Loss = 3.16527
2023-09-24 22:24:45.732618 Epoch 28  	Train Loss = 2.17666 Val Loss = 3.14699
2023-09-24 22:30:42.502117 Epoch 29  	Train Loss = 2.24564 Val Loss = 3.12234
2023-09-24 22:36:40.784673 Epoch 30  	Train Loss = 2.30178 Val Loss = 3.09644
2023-09-24 22:42:38.979406 Epoch 31  	Train Loss = 2.36098 Val Loss = 3.09175
2023-09-24 22:48:37.120735 Epoch 32  	Train Loss = 2.41408 Val Loss = 3.08612
2023-09-24 22:54:35.350533 Epoch 33  	Train Loss = 2.47282 Val Loss = 3.07979
2023-09-24 23:00:33.203949 Epoch 34  	Train Loss = 2.51388 Val Loss = 3.07263
2023-09-24 23:06:30.995574 Epoch 35  	Train Loss = 2.54987 Val Loss = 3.06586
2023-09-24 23:12:28.887033 Epoch 36  	Train Loss = 2.57201 Val Loss = 3.05928
2023-09-24 23:18:26.453806 Epoch 37  	Train Loss = 2.59455 Val Loss = 3.05302
2023-09-24 23:24:26.235600 Epoch 38  	Train Loss = 2.59544 Val Loss = 3.04706
2023-09-24 23:30:25.035005 Epoch 39  	Train Loss = 2.61366 Val Loss = 3.04130
2023-09-24 23:36:21.977296 Epoch 40  	Train Loss = 2.61987 Val Loss = 3.03602
2023-09-24 23:42:19.064068 Epoch 41  	Train Loss = 2.63383 Val Loss = 3.03534
2023-09-24 23:48:15.374256 Epoch 42  	Train Loss = 2.63626 Val Loss = 3.03484
2023-09-24 23:54:13.126616 Epoch 43  	Train Loss = 2.63779 Val Loss = 3.03426
2023-09-25 00:00:09.874164 Epoch 44  	Train Loss = 2.64441 Val Loss = 3.03378
2023-09-25 00:06:06.510753 Epoch 45  	Train Loss = 2.64697 Val Loss = 3.03328
2023-09-25 00:12:03.808046 Epoch 46  	Train Loss = 2.64819 Val Loss = 3.03273
2023-09-25 00:18:00.072233 Epoch 47  	Train Loss = 2.64899 Val Loss = 3.03209
2023-09-25 00:23:53.777831 Epoch 48  	Train Loss = 2.64915 Val Loss = 3.03162
2023-09-25 00:29:47.412466 Epoch 49  	Train Loss = 2.64914 Val Loss = 3.03106
2023-09-25 00:35:40.574913 Epoch 50  	Train Loss = 2.65025 Val Loss = 3.03059
2023-09-25 00:41:33.442094 Epoch 51  	Train Loss = 2.65093 Val Loss = 3.03054
2023-09-25 00:47:27.181081 Epoch 52  	Train Loss = 2.65099 Val Loss = 3.03048
2023-09-25 00:53:20.313476 Epoch 53  	Train Loss = 2.64946 Val Loss = 3.03042
2023-09-25 00:59:13.857543 Epoch 54  	Train Loss = 2.65107 Val Loss = 3.03036
2023-09-25 01:05:07.435855 Epoch 55  	Train Loss = 2.65113 Val Loss = 3.03031
2023-09-25 01:11:00.787233 Epoch 56  	Train Loss = 2.65066 Val Loss = 3.03025
2023-09-25 01:16:54.915286 Epoch 57  	Train Loss = 2.65130 Val Loss = 3.03020
2023-09-25 01:22:48.273156 Epoch 58  	Train Loss = 2.65136 Val Loss = 3.03016
2023-09-25 01:28:41.260211 Epoch 59  	Train Loss = 2.65087 Val Loss = 3.03010
2023-09-25 01:34:33.697209 Epoch 60  	Train Loss = 2.65103 Val Loss = 3.03004
2023-09-25 01:40:26.902247 Epoch 61  	Train Loss = 2.65127 Val Loss = 3.02999
2023-09-25 01:46:20.422466 Epoch 62  	Train Loss = 2.65082 Val Loss = 3.02993
2023-09-25 01:52:13.023620 Epoch 63  	Train Loss = 2.65131 Val Loss = 3.02987
2023-09-25 01:58:06.417363 Epoch 64  	Train Loss = 2.65090 Val Loss = 3.02982
2023-09-25 02:03:59.618222 Epoch 65  	Train Loss = 2.65101 Val Loss = 3.02976
2023-09-25 02:09:52.507780 Epoch 66  	Train Loss = 2.65075 Val Loss = 3.02972
2023-09-25 02:15:45.450404 Epoch 67  	Train Loss = 2.65064 Val Loss = 3.02967
2023-09-25 02:21:39.052595 Epoch 68  	Train Loss = 2.65087 Val Loss = 3.02961
2023-09-25 02:27:32.467405 Epoch 69  	Train Loss = 2.65070 Val Loss = 3.02956
2023-09-25 02:33:25.387331 Epoch 70  	Train Loss = 2.65070 Val Loss = 3.02950
2023-09-25 02:39:18.817123 Epoch 71  	Train Loss = 2.65061 Val Loss = 3.02945
2023-09-25 02:45:12.141496 Epoch 72  	Train Loss = 2.65077 Val Loss = 3.02939
2023-09-25 02:51:05.307347 Epoch 73  	Train Loss = 2.65067 Val Loss = 3.02934
2023-09-25 02:56:58.371013 Epoch 74  	Train Loss = 2.65049 Val Loss = 3.02929
2023-09-25 03:02:51.177176 Epoch 75  	Train Loss = 2.65056 Val Loss = 3.02924
2023-09-25 03:08:44.548400 Epoch 76  	Train Loss = 2.65041 Val Loss = 3.02918
2023-09-25 03:14:37.848016 Epoch 77  	Train Loss = 2.65021 Val Loss = 3.02912
2023-09-25 03:20:31.037374 Epoch 78  	Train Loss = 2.65041 Val Loss = 3.02907
2023-09-25 03:26:24.814679 Epoch 79  	Train Loss = 2.65021 Val Loss = 3.02902
2023-09-25 03:32:18.446696 Epoch 80  	Train Loss = 2.65032 Val Loss = 3.02896
2023-09-25 03:38:11.835222 Epoch 81  	Train Loss = 2.65016 Val Loss = 3.02891
2023-09-25 03:44:05.048492 Epoch 82  	Train Loss = 2.65002 Val Loss = 3.02885
2023-09-25 03:49:58.232078 Epoch 83  	Train Loss = 2.65005 Val Loss = 3.02880
2023-09-25 03:55:51.562700 Epoch 84  	Train Loss = 2.65000 Val Loss = 3.02874
2023-09-25 04:01:45.685722 Epoch 85  	Train Loss = 2.65006 Val Loss = 3.02868
2023-09-25 04:07:38.656025 Epoch 86  	Train Loss = 2.64997 Val Loss = 3.02862
2023-09-25 04:13:32.049518 Epoch 87  	Train Loss = 2.65023 Val Loss = 3.02858
2023-09-25 04:19:25.596806 Epoch 88  	Train Loss = 2.64988 Val Loss = 3.02851
2023-09-25 04:25:18.447795 Epoch 89  	Train Loss = 2.65000 Val Loss = 3.02847
2023-09-25 04:31:11.700598 Epoch 90  	Train Loss = 2.64979 Val Loss = 3.02843
2023-09-25 04:37:05.209698 Epoch 91  	Train Loss = 2.64986 Val Loss = 3.02837
2023-09-25 04:42:58.573834 Epoch 92  	Train Loss = 2.64985 Val Loss = 3.02831
2023-09-25 04:48:51.339898 Epoch 93  	Train Loss = 2.64949 Val Loss = 3.02825
2023-09-25 04:54:44.533815 Epoch 94  	Train Loss = 2.64951 Val Loss = 3.02820
2023-09-25 05:00:37.816810 Epoch 95  	Train Loss = 2.64950 Val Loss = 3.02815
2023-09-25 05:06:30.970212 Epoch 96  	Train Loss = 2.64980 Val Loss = 3.02810
2023-09-25 05:12:23.309266 Epoch 97  	Train Loss = 2.64950 Val Loss = 3.02805
2023-09-25 05:18:16.105380 Epoch 98  	Train Loss = 2.64942 Val Loss = 3.02800
2023-09-25 05:24:09.553318 Epoch 99  	Train Loss = 2.64936 Val Loss = 3.02795
2023-09-25 05:30:02.601939 Epoch 100  	Train Loss = 2.64928 Val Loss = 3.02789
2023-09-25 05:35:56.030318 Epoch 101  	Train Loss = 2.64929 Val Loss = 3.02784
2023-09-25 05:41:49.368100 Epoch 102  	Train Loss = 2.64926 Val Loss = 3.02778
2023-09-25 05:47:42.178788 Epoch 103  	Train Loss = 2.64910 Val Loss = 3.02773
2023-09-25 05:53:35.775167 Epoch 104  	Train Loss = 2.64927 Val Loss = 3.02767
2023-09-25 05:59:28.780323 Epoch 105  	Train Loss = 2.64912 Val Loss = 3.02762
2023-09-25 06:05:22.595530 Epoch 106  	Train Loss = 2.64901 Val Loss = 3.02756
2023-09-25 06:11:16.444844 Epoch 107  	Train Loss = 2.64892 Val Loss = 3.02750
2023-09-25 06:17:09.353202 Epoch 108  	Train Loss = 2.64902 Val Loss = 3.02746
2023-09-25 06:23:03.084608 Epoch 109  	Train Loss = 2.64902 Val Loss = 3.02741
2023-09-25 06:28:54.950806 Epoch 110  	Train Loss = 2.64878 Val Loss = 3.02735
2023-09-25 06:34:48.352341 Epoch 111  	Train Loss = 2.64889 Val Loss = 3.02729
2023-09-25 06:40:41.646796 Epoch 112  	Train Loss = 2.64892 Val Loss = 3.02724
2023-09-25 06:46:34.803366 Epoch 113  	Train Loss = 2.64873 Val Loss = 3.02719
2023-09-25 06:52:28.316935 Epoch 114  	Train Loss = 2.64857 Val Loss = 3.02713
2023-09-25 06:58:21.434771 Epoch 115  	Train Loss = 2.64849 Val Loss = 3.02709
2023-09-25 07:04:14.347763 Epoch 116  	Train Loss = 2.64847 Val Loss = 3.02704
2023-09-25 07:10:07.788576 Epoch 117  	Train Loss = 2.64852 Val Loss = 3.02698
2023-09-25 07:16:00.746663 Epoch 118  	Train Loss = 2.64849 Val Loss = 3.02693
2023-09-25 07:21:53.991598 Epoch 119  	Train Loss = 2.64836 Val Loss = 3.02688
2023-09-25 07:27:46.550470 Epoch 120  	Train Loss = 2.64829 Val Loss = 3.02684
2023-09-25 07:33:40.551702 Epoch 121  	Train Loss = 2.64852 Val Loss = 3.02678
2023-09-25 07:39:34.462896 Epoch 122  	Train Loss = 2.64826 Val Loss = 3.02673
2023-09-25 07:45:27.486470 Epoch 123  	Train Loss = 2.64831 Val Loss = 3.02668
2023-09-25 07:51:20.860894 Epoch 124  	Train Loss = 2.64828 Val Loss = 3.02664
2023-09-25 07:57:13.663751 Epoch 125  	Train Loss = 2.64811 Val Loss = 3.02659
2023-09-25 08:03:06.721263 Epoch 126  	Train Loss = 2.64802 Val Loss = 3.02654
2023-09-25 08:08:59.459161 Epoch 127  	Train Loss = 2.64798 Val Loss = 3.02647
2023-09-25 08:14:51.712988 Epoch 128  	Train Loss = 2.64813 Val Loss = 3.02642
2023-09-25 08:20:44.521417 Epoch 129  	Train Loss = 2.64792 Val Loss = 3.02638
2023-09-25 08:26:37.905799 Epoch 130  	Train Loss = 2.64765 Val Loss = 3.02633
2023-09-25 08:32:30.884589 Epoch 131  	Train Loss = 2.64787 Val Loss = 3.02628
2023-09-25 08:38:22.890313 Epoch 132  	Train Loss = 2.64778 Val Loss = 3.02622
2023-09-25 08:44:14.688893 Epoch 133  	Train Loss = 2.64776 Val Loss = 3.02617
2023-09-25 08:50:06.473697 Epoch 134  	Train Loss = 2.64783 Val Loss = 3.02611
2023-09-25 08:55:58.471361 Epoch 135  	Train Loss = 2.64767 Val Loss = 3.02606
2023-09-25 09:01:50.585807 Epoch 136  	Train Loss = 2.64755 Val Loss = 3.02600
2023-09-25 09:07:42.809703 Epoch 137  	Train Loss = 2.64748 Val Loss = 3.02595
2023-09-25 09:13:34.897591 Epoch 138  	Train Loss = 2.64750 Val Loss = 3.02590
2023-09-25 09:19:26.908740 Epoch 139  	Train Loss = 2.64756 Val Loss = 3.02584
2023-09-25 09:25:18.877408 Epoch 140  	Train Loss = 2.64756 Val Loss = 3.02580
2023-09-25 09:31:10.587328 Epoch 141  	Train Loss = 2.64743 Val Loss = 3.02575
2023-09-25 09:37:03.102572 Epoch 142  	Train Loss = 2.64742 Val Loss = 3.02569
2023-09-25 09:42:55.132672 Epoch 143  	Train Loss = 2.64744 Val Loss = 3.02566
2023-09-25 09:48:47.399977 Epoch 144  	Train Loss = 2.64737 Val Loss = 3.02561
2023-09-25 09:54:39.975292 Epoch 145  	Train Loss = 2.64715 Val Loss = 3.02557
2023-09-25 10:00:32.743501 Epoch 146  	Train Loss = 2.64715 Val Loss = 3.02551
2023-09-25 10:06:28.199854 Epoch 147  	Train Loss = 2.64724 Val Loss = 3.02545
2023-09-25 10:12:24.342812 Epoch 148  	Train Loss = 2.64715 Val Loss = 3.02539
2023-09-25 10:18:20.781527 Epoch 149  	Train Loss = 2.64704 Val Loss = 3.02534
2023-09-25 10:24:17.880848 Epoch 150  	Train Loss = 2.64706 Val Loss = 3.02529
2023-09-25 10:30:14.739964 Epoch 151  	Train Loss = 2.64687 Val Loss = 3.02524
2023-09-25 10:36:11.926412 Epoch 152  	Train Loss = 2.64693 Val Loss = 3.02519
2023-09-25 10:42:09.116834 Epoch 153  	Train Loss = 2.64698 Val Loss = 3.02512
2023-09-25 10:48:06.905212 Epoch 154  	Train Loss = 2.64705 Val Loss = 3.02507
2023-09-25 10:54:04.880322 Epoch 155  	Train Loss = 2.64689 Val Loss = 3.02502
2023-09-25 11:00:02.167913 Epoch 156  	Train Loss = 2.64675 Val Loss = 3.02497
2023-09-25 11:05:57.222609 Epoch 157  	Train Loss = 2.64664 Val Loss = 3.02493
2023-09-25 11:11:54.056319 Epoch 158  	Train Loss = 2.64671 Val Loss = 3.02487
2023-09-25 11:17:51.587694 Epoch 159  	Train Loss = 2.64663 Val Loss = 3.02483
2023-09-25 11:23:49.687990 Epoch 160  	Train Loss = 2.64665 Val Loss = 3.02477
2023-09-25 11:29:46.368981 Epoch 161  	Train Loss = 2.64649 Val Loss = 3.02472
2023-09-25 11:35:43.313902 Epoch 162  	Train Loss = 2.64651 Val Loss = 3.02466
2023-09-25 11:41:40.941320 Epoch 163  	Train Loss = 2.64638 Val Loss = 3.02461
2023-09-25 11:47:38.104442 Epoch 164  	Train Loss = 2.64644 Val Loss = 3.02456
2023-09-25 11:53:33.661649 Epoch 165  	Train Loss = 2.64650 Val Loss = 3.02451
2023-09-25 11:59:30.299781 Epoch 166  	Train Loss = 2.64633 Val Loss = 3.02446
2023-09-25 12:05:28.008967 Epoch 167  	Train Loss = 2.64616 Val Loss = 3.02441
2023-09-25 12:11:24.568070 Epoch 168  	Train Loss = 2.64619 Val Loss = 3.02437
2023-09-25 12:17:22.695740 Epoch 169  	Train Loss = 2.64629 Val Loss = 3.02431
2023-09-25 12:23:20.708610 Epoch 170  	Train Loss = 2.64614 Val Loss = 3.02425
2023-09-25 12:29:17.199172 Epoch 171  	Train Loss = 2.64604 Val Loss = 3.02420
2023-09-25 12:35:15.253527 Epoch 172  	Train Loss = 2.64609 Val Loss = 3.02414
2023-09-25 12:41:12.858769 Epoch 173  	Train Loss = 2.64594 Val Loss = 3.02409
2023-09-25 12:47:09.299778 Epoch 174  	Train Loss = 2.64594 Val Loss = 3.02404
2023-09-25 12:53:06.941144 Epoch 175  	Train Loss = 2.64600 Val Loss = 3.02399
2023-09-25 12:59:04.377679 Epoch 176  	Train Loss = 2.64584 Val Loss = 3.02395
2023-09-25 13:05:01.800706 Epoch 177  	Train Loss = 2.64571 Val Loss = 3.02390
2023-09-25 13:10:58.753132 Epoch 178  	Train Loss = 2.64575 Val Loss = 3.02384
2023-09-25 13:16:56.078087 Epoch 179  	Train Loss = 2.64577 Val Loss = 3.02379
2023-09-25 13:22:53.525541 Epoch 180  	Train Loss = 2.64583 Val Loss = 3.02374
2023-09-25 13:28:49.926941 Epoch 181  	Train Loss = 2.64567 Val Loss = 3.02368
2023-09-25 13:34:47.743102 Epoch 182  	Train Loss = 2.64563 Val Loss = 3.02363
2023-09-25 13:40:46.015155 Epoch 183  	Train Loss = 2.64573 Val Loss = 3.02359
2023-09-25 13:46:41.881013 Epoch 184  	Train Loss = 2.64553 Val Loss = 3.02354
2023-09-25 13:52:40.307267 Epoch 185  	Train Loss = 2.64550 Val Loss = 3.02350
2023-09-25 13:58:38.237877 Epoch 186  	Train Loss = 2.64565 Val Loss = 3.02345
2023-09-25 14:04:35.442988 Epoch 187  	Train Loss = 2.64541 Val Loss = 3.02340
2023-09-25 14:10:32.297658 Epoch 188  	Train Loss = 2.64542 Val Loss = 3.02333
2023-09-25 14:16:30.702440 Epoch 189  	Train Loss = 2.64539 Val Loss = 3.02329
2023-09-25 14:22:27.747573 Epoch 190  	Train Loss = 2.64539 Val Loss = 3.02323
2023-09-25 14:28:22.388810 Epoch 191  	Train Loss = 2.64507 Val Loss = 3.02319
2023-09-25 14:34:16.368130 Epoch 192  	Train Loss = 2.64541 Val Loss = 3.02313
2023-09-25 14:40:11.190264 Epoch 193  	Train Loss = 2.64500 Val Loss = 3.02307
2023-09-25 14:46:05.528408 Epoch 194  	Train Loss = 2.64506 Val Loss = 3.02302
2023-09-25 14:52:02.636159 Epoch 195  	Train Loss = 2.64520 Val Loss = 3.02297
2023-09-25 14:57:59.133209 Epoch 196  	Train Loss = 2.64514 Val Loss = 3.02292
2023-09-25 15:03:55.391871 Epoch 197  	Train Loss = 2.64502 Val Loss = 3.02286
2023-09-25 15:09:53.222759 Epoch 198  	Train Loss = 2.64479 Val Loss = 3.02281
2023-09-25 15:15:51.256024 Epoch 199  	Train Loss = 2.64499 Val Loss = 3.02276
2023-09-25 15:21:46.912550 Epoch 200  	Train Loss = 2.64484 Val Loss = 3.02272
Early stopping at epoch: 200
Best at epoch 200:
Train Loss = 2.64484
Train RMSE = 5.46112, MAE = 2.64484, MAPE = 6.33976
Val Loss = 3.02272
Val RMSE = 6.15377, MAE = 2.99638, MAPE = 7.63291
--------- Test ---------
All Steps RMSE = 5.61840, MAE = 2.71847, MAPE = 6.66097
Step 1 RMSE = 3.57883, MAE = 1.93687, MAPE = 4.48935
Step 2 RMSE = 3.85132, MAE = 1.98500, MAPE = 4.60556
Step 3 RMSE = 4.29701, MAE = 2.14573, MAPE = 5.08833
Step 4 RMSE = 4.75328, MAE = 2.31188, MAPE = 5.63303
Step 5 RMSE = 5.17407, MAE = 2.48620, MAPE = 6.16343
Step 6 RMSE = 5.53709, MAE = 2.65747, MAPE = 6.63788
Step 7 RMSE = 5.84451, MAE = 2.81100, MAPE = 7.03763
Step 8 RMSE = 6.11176, MAE = 2.94548, MAPE = 7.37315
Step 9 RMSE = 6.35738, MAE = 3.07556, MAPE = 7.68039
Step 10 RMSE = 6.59729, MAE = 3.22377, MAPE = 8.00530
Step 11 RMSE = 6.84245, MAE = 3.40812, MAPE = 8.38450
Step 12 RMSE = 7.09908, MAE = 3.63445, MAPE = 8.83314
Inference time: 54.53 s
