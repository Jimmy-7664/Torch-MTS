METRLA
Trainset:	x-(23974, 12, 207, 2)	y-(23974, 12, 207, 1)
Valset:  	x-(3425, 12, 207, 2)  	y-(3425, 12, 207, 1)
Testset:	x-(6850, 12, 207, 2)	y-(6850, 12, 207, 1)

Random seed = 233
--------- DCRNN ---------
{
    "num_nodes": 207,
    "in_steps": 12,
    "out_steps": 12,
    "time_of_day": true,
    "runner": "dcrnn",
    "lr": 0.01,
    "eps": 0.001,
    "milestones": [
        20,
        30,
        40,
        50
    ],
    "clip_grad": 5,
    "batch_size": 64,
    "max_epochs": 200,
    "early_stop": 20,
    "pass_device": true,
    "model_args": {
        "num_nodes": 207,
        "adj_path": "../data/METRLA/adj_mx.pkl",
        "input_dim": 2,
        "output_dim": 1,
        "seq_len": 12,
        "horizon": 12,
        "rnn_units": 64,
        "num_rnn_layers": 2,
        "max_diffusion_step": 2,
        "filter_type": "dual_random_walk",
        "tf_decay_steps": 2000,
        "use_teacher_forcing": true,
        "device": "cuda:0"
    }
}
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
DCRNN                                    [64, 12, 207, 1]          --
├─EncoderModel: 1-1                      [64, 13248]               --
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-1               [64, 13248]               --
│    │    └─DCGRUCell: 3-2               [64, 13248]               --
├─EncoderModel: 1-2                      [64, 13248]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-3               [64, 13248]               (recursive)
│    │    └─DCGRUCell: 3-4               [64, 13248]               (recursive)
├─EncoderModel: 1-3                      [64, 13248]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-5               [64, 13248]               (recursive)
│    │    └─DCGRUCell: 3-6               [64, 13248]               (recursive)
├─EncoderModel: 1-4                      [64, 13248]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-7               [64, 13248]               (recursive)
│    │    └─DCGRUCell: 3-8               [64, 13248]               (recursive)
├─EncoderModel: 1-5                      [64, 13248]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-9               [64, 13248]               (recursive)
│    │    └─DCGRUCell: 3-10              [64, 13248]               (recursive)
├─EncoderModel: 1-6                      [64, 13248]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-11              [64, 13248]               (recursive)
│    │    └─DCGRUCell: 3-12              [64, 13248]               (recursive)
├─EncoderModel: 1-7                      [64, 13248]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-13              [64, 13248]               (recursive)
│    │    └─DCGRUCell: 3-14              [64, 13248]               (recursive)
├─EncoderModel: 1-8                      [64, 13248]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-15              [64, 13248]               (recursive)
│    │    └─DCGRUCell: 3-16              [64, 13248]               (recursive)
├─EncoderModel: 1-9                      [64, 13248]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-17              [64, 13248]               (recursive)
│    │    └─DCGRUCell: 3-18              [64, 13248]               (recursive)
├─EncoderModel: 1-10                     [64, 13248]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-19              [64, 13248]               (recursive)
│    │    └─DCGRUCell: 3-20              [64, 13248]               (recursive)
├─EncoderModel: 1-11                     [64, 13248]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-21              [64, 13248]               (recursive)
│    │    └─DCGRUCell: 3-22              [64, 13248]               (recursive)
├─EncoderModel: 1-12                     [64, 13248]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-23              [64, 13248]               (recursive)
│    │    └─DCGRUCell: 3-24              [64, 13248]               (recursive)
├─DecoderModel: 1-13                     [64, 207]                 --
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-25              [64, 13248]               --
│    │    └─DCGRUCell: 3-26              [64, 13248]               --
│    └─Linear: 2-14                      [13248, 1]                65
├─DecoderModel: 1-14                     [64, 207]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-27              [64, 13248]               (recursive)
│    │    └─DCGRUCell: 3-28              [64, 13248]               (recursive)
│    └─Linear: 2-16                      [13248, 1]                (recursive)
├─DecoderModel: 1-15                     [64, 207]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-29              [64, 13248]               (recursive)
│    │    └─DCGRUCell: 3-30              [64, 13248]               (recursive)
│    └─Linear: 2-18                      [13248, 1]                (recursive)
├─DecoderModel: 1-16                     [64, 207]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-31              [64, 13248]               (recursive)
│    │    └─DCGRUCell: 3-32              [64, 13248]               (recursive)
│    └─Linear: 2-20                      [13248, 1]                (recursive)
├─DecoderModel: 1-17                     [64, 207]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-33              [64, 13248]               (recursive)
│    │    └─DCGRUCell: 3-34              [64, 13248]               (recursive)
│    └─Linear: 2-22                      [13248, 1]                (recursive)
├─DecoderModel: 1-18                     [64, 207]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-35              [64, 13248]               (recursive)
│    │    └─DCGRUCell: 3-36              [64, 13248]               (recursive)
│    └─Linear: 2-24                      [13248, 1]                (recursive)
├─DecoderModel: 1-19                     [64, 207]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-37              [64, 13248]               (recursive)
│    │    └─DCGRUCell: 3-38              [64, 13248]               (recursive)
│    └─Linear: 2-26                      [13248, 1]                (recursive)
├─DecoderModel: 1-20                     [64, 207]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-39              [64, 13248]               (recursive)
│    │    └─DCGRUCell: 3-40              [64, 13248]               (recursive)
│    └─Linear: 2-28                      [13248, 1]                (recursive)
├─DecoderModel: 1-21                     [64, 207]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-41              [64, 13248]               (recursive)
│    │    └─DCGRUCell: 3-42              [64, 13248]               (recursive)
│    └─Linear: 2-30                      [13248, 1]                (recursive)
├─DecoderModel: 1-22                     [64, 207]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-43              [64, 13248]               (recursive)
│    │    └─DCGRUCell: 3-44              [64, 13248]               (recursive)
│    └─Linear: 2-32                      [13248, 1]                (recursive)
├─DecoderModel: 1-23                     [64, 207]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-45              [64, 13248]               (recursive)
│    │    └─DCGRUCell: 3-46              [64, 13248]               (recursive)
│    └─Linear: 2-34                      [13248, 1]                (recursive)
├─DecoderModel: 1-24                     [64, 207]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-47              [64, 13248]               (recursive)
│    │    └─DCGRUCell: 3-48              [64, 13248]               (recursive)
│    └─Linear: 2-36                      [13248, 1]                (recursive)
==========================================================================================
Total params: 65
Trainable params: 65
Non-trainable params: 0
Total mult-adds (T): 3.79
==========================================================================================
Input size (MB): 1.27
Forward/backward pass size (MB): 299.72
Params size (MB): 0.00
Estimated Total Size (MB): 300.99
==========================================================================================

Loss: MaskedMAELoss

2024-04-21 09:15:40.163269 Epoch 1  	Train Loss = 2.77598 Val Loss = 3.51500
2024-04-21 09:17:52.025848 Epoch 2  	Train Loss = 2.31729 Val Loss = 3.25165
2024-04-21 09:20:05.783150 Epoch 3  	Train Loss = 2.25221 Val Loss = 3.15282
2024-04-21 09:22:16.571001 Epoch 4  	Train Loss = 2.20841 Val Loss = 3.09472
2024-04-21 09:24:25.185446 Epoch 5  	Train Loss = 2.17692 Val Loss = 3.04074
2024-04-21 09:26:44.528305 Epoch 6  	Train Loss = 2.15465 Val Loss = 3.00777
2024-04-21 09:28:57.185868 Epoch 7  	Train Loss = 2.13842 Val Loss = 3.05202
2024-04-21 09:31:15.254547 Epoch 8  	Train Loss = 2.12169 Val Loss = 2.93624
2024-04-21 09:33:26.170129 Epoch 9  	Train Loss = 2.10985 Val Loss = 3.03830
2024-04-21 09:35:39.676092 Epoch 10  	Train Loss = 2.09721 Val Loss = 2.92387
2024-04-21 09:37:53.481932 Epoch 11  	Train Loss = 2.08789 Val Loss = 2.89753
2024-04-21 09:40:08.698692 Epoch 12  	Train Loss = 2.07494 Val Loss = 2.95996
2024-04-21 09:42:22.755351 Epoch 13  	Train Loss = 2.06942 Val Loss = 2.91320
2024-04-21 09:44:29.641411 Epoch 14  	Train Loss = 2.06266 Val Loss = 2.93310
2024-04-21 09:46:42.347815 Epoch 15  	Train Loss = 2.05583 Val Loss = 3.02737
2024-04-21 09:48:57.022144 Epoch 16  	Train Loss = 2.04978 Val Loss = 2.93757
2024-04-21 09:51:11.585853 Epoch 17  	Train Loss = 2.04371 Val Loss = 2.92252
2024-04-21 09:53:23.044208 Epoch 18  	Train Loss = 2.03904 Val Loss = 2.89374
2024-04-21 09:55:37.156343 Epoch 19  	Train Loss = 2.03257 Val Loss = 2.97640
2024-04-21 09:57:47.807413 Epoch 20  	Train Loss = 2.02866 Val Loss = 2.89855
2024-04-21 10:00:05.134450 Epoch 21  	Train Loss = 2.00310 Val Loss = 2.84393
2024-04-21 10:02:17.114997 Epoch 22  	Train Loss = 2.00034 Val Loss = 2.84378
2024-04-21 10:04:27.490415 Epoch 23  	Train Loss = 2.00000 Val Loss = 2.84536
2024-04-21 10:06:41.171715 Epoch 24  	Train Loss = 2.00288 Val Loss = 2.84911
2024-04-21 10:08:58.742630 Epoch 25  	Train Loss = 2.00195 Val Loss = 2.85221
2024-04-21 10:11:17.267005 Epoch 26  	Train Loss = 2.00552 Val Loss = 2.85762
2024-04-21 10:13:37.849076 Epoch 27  	Train Loss = 2.01313 Val Loss = 2.84766
2024-04-21 10:15:47.637342 Epoch 28  	Train Loss = 2.01514 Val Loss = 2.85514
2024-04-21 10:18:02.494257 Epoch 29  	Train Loss = 2.01916 Val Loss = 2.85074
2024-04-21 10:20:16.379235 Epoch 30  	Train Loss = 2.02827 Val Loss = 2.84876
2024-04-21 10:22:26.965930 Epoch 31  	Train Loss = 2.03168 Val Loss = 2.84088
2024-04-21 10:24:41.123275 Epoch 32  	Train Loss = 2.03411 Val Loss = 2.83853
2024-04-21 10:26:55.190753 Epoch 33  	Train Loss = 2.04644 Val Loss = 2.83584
2024-04-21 10:29:15.383756 Epoch 34  	Train Loss = 2.05552 Val Loss = 2.83411
2024-04-21 10:31:22.742525 Epoch 35  	Train Loss = 2.06982 Val Loss = 2.83533
2024-04-21 10:33:35.134276 Epoch 36  	Train Loss = 2.09000 Val Loss = 2.83478
2024-04-21 10:35:48.115921 Epoch 37  	Train Loss = 2.10152 Val Loss = 2.83594
2024-04-21 10:38:00.863067 Epoch 38  	Train Loss = 2.12488 Val Loss = 2.83122
2024-04-21 10:40:19.277254 Epoch 39  	Train Loss = 2.13942 Val Loss = 2.82640
2024-04-21 10:42:37.672322 Epoch 40  	Train Loss = 2.15926 Val Loss = 2.82567
2024-04-21 10:44:50.829623 Epoch 41  	Train Loss = 2.19769 Val Loss = 2.82013
2024-04-21 10:46:58.678369 Epoch 42  	Train Loss = 2.21585 Val Loss = 2.81884
2024-04-21 10:49:11.297740 Epoch 43  	Train Loss = 2.25884 Val Loss = 2.81662
2024-04-21 10:51:16.580497 Epoch 44  	Train Loss = 2.29066 Val Loss = 2.81487
2024-04-21 10:53:30.228099 Epoch 45  	Train Loss = 2.32413 Val Loss = 2.81511
2024-04-21 10:55:42.535714 Epoch 46  	Train Loss = 2.35287 Val Loss = 2.81254
2024-04-21 10:57:55.282257 Epoch 47  	Train Loss = 2.38282 Val Loss = 2.81179
2024-04-21 11:00:02.564521 Epoch 48  	Train Loss = 2.41655 Val Loss = 2.81115
2024-04-21 11:02:17.843884 Epoch 49  	Train Loss = 2.45404 Val Loss = 2.81086
2024-04-21 11:04:31.537610 Epoch 50  	Train Loss = 2.48911 Val Loss = 2.80822
2024-04-21 11:06:39.453063 Epoch 51  	Train Loss = 2.51752 Val Loss = 2.80779
2024-04-21 11:08:52.462982 Epoch 52  	Train Loss = 2.54670 Val Loss = 2.80731
2024-04-21 11:11:04.862373 Epoch 53  	Train Loss = 2.56496 Val Loss = 2.80682
2024-04-21 11:13:16.061294 Epoch 54  	Train Loss = 2.59020 Val Loss = 2.80696
2024-04-21 11:15:32.342042 Epoch 55  	Train Loss = 2.60923 Val Loss = 2.80681
2024-04-21 11:17:44.826888 Epoch 56  	Train Loss = 2.62652 Val Loss = 2.80605
2024-04-21 11:19:51.684916 Epoch 57  	Train Loss = 2.62629 Val Loss = 2.80593
2024-04-21 11:22:00.844434 Epoch 58  	Train Loss = 2.64463 Val Loss = 2.80593
2024-04-21 11:24:16.355753 Epoch 59  	Train Loss = 2.65610 Val Loss = 2.80558
2024-04-21 11:26:31.637150 Epoch 60  	Train Loss = 2.66345 Val Loss = 2.80566
2024-04-21 11:28:42.823525 Epoch 61  	Train Loss = 2.67711 Val Loss = 2.80519
2024-04-21 11:30:54.193150 Epoch 62  	Train Loss = 2.69159 Val Loss = 2.80486
2024-04-21 11:33:07.460730 Epoch 63  	Train Loss = 2.69241 Val Loss = 2.80481
2024-04-21 11:35:20.485201 Epoch 64  	Train Loss = 2.69408 Val Loss = 2.80491
2024-04-21 11:37:32.240755 Epoch 65  	Train Loss = 2.69740 Val Loss = 2.80459
2024-04-21 11:39:44.934294 Epoch 66  	Train Loss = 2.70225 Val Loss = 2.80405
2024-04-21 11:41:59.391249 Epoch 67  	Train Loss = 2.70640 Val Loss = 2.80460
2024-04-21 11:44:11.053636 Epoch 68  	Train Loss = 2.70770 Val Loss = 2.80389
2024-04-21 11:46:23.236258 Epoch 69  	Train Loss = 2.70815 Val Loss = 2.80419
2024-04-21 11:48:29.187309 Epoch 70  	Train Loss = 2.71303 Val Loss = 2.80363
2024-04-21 11:50:42.603947 Epoch 71  	Train Loss = 2.70987 Val Loss = 2.80398
2024-04-21 11:52:56.566486 Epoch 72  	Train Loss = 2.71097 Val Loss = 2.80384
2024-04-21 11:55:11.254438 Epoch 73  	Train Loss = 2.71368 Val Loss = 2.80343
2024-04-21 11:57:17.416247 Epoch 74  	Train Loss = 2.71140 Val Loss = 2.80373
2024-04-21 11:59:33.117452 Epoch 75  	Train Loss = 2.71054 Val Loss = 2.80320
2024-04-21 12:01:46.425191 Epoch 76  	Train Loss = 2.71484 Val Loss = 2.80334
2024-04-21 12:03:55.847220 Epoch 77  	Train Loss = 2.71502 Val Loss = 2.80339
2024-04-21 12:06:08.798187 Epoch 78  	Train Loss = 2.71360 Val Loss = 2.80367
2024-04-21 12:08:14.537172 Epoch 79  	Train Loss = 2.71400 Val Loss = 2.80345
2024-04-21 12:10:30.947849 Epoch 80  	Train Loss = 2.71079 Val Loss = 2.80336
2024-04-21 12:12:52.724429 Epoch 81  	Train Loss = 2.71312 Val Loss = 2.80304
2024-04-21 12:15:07.208210 Epoch 82  	Train Loss = 2.71342 Val Loss = 2.80305
2024-04-21 12:17:27.270870 Epoch 83  	Train Loss = 2.71297 Val Loss = 2.80322
2024-04-21 12:19:40.200517 Epoch 84  	Train Loss = 2.71203 Val Loss = 2.80314
2024-04-21 12:21:49.769909 Epoch 85  	Train Loss = 2.71242 Val Loss = 2.80318
2024-04-21 12:24:07.604011 Epoch 86  	Train Loss = 2.71221 Val Loss = 2.80292
2024-04-21 12:26:21.063024 Epoch 87  	Train Loss = 2.71223 Val Loss = 2.80270
2024-04-21 12:28:36.539295 Epoch 88  	Train Loss = 2.71208 Val Loss = 2.80263
2024-04-21 12:30:47.805607 Epoch 89  	Train Loss = 2.71188 Val Loss = 2.80276
2024-04-21 12:32:56.910783 Epoch 90  	Train Loss = 2.71145 Val Loss = 2.80259
2024-04-21 12:35:09.537308 Epoch 91  	Train Loss = 2.71129 Val Loss = 2.80266
2024-04-21 12:37:20.582031 Epoch 92  	Train Loss = 2.71074 Val Loss = 2.80276
2024-04-21 12:39:34.171605 Epoch 93  	Train Loss = 2.71058 Val Loss = 2.80277
2024-04-21 12:41:46.684353 Epoch 94  	Train Loss = 2.71048 Val Loss = 2.80256
2024-04-21 12:44:00.291282 Epoch 95  	Train Loss = 2.71051 Val Loss = 2.80289
2024-04-21 12:46:11.934547 Epoch 96  	Train Loss = 2.70969 Val Loss = 2.80274
2024-04-21 12:48:22.889125 Epoch 97  	Train Loss = 2.70938 Val Loss = 2.80228
2024-04-21 12:50:34.955739 Epoch 98  	Train Loss = 2.70988 Val Loss = 2.80257
2024-04-21 12:52:44.448031 Epoch 99  	Train Loss = 2.70914 Val Loss = 2.80242
2024-04-21 12:55:01.421833 Epoch 100  	Train Loss = 2.70867 Val Loss = 2.80250
2024-04-21 12:57:17.410097 Epoch 101  	Train Loss = 2.70849 Val Loss = 2.80249
2024-04-21 12:59:26.884810 Epoch 102  	Train Loss = 2.70871 Val Loss = 2.80230
2024-04-21 13:01:39.091914 Epoch 103  	Train Loss = 2.70880 Val Loss = 2.80242
2024-04-21 13:03:52.889115 Epoch 104  	Train Loss = 2.70789 Val Loss = 2.80271
2024-04-21 13:06:06.787320 Epoch 105  	Train Loss = 2.70785 Val Loss = 2.80228
2024-04-21 13:08:17.615218 Epoch 106  	Train Loss = 2.70831 Val Loss = 2.80225
2024-04-21 13:10:32.344341 Epoch 107  	Train Loss = 2.70754 Val Loss = 2.80252
2024-04-21 13:12:51.218962 Epoch 108  	Train Loss = 2.70793 Val Loss = 2.80220
2024-04-21 13:15:07.311228 Epoch 109  	Train Loss = 2.70731 Val Loss = 2.80217
2024-04-21 13:17:22.131222 Epoch 110  	Train Loss = 2.70688 Val Loss = 2.80238
2024-04-21 13:19:42.344640 Epoch 111  	Train Loss = 2.70634 Val Loss = 2.80242
2024-04-21 13:21:54.592323 Epoch 112  	Train Loss = 2.70654 Val Loss = 2.80242
2024-04-21 13:24:15.359110 Epoch 113  	Train Loss = 2.70667 Val Loss = 2.80231
2024-04-21 13:26:38.300148 Epoch 114  	Train Loss = 2.70551 Val Loss = 2.80234
2024-04-21 13:28:52.848652 Epoch 115  	Train Loss = 2.70585 Val Loss = 2.80235
2024-04-21 13:31:07.222109 Epoch 116  	Train Loss = 2.70544 Val Loss = 2.80250
2024-04-21 13:33:20.521412 Epoch 117  	Train Loss = 2.70595 Val Loss = 2.80222
2024-04-21 13:35:38.360031 Epoch 118  	Train Loss = 2.70547 Val Loss = 2.80196
2024-04-21 13:37:47.565112 Epoch 119  	Train Loss = 2.70520 Val Loss = 2.80256
2024-04-21 13:40:06.416214 Epoch 120  	Train Loss = 2.70449 Val Loss = 2.80226
2024-04-21 13:42:23.651044 Epoch 121  	Train Loss = 2.70484 Val Loss = 2.80232
2024-04-21 13:44:46.337982 Epoch 122  	Train Loss = 2.70453 Val Loss = 2.80225
2024-04-21 13:47:08.411035 Epoch 123  	Train Loss = 2.70407 Val Loss = 2.80206
2024-04-21 13:49:24.334528 Epoch 124  	Train Loss = 2.70426 Val Loss = 2.80246
2024-04-21 13:51:45.456550 Epoch 125  	Train Loss = 2.70409 Val Loss = 2.80222
2024-04-21 13:53:59.312926 Epoch 126  	Train Loss = 2.70351 Val Loss = 2.80209
2024-04-21 13:56:16.778040 Epoch 127  	Train Loss = 2.70322 Val Loss = 2.80233
2024-04-21 13:58:31.639306 Epoch 128  	Train Loss = 2.70314 Val Loss = 2.80207
2024-04-21 14:00:46.626882 Epoch 129  	Train Loss = 2.70307 Val Loss = 2.80231
2024-04-21 14:03:00.035951 Epoch 130  	Train Loss = 2.70299 Val Loss = 2.80213
2024-04-21 14:05:12.170617 Epoch 131  	Train Loss = 2.70228 Val Loss = 2.80242
2024-04-21 14:07:18.241688 Epoch 132  	Train Loss = 2.70250 Val Loss = 2.80239
2024-04-21 14:09:29.664180 Epoch 133  	Train Loss = 2.70190 Val Loss = 2.80206
2024-04-21 14:11:44.118264 Epoch 134  	Train Loss = 2.70213 Val Loss = 2.80234
2024-04-21 14:13:49.951527 Epoch 135  	Train Loss = 2.70172 Val Loss = 2.80217
2024-04-21 14:16:03.978334 Epoch 136  	Train Loss = 2.70210 Val Loss = 2.80204
2024-04-21 14:18:17.532624 Epoch 137  	Train Loss = 2.70141 Val Loss = 2.80224
2024-04-21 14:20:35.269913 Epoch 138  	Train Loss = 2.70124 Val Loss = 2.80227
Early stopping at epoch: 138
Best at epoch 118:
Train Loss = 2.70547
Train MAE = 2.70484, RMSE = 5.53568, MAPE = 7.12189
Val Loss = 2.80196
Val MAE = 2.83195, RMSE = 6.03176, MAPE = 7.89499
Model checkpoint saved to: ../saved_models/DCRNN/DCRNN-METRLA-2024-04-21-09-13-26.pt
--------- Test ---------
All Steps (1-12) MAE = 3.08193, RMSE = 6.37786, MAPE = 8.44660
Step 1 MAE = 2.23530, RMSE = 3.89872, MAPE = 5.35640
Step 2 MAE = 2.52283, RMSE = 4.74067, MAPE = 6.31365
Step 3 MAE = 2.71726, RMSE = 5.31083, MAPE = 7.01829
Step 4 MAE = 2.87458, RMSE = 5.75853, MAPE = 7.60898
Step 5 MAE = 3.00633, RMSE = 6.12035, MAPE = 8.11302
Step 6 MAE = 3.11987, RMSE = 6.42575, MAPE = 8.55188
Step 7 MAE = 3.22183, RMSE = 6.69205, MAPE = 8.94799
Step 8 MAE = 3.31217, RMSE = 6.92411, MAPE = 9.30204
Step 9 MAE = 3.39188, RMSE = 7.12482, MAPE = 9.62303
Step 10 MAE = 3.46208, RMSE = 7.30146, MAPE = 9.90995
Step 11 MAE = 3.52739, RMSE = 7.45946, MAPE = 10.17428
Step 12 MAE = 3.59178, RMSE = 7.60882, MAPE = 10.43991
Inference time: 15.48 s
