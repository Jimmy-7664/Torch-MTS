PEMS08
Trainset:	x-(10700, 12, 170, 2)	y-(10700, 12, 170, 1)
Valset:  	x-(3567, 12, 170, 2)  	y-(3567, 12, 170, 1)
Testset:	x-(3566, 12, 170, 2)	y-(3566, 12, 170, 1)

--------- DCRNN ---------
{
    "num_nodes": 170,
    "in_steps": 12,
    "out_steps": 12,
    "time_of_day": true,
    "runner": "dcrnn",
    "lr": 0.003,
    "eps": 0.001,
    "milestones": [
        80
    ],
    "lr_decay_rate": 0.3,
    "batch_size": 64,
    "max_epochs": 200,
    "early_stop": 20,
    "pass_device": true,
    "model_args": {
        "num_nodes": 170,
        "adj_path": "../data/PEMS08/adj_PEMS08.pkl",
        "input_dim": 2,
        "output_dim": 1,
        "seq_len": 12,
        "horizon": 12,
        "rnn_units": 64,
        "num_rnn_layers": 2,
        "max_diffusion_step": 2,
        "filter_type": "dual_random_walk",
        "tf_decay_steps": 2000,
        "use_teacher_forcing": true,
        "device": "cuda:0"
    }
}
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
DCRNN                                    [64, 12, 170, 1]          --
├─EncoderModel: 1-1                      [64, 10880]               --
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-1               [64, 10880]               --
│    │    └─DCGRUCell: 3-2               [64, 10880]               --
├─EncoderModel: 1-2                      [64, 10880]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-3               [64, 10880]               (recursive)
│    │    └─DCGRUCell: 3-4               [64, 10880]               (recursive)
├─EncoderModel: 1-3                      [64, 10880]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-5               [64, 10880]               (recursive)
│    │    └─DCGRUCell: 3-6               [64, 10880]               (recursive)
├─EncoderModel: 1-4                      [64, 10880]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-7               [64, 10880]               (recursive)
│    │    └─DCGRUCell: 3-8               [64, 10880]               (recursive)
├─EncoderModel: 1-5                      [64, 10880]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-9               [64, 10880]               (recursive)
│    │    └─DCGRUCell: 3-10              [64, 10880]               (recursive)
├─EncoderModel: 1-6                      [64, 10880]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-11              [64, 10880]               (recursive)
│    │    └─DCGRUCell: 3-12              [64, 10880]               (recursive)
├─EncoderModel: 1-7                      [64, 10880]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-13              [64, 10880]               (recursive)
│    │    └─DCGRUCell: 3-14              [64, 10880]               (recursive)
├─EncoderModel: 1-8                      [64, 10880]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-15              [64, 10880]               (recursive)
│    │    └─DCGRUCell: 3-16              [64, 10880]               (recursive)
├─EncoderModel: 1-9                      [64, 10880]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-17              [64, 10880]               (recursive)
│    │    └─DCGRUCell: 3-18              [64, 10880]               (recursive)
├─EncoderModel: 1-10                     [64, 10880]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-19              [64, 10880]               (recursive)
│    │    └─DCGRUCell: 3-20              [64, 10880]               (recursive)
├─EncoderModel: 1-11                     [64, 10880]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-21              [64, 10880]               (recursive)
│    │    └─DCGRUCell: 3-22              [64, 10880]               (recursive)
├─EncoderModel: 1-12                     [64, 10880]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-23              [64, 10880]               (recursive)
│    │    └─DCGRUCell: 3-24              [64, 10880]               (recursive)
├─DecoderModel: 1-13                     [64, 170]                 --
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-25              [64, 10880]               --
│    │    └─DCGRUCell: 3-26              [64, 10880]               --
│    └─Linear: 2-14                      [10880, 1]                65
├─DecoderModel: 1-14                     [64, 170]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-27              [64, 10880]               (recursive)
│    │    └─DCGRUCell: 3-28              [64, 10880]               (recursive)
│    └─Linear: 2-16                      [10880, 1]                (recursive)
├─DecoderModel: 1-15                     [64, 170]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-29              [64, 10880]               (recursive)
│    │    └─DCGRUCell: 3-30              [64, 10880]               (recursive)
│    └─Linear: 2-18                      [10880, 1]                (recursive)
├─DecoderModel: 1-16                     [64, 170]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-31              [64, 10880]               (recursive)
│    │    └─DCGRUCell: 3-32              [64, 10880]               (recursive)
│    └─Linear: 2-20                      [10880, 1]                (recursive)
├─DecoderModel: 1-17                     [64, 170]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-33              [64, 10880]               (recursive)
│    │    └─DCGRUCell: 3-34              [64, 10880]               (recursive)
│    └─Linear: 2-22                      [10880, 1]                (recursive)
├─DecoderModel: 1-18                     [64, 170]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-35              [64, 10880]               (recursive)
│    │    └─DCGRUCell: 3-36              [64, 10880]               (recursive)
│    └─Linear: 2-24                      [10880, 1]                (recursive)
├─DecoderModel: 1-19                     [64, 170]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-37              [64, 10880]               (recursive)
│    │    └─DCGRUCell: 3-38              [64, 10880]               (recursive)
│    └─Linear: 2-26                      [10880, 1]                (recursive)
├─DecoderModel: 1-20                     [64, 170]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-39              [64, 10880]               (recursive)
│    │    └─DCGRUCell: 3-40              [64, 10880]               (recursive)
│    └─Linear: 2-28                      [10880, 1]                (recursive)
├─DecoderModel: 1-21                     [64, 170]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-41              [64, 10880]               (recursive)
│    │    └─DCGRUCell: 3-42              [64, 10880]               (recursive)
│    └─Linear: 2-30                      [10880, 1]                (recursive)
├─DecoderModel: 1-22                     [64, 170]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-43              [64, 10880]               (recursive)
│    │    └─DCGRUCell: 3-44              [64, 10880]               (recursive)
│    └─Linear: 2-32                      [10880, 1]                (recursive)
├─DecoderModel: 1-23                     [64, 170]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-45              [64, 10880]               (recursive)
│    │    └─DCGRUCell: 3-46              [64, 10880]               (recursive)
│    └─Linear: 2-34                      [10880, 1]                (recursive)
├─DecoderModel: 1-24                     [64, 170]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-47              [64, 10880]               (recursive)
│    │    └─DCGRUCell: 3-48              [64, 10880]               (recursive)
│    └─Linear: 2-36                      [10880, 1]                (recursive)
==========================================================================================
Total params: 65
Trainable params: 65
Non-trainable params: 0
Total mult-adds (T): 3.11
==========================================================================================
Input size (MB): 1.04
Forward/backward pass size (MB): 246.15
Params size (MB): 0.00
Estimated Total Size (MB): 247.19
==========================================================================================

Loss: HuberLoss

2024-03-21 09:40:10.671858 Epoch 1  	Train Loss = 18.76364 Val Loss = 22.16770
2024-03-21 09:41:26.501228 Epoch 2  	Train Loss = 14.27754 Val Loss = 22.25409
2024-03-21 09:42:42.157589 Epoch 3  	Train Loss = 13.87653 Val Loss = 19.74979
2024-03-21 09:43:57.323386 Epoch 4  	Train Loss = 13.84895 Val Loss = 19.68241
2024-03-21 09:45:13.008121 Epoch 5  	Train Loss = 13.69344 Val Loss = 20.06245
2024-03-21 09:46:30.709591 Epoch 6  	Train Loss = 13.63919 Val Loss = 20.05492
2024-03-21 09:47:46.935980 Epoch 7  	Train Loss = 13.57458 Val Loss = 18.77842
2024-03-21 09:49:04.056348 Epoch 8  	Train Loss = 13.56379 Val Loss = 19.36036
2024-03-21 09:50:20.931705 Epoch 9  	Train Loss = 13.52078 Val Loss = 18.25357
2024-03-21 09:51:38.454892 Epoch 10  	Train Loss = 13.37786 Val Loss = 18.73756
2024-03-21 09:52:56.076898 Epoch 11  	Train Loss = 13.33603 Val Loss = 24.48754
2024-03-21 09:54:11.540882 Epoch 12  	Train Loss = 13.42988 Val Loss = 18.27188
2024-03-21 09:55:28.475219 Epoch 13  	Train Loss = 13.27962 Val Loss = 18.51578
2024-03-21 09:56:45.444353 Epoch 14  	Train Loss = 13.19013 Val Loss = 18.80256
2024-03-21 09:58:00.154261 Epoch 15  	Train Loss = 13.16382 Val Loss = 18.32830
2024-03-21 09:59:16.733712 Epoch 16  	Train Loss = 13.14633 Val Loss = 18.92776
2024-03-21 10:00:34.922733 Epoch 17  	Train Loss = 13.08389 Val Loss = 18.94196
2024-03-21 10:01:54.240725 Epoch 18  	Train Loss = 13.03067 Val Loss = 20.40893
2024-03-21 10:03:11.834776 Epoch 19  	Train Loss = 13.01052 Val Loss = 16.92539
2024-03-21 10:04:30.365612 Epoch 20  	Train Loss = 12.92757 Val Loss = 17.32518
2024-03-21 10:05:46.736073 Epoch 21  	Train Loss = 12.90113 Val Loss = 16.75977
2024-03-21 10:07:04.826029 Epoch 22  	Train Loss = 12.83831 Val Loss = 18.04376
2024-03-21 10:08:21.537046 Epoch 23  	Train Loss = 12.84732 Val Loss = 17.38661
2024-03-21 10:09:38.656323 Epoch 24  	Train Loss = 12.74787 Val Loss = 16.87160
2024-03-21 10:10:55.420419 Epoch 25  	Train Loss = 12.69024 Val Loss = 16.32066
2024-03-21 10:12:13.791141 Epoch 26  	Train Loss = 12.62980 Val Loss = 17.14459
2024-03-21 10:13:31.956259 Epoch 27  	Train Loss = 12.64943 Val Loss = 17.19007
2024-03-21 10:14:50.824936 Epoch 28  	Train Loss = 12.57208 Val Loss = 16.50884
2024-03-21 10:16:07.845218 Epoch 29  	Train Loss = 12.54244 Val Loss = 16.41161
2024-03-21 10:17:24.355644 Epoch 30  	Train Loss = 12.54223 Val Loss = 15.93679
2024-03-21 10:18:43.657808 Epoch 31  	Train Loss = 12.42766 Val Loss = 16.44821
2024-03-21 10:19:59.395680 Epoch 32  	Train Loss = 12.42218 Val Loss = 16.32937
2024-03-21 10:21:16.786445 Epoch 33  	Train Loss = 12.35663 Val Loss = 15.96873
2024-03-21 10:22:34.246608 Epoch 34  	Train Loss = 12.36114 Val Loss = 16.41805
2024-03-21 10:23:52.350661 Epoch 35  	Train Loss = 12.41160 Val Loss = 16.37476
2024-03-21 10:25:08.643982 Epoch 36  	Train Loss = 12.26025 Val Loss = 17.07906
2024-03-21 10:26:25.841549 Epoch 37  	Train Loss = 12.25701 Val Loss = 15.80690
2024-03-21 10:27:43.493646 Epoch 38  	Train Loss = 12.22842 Val Loss = 18.93149
2024-03-21 10:29:02.143867 Epoch 39  	Train Loss = 12.16990 Val Loss = 16.26759
2024-03-21 10:30:19.724637 Epoch 40  	Train Loss = 12.17055 Val Loss = 16.14070
2024-03-21 10:31:38.302477 Epoch 41  	Train Loss = 12.17580 Val Loss = 15.55957
2024-03-21 10:32:55.939880 Epoch 42  	Train Loss = 12.07458 Val Loss = 16.05746
2024-03-21 10:34:12.818717 Epoch 43  	Train Loss = 12.13560 Val Loss = 16.22442
2024-03-21 10:35:29.497701 Epoch 44  	Train Loss = 12.05266 Val Loss = 16.47481
2024-03-21 10:36:46.220250 Epoch 45  	Train Loss = 12.00678 Val Loss = 17.39484
2024-03-21 10:38:04.705325 Epoch 46  	Train Loss = 12.01192 Val Loss = 16.55502
2024-03-21 10:39:21.980405 Epoch 47  	Train Loss = 11.97520 Val Loss = 15.78573
2024-03-21 10:40:38.765200 Epoch 48  	Train Loss = 11.97138 Val Loss = 15.75171
2024-03-21 10:41:54.482919 Epoch 49  	Train Loss = 11.91653 Val Loss = 16.04528
2024-03-21 10:43:11.150940 Epoch 50  	Train Loss = 11.93611 Val Loss = 15.63462
2024-03-21 10:44:28.074387 Epoch 51  	Train Loss = 11.87015 Val Loss = 15.62974
2024-03-21 10:45:45.759002 Epoch 52  	Train Loss = 11.84262 Val Loss = 15.82657
2024-03-21 10:47:02.328989 Epoch 53  	Train Loss = 11.82991 Val Loss = 15.81502
2024-03-21 10:48:18.668527 Epoch 54  	Train Loss = 11.85119 Val Loss = 15.64982
2024-03-21 10:49:36.793187 Epoch 55  	Train Loss = 11.77846 Val Loss = 17.10693
2024-03-21 10:50:53.733565 Epoch 56  	Train Loss = 11.88055 Val Loss = 15.48152
2024-03-21 10:52:10.195613 Epoch 57  	Train Loss = 11.77176 Val Loss = 15.90927
2024-03-21 10:53:28.769358 Epoch 58  	Train Loss = 11.79058 Val Loss = 15.39522
2024-03-21 10:54:46.407363 Epoch 59  	Train Loss = 11.82734 Val Loss = 15.97821
2024-03-21 10:56:05.257575 Epoch 60  	Train Loss = 11.77848 Val Loss = 15.45418
2024-03-21 10:57:23.823748 Epoch 61  	Train Loss = 11.78934 Val Loss = 15.46385
2024-03-21 10:58:41.248452 Epoch 62  	Train Loss = 11.77532 Val Loss = 16.87460
2024-03-21 10:59:58.373704 Epoch 63  	Train Loss = 11.79811 Val Loss = 15.54888
2024-03-21 11:01:16.424534 Epoch 64  	Train Loss = 11.78758 Val Loss = 16.14851
2024-03-21 11:02:33.369268 Epoch 65  	Train Loss = 11.74917 Val Loss = 17.36111
2024-03-21 11:03:51.143853 Epoch 66  	Train Loss = 11.84879 Val Loss = 15.46569
2024-03-21 11:05:07.963586 Epoch 67  	Train Loss = 11.70743 Val Loss = 15.34026
2024-03-21 11:06:24.323450 Epoch 68  	Train Loss = 11.76898 Val Loss = 15.71973
2024-03-21 11:07:40.606785 Epoch 69  	Train Loss = 11.81132 Val Loss = 15.72584
2024-03-21 11:08:57.001413 Epoch 70  	Train Loss = 11.74981 Val Loss = 15.53898
2024-03-21 11:10:14.512094 Epoch 71  	Train Loss = 11.74756 Val Loss = 15.95897
2024-03-21 11:11:31.680853 Epoch 72  	Train Loss = 11.76705 Val Loss = 15.66948
2024-03-21 11:12:47.573748 Epoch 73  	Train Loss = 12.03229 Val Loss = 15.48545
2024-03-21 11:14:04.058185 Epoch 74  	Train Loss = 11.73314 Val Loss = 15.79420
2024-03-21 11:15:20.591612 Epoch 75  	Train Loss = 11.79004 Val Loss = 15.98546
2024-03-21 11:16:37.339514 Epoch 76  	Train Loss = 11.77530 Val Loss = 15.88975
2024-03-21 11:17:53.697469 Epoch 77  	Train Loss = 11.78071 Val Loss = 18.84754
2024-03-21 11:19:10.788693 Epoch 78  	Train Loss = 11.93646 Val Loss = 15.44691
2024-03-21 11:20:27.248975 Epoch 79  	Train Loss = 11.89271 Val Loss = 15.62283
2024-03-21 11:21:42.985441 Epoch 80  	Train Loss = 12.12540 Val Loss = 15.55503
2024-03-21 11:22:59.412836 Epoch 81  	Train Loss = 11.67411 Val Loss = 15.01615
2024-03-21 11:24:16.177307 Epoch 82  	Train Loss = 11.66618 Val Loss = 15.03491
2024-03-21 11:25:31.986440 Epoch 83  	Train Loss = 11.65670 Val Loss = 15.00549
2024-03-21 11:26:47.372500 Epoch 84  	Train Loss = 11.70571 Val Loss = 15.01544
2024-03-21 11:28:03.022659 Epoch 85  	Train Loss = 11.74958 Val Loss = 15.24371
2024-03-21 11:29:19.519987 Epoch 86  	Train Loss = 11.71853 Val Loss = 15.07982
2024-03-21 11:30:36.921016 Epoch 87  	Train Loss = 11.81764 Val Loss = 15.16464
2024-03-21 11:31:54.155049 Epoch 88  	Train Loss = 11.83220 Val Loss = 15.20241
2024-03-21 11:33:09.608511 Epoch 89  	Train Loss = 11.81943 Val Loss = 15.09199
2024-03-21 11:34:25.672964 Epoch 90  	Train Loss = 11.88166 Val Loss = 15.32313
2024-03-21 11:35:41.569135 Epoch 91  	Train Loss = 12.00819 Val Loss = 15.60168
2024-03-21 11:36:56.805048 Epoch 92  	Train Loss = 11.97936 Val Loss = 15.26582
2024-03-21 11:38:11.927447 Epoch 93  	Train Loss = 11.92687 Val Loss = 15.07817
2024-03-21 11:39:27.576475 Epoch 94  	Train Loss = 12.01748 Val Loss = 15.07988
2024-03-21 11:40:44.877150 Epoch 95  	Train Loss = 12.09116 Val Loss = 15.17165
2024-03-21 11:42:03.686410 Epoch 96  	Train Loss = 12.07054 Val Loss = 15.01904
2024-03-21 11:43:20.021998 Epoch 97  	Train Loss = 12.16079 Val Loss = 15.18065
2024-03-21 11:44:35.283156 Epoch 98  	Train Loss = 12.15374 Val Loss = 15.65405
2024-03-21 11:45:50.578763 Epoch 99  	Train Loss = 12.22591 Val Loss = 15.21819
2024-03-21 11:47:08.449464 Epoch 100  	Train Loss = 12.25062 Val Loss = 15.96289
2024-03-21 11:48:25.539808 Epoch 101  	Train Loss = 12.26482 Val Loss = 15.25943
2024-03-21 11:49:41.718938 Epoch 102  	Train Loss = 12.27569 Val Loss = 15.34712
2024-03-21 11:50:58.808816 Epoch 103  	Train Loss = 12.31892 Val Loss = 15.14502
Early stopping at epoch: 103
Best at epoch 83:
Train Loss = 11.65670
Train RMSE = 23.03633, MAE = 13.72770, MAPE = 8.85025
Val Loss = 15.00549
Val RMSE = 25.30037, MAE = 15.45574, MAPE = 11.20572
--------- Test ---------
All Steps RMSE = 24.34791, MAE = 15.31831, MAPE = 9.78834
Step 1 RMSE = 19.85847, MAE = 12.88660, MAPE = 8.42492
Step 2 RMSE = 21.29726, MAE = 13.67591, MAPE = 8.81522
Step 3 RMSE = 22.25612, MAE = 14.18317, MAPE = 9.09038
Step 4 RMSE = 23.08833, MAE = 14.60046, MAPE = 9.33295
Step 5 RMSE = 23.79604, MAE = 14.98413, MAPE = 9.55998
Step 6 RMSE = 24.41056, MAE = 15.32219, MAPE = 9.77108
Step 7 RMSE = 24.96875, MAE = 15.65218, MAPE = 9.96478
Step 8 RMSE = 25.46167, MAE = 15.95999, MAPE = 10.15051
Step 9 RMSE = 25.86562, MAE = 16.22655, MAPE = 10.31808
Step 10 RMSE = 26.25941, MAE = 16.49155, MAPE = 10.48722
Step 11 RMSE = 26.64468, MAE = 16.76005, MAPE = 10.66470
Step 12 RMSE = 27.11321, MAE = 17.07702, MAPE = 10.88030
Inference time: 9.84 s
