ELECTRICITY
Trainset:	x-(17674, 336, 321, 1)	y-(17674, 720, 321, 1)
Valset:  	x-(2525, 336, 321, 1)  	y-(2525, 720, 321, 1)
Testset:	x-(5050, 336, 321, 1)	y-(5050, 720, 321, 1)
INFO: Using scaled X and Y, only for LTSF!

Random seed = 233
--------- PatchTST ---------
{
    "num_nodes": 321,
    "in_steps": 336,
    "out_steps": 720,
    "lr": 0.0001,
    "weight_decay": 0,
    "milestones": [
        30,
        50
    ],
    "lr_decay_rate": 0.1,
    "clip_grad": 0,
    "batch_size": 32,
    "max_epochs": 200,
    "dataloader": "ltsf",
    "runner": "ltsf",
    "loss": "mse",
    "model_args": {
        "enc_in": 321,
        "seq_len": 336,
        "pred_len": 720,
        "e_layers": 3,
        "n_heads": 16,
        "d_model": 128,
        "d_ff": 256,
        "dropout": 0.2,
        "fc_dropout": 0.2,
        "head_dropout": 0,
        "patch_len": 16,
        "stride": 8,
        "individual": 0,
        "padding_patch": "end",
        "revin": 1,
        "affine": 0,
        "subtract_last": 0,
        "decomposition": 0,
        "kernel_size": 25
    }
}
========================================================================================================================
Layer (type:depth-idx)                                                 Output Shape              Param #
========================================================================================================================
PatchTST                                                               [32, 720, 321, 1]         --
├─PatchTST_backbone: 1-1                                               [32, 321, 720]            --
│    └─RevIN: 2-1                                                      [32, 336, 321]            --
│    └─ReplicationPad1d: 2-2                                           [32, 321, 344]            --
│    └─TSTiEncoder: 2-3                                                [32, 321, 128, 42]        5,376
│    │    └─Linear: 3-1                                                [32, 321, 42, 128]        2,176
│    │    └─Dropout: 3-2                                               [10272, 42, 128]          --
│    │    └─TSTEncoder: 3-3                                            [10272, 42, 128]          397,443
│    └─Flatten_Head: 2-4                                               [32, 321, 720]            --
│    │    └─Flatten: 3-4                                               [32, 321, 5376]           --
│    │    └─Linear: 3-5                                                [32, 321, 720]            3,871,440
│    │    └─Dropout: 3-6                                               [32, 321, 720]            --
│    └─RevIN: 2-5                                                      [32, 720, 321]            --
========================================================================================================================
Total params: 4,276,435
Trainable params: 4,276,432
Non-trainable params: 3
Total mult-adds (G): 4.21
========================================================================================================================
Input size (MB): 13.81
Forward/backward pass size (MB): 12428.96
Params size (MB): 17.08
Estimated Total Size (MB): 12459.85
========================================================================================================================

Loss: MSELoss

2024-04-03 09:57:02.036087 Epoch 1  	Train Loss = 0.27402 Val Loss = 0.17702
2024-04-03 10:01:53.146371 Epoch 2  	Train Loss = 0.24308 Val Loss = 0.17791
2024-04-03 10:06:44.279602 Epoch 3  	Train Loss = 0.23801 Val Loss = 0.17343
2024-04-03 10:11:35.660059 Epoch 4  	Train Loss = 0.23453 Val Loss = 0.17252
2024-04-03 10:16:26.818878 Epoch 5  	Train Loss = 0.23167 Val Loss = 0.17243
2024-04-03 10:21:17.920907 Epoch 6  	Train Loss = 0.22943 Val Loss = 0.17312
2024-04-03 10:26:09.124921 Epoch 7  	Train Loss = 0.22800 Val Loss = 0.17147
2024-04-03 10:31:00.584556 Epoch 8  	Train Loss = 0.22633 Val Loss = 0.17255
2024-04-03 10:35:51.866209 Epoch 9  	Train Loss = 0.22484 Val Loss = 0.17329
2024-04-03 10:40:43.140938 Epoch 10  	Train Loss = 0.22384 Val Loss = 0.17216
2024-04-03 10:45:34.235912 Epoch 11  	Train Loss = 0.22235 Val Loss = 0.17144
2024-04-03 10:50:25.484778 Epoch 12  	Train Loss = 0.22144 Val Loss = 0.17095
2024-04-03 10:55:16.729047 Epoch 13  	Train Loss = 0.22010 Val Loss = 0.17150
2024-04-03 11:00:07.894289 Epoch 14  	Train Loss = 0.21937 Val Loss = 0.16995
2024-04-03 11:04:59.067093 Epoch 15  	Train Loss = 0.21826 Val Loss = 0.16941
2024-04-03 11:09:50.771341 Epoch 16  	Train Loss = 0.21723 Val Loss = 0.17036
2024-04-03 11:14:41.955578 Epoch 17  	Train Loss = 0.21636 Val Loss = 0.16996
2024-04-03 11:19:33.468742 Epoch 18  	Train Loss = 0.21536 Val Loss = 0.16906
2024-04-03 11:24:24.984542 Epoch 19  	Train Loss = 0.21464 Val Loss = 0.16849
2024-04-03 11:29:16.522056 Epoch 20  	Train Loss = 0.21380 Val Loss = 0.16777
2024-04-03 11:34:08.086978 Epoch 21  	Train Loss = 0.21310 Val Loss = 0.16917
2024-04-03 11:38:59.556217 Epoch 22  	Train Loss = 0.21247 Val Loss = 0.16898
2024-04-03 11:43:50.928700 Epoch 23  	Train Loss = 0.21169 Val Loss = 0.16728
2024-04-03 11:48:42.138352 Epoch 24  	Train Loss = 0.21090 Val Loss = 0.16704
2024-04-03 11:53:33.368990 Epoch 25  	Train Loss = 0.21051 Val Loss = 0.16888
2024-04-03 11:58:24.753580 Epoch 26  	Train Loss = 0.20971 Val Loss = 0.16802
2024-04-03 12:03:16.139462 Epoch 27  	Train Loss = 0.20922 Val Loss = 0.16684
2024-04-03 12:08:07.331462 Epoch 28  	Train Loss = 0.20852 Val Loss = 0.16691
2024-04-03 12:12:58.500330 Epoch 29  	Train Loss = 0.20802 Val Loss = 0.16622
2024-04-03 12:17:49.846391 Epoch 30  	Train Loss = 0.20740 Val Loss = 0.16697
2024-04-03 12:22:41.279446 Epoch 31  	Train Loss = 0.20507 Val Loss = 0.16571
2024-04-03 12:27:32.555049 Epoch 32  	Train Loss = 0.20476 Val Loss = 0.16558
2024-04-03 12:32:23.878851 Epoch 33  	Train Loss = 0.20472 Val Loss = 0.16601
2024-04-03 12:37:15.250233 Epoch 34  	Train Loss = 0.20467 Val Loss = 0.16573
2024-04-03 12:42:06.667780 Epoch 35  	Train Loss = 0.20450 Val Loss = 0.16519
2024-04-03 12:46:57.948715 Epoch 36  	Train Loss = 0.20446 Val Loss = 0.16601
2024-04-03 12:51:49.081118 Epoch 37  	Train Loss = 0.20444 Val Loss = 0.16634
2024-04-03 12:56:40.232061 Epoch 38  	Train Loss = 0.20433 Val Loss = 0.16621
2024-04-03 13:01:31.364738 Epoch 39  	Train Loss = 0.20432 Val Loss = 0.16580
2024-04-03 13:06:22.463379 Epoch 40  	Train Loss = 0.20420 Val Loss = 0.16604
2024-04-03 13:11:13.581770 Epoch 41  	Train Loss = 0.20420 Val Loss = 0.16645
2024-04-03 13:16:05.141302 Epoch 42  	Train Loss = 0.20425 Val Loss = 0.16623
2024-04-03 13:20:56.216121 Epoch 43  	Train Loss = 0.20415 Val Loss = 0.16586
2024-04-03 13:25:47.224509 Epoch 44  	Train Loss = 0.20405 Val Loss = 0.16538
2024-04-03 13:30:38.399540 Epoch 45  	Train Loss = 0.20398 Val Loss = 0.16597
Early stopping at epoch: 45
Best at epoch 35:
Train Loss = 0.20450
Train MSE = 0.19899, MAE = 0.28730
Val Loss = 0.16519
Val MSE = 0.16521, MAE = 0.25508
Model checkpoint saved to: ../saved_models/PatchTST/PatchTST-ELECTRICITY-2024-04-03-09-51-28.pt
--------- Test ---------
All Steps (1-720) MSE = 0.19917, MAE = 0.28911
Inference time: 37.82 s
