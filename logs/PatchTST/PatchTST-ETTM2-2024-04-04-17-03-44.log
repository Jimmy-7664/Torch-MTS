ETTM2
Trainset:	x-(34157, 336, 7, 1)	y-(34157, 336, 7, 1)
Valset:  	x-(11386, 336, 7, 1)  	y-(11386, 336, 7, 1)
Testset:	x-(11386, 336, 7, 1)	y-(11386, 336, 7, 1)
INFO: Using scaled X and Y, only for LTSF!

Random seed = 233
--------- PatchTST ---------
{
    "num_nodes": 7,
    "in_steps": 336,
    "out_steps": 336,
    "lr": 0.0001,
    "weight_decay": 0,
    "milestones": [
        10
    ],
    "lr_decay_rate": 0.1,
    "clip_grad": 0,
    "batch_size": 64,
    "max_epochs": 200,
    "dataloader": "ltsf",
    "runner": "ltsf",
    "loss": "mse",
    "model_args": {
        "enc_in": 7,
        "seq_len": 336,
        "pred_len": 336,
        "e_layers": 3,
        "n_heads": 16,
        "d_model": 128,
        "d_ff": 256,
        "dropout": 0.2,
        "fc_dropout": 0.2,
        "head_dropout": 0,
        "patch_len": 16,
        "stride": 8,
        "individual": 0,
        "padding_patch": "end",
        "revin": 1,
        "affine": 0,
        "subtract_last": 0,
        "decomposition": 0,
        "kernel_size": 25
    }
}
========================================================================================================================
Layer (type:depth-idx)                                                 Output Shape              Param #
========================================================================================================================
PatchTST                                                               [64, 336, 7, 1]           --
├─PatchTST_backbone: 1-1                                               [64, 7, 336]              --
│    └─RevIN: 2-1                                                      [64, 336, 7]              --
│    └─ReplicationPad1d: 2-2                                           [64, 7, 344]              --
│    └─TSTiEncoder: 2-3                                                [64, 7, 128, 42]          5,376
│    │    └─Linear: 3-1                                                [64, 7, 42, 128]          2,176
│    │    └─Dropout: 3-2                                               [448, 42, 128]            --
│    │    └─TSTEncoder: 3-3                                            [448, 42, 128]            397,443
│    └─Flatten_Head: 2-4                                               [64, 7, 336]              --
│    │    └─Flatten: 3-4                                               [64, 7, 5376]             --
│    │    └─Linear: 3-5                                                [64, 7, 336]              1,806,672
│    │    └─Dropout: 3-6                                               [64, 7, 336]              --
│    └─RevIN: 2-5                                                      [64, 336, 7]              --
========================================================================================================================
Total params: 2,211,667
Trainable params: 2,211,664
Non-trainable params: 3
Total mult-adds (M): 293.82
========================================================================================================================
Input size (MB): 0.60
Forward/backward pass size (MB): 540.70
Params size (MB): 8.83
Estimated Total Size (MB): 550.12
========================================================================================================================

Loss: MSELoss

2024-04-04 17:04:02.284021 Epoch 1  	Train Loss = 0.39754 Val Loss = 0.21851
2024-04-04 17:04:17.505917 Epoch 2  	Train Loss = 0.33313 Val Loss = 0.22406
2024-04-04 17:04:32.689348 Epoch 3  	Train Loss = 0.30800 Val Loss = 0.22241
2024-04-04 17:04:47.917549 Epoch 4  	Train Loss = 0.29435 Val Loss = 0.22389
2024-04-04 17:05:03.120820 Epoch 5  	Train Loss = 0.28511 Val Loss = 0.22197
2024-04-04 17:05:18.261452 Epoch 6  	Train Loss = 0.27841 Val Loss = 0.22605
2024-04-04 17:05:33.643011 Epoch 7  	Train Loss = 0.27109 Val Loss = 0.22401
2024-04-04 17:05:48.881562 Epoch 8  	Train Loss = 0.26519 Val Loss = 0.22354
2024-04-04 17:06:04.022707 Epoch 9  	Train Loss = 0.25990 Val Loss = 0.22251
2024-04-04 17:06:19.191727 Epoch 10  	Train Loss = 0.25498 Val Loss = 0.23002
2024-04-04 17:06:34.396016 Epoch 11  	Train Loss = 0.24732 Val Loss = 0.22645
Early stopping at epoch: 11
Best at epoch 1:
Train Loss = 0.39754
Train MSE = 0.35028, MAE = 0.34273
Val Loss = 0.21851
Val MSE = 0.21851, MAE = 0.31919
Model checkpoint saved to: ../saved_models/PatchTST/PatchTST-ETTM2-2024-04-04-17-03-44.pt
--------- Test ---------
All Steps (1-336) MSE = 0.28602, MAE = 0.33888
Inference time: 1.57 s
