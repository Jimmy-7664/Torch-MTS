ETTH2
Trainset:	x-(8237, 336, 7, 1)	y-(8237, 336, 7, 1)
Valset:  	x-(2746, 336, 7, 1)  	y-(2746, 336, 7, 1)
Testset:	x-(2746, 336, 7, 1)	y-(2746, 336, 7, 1)
INFO: Using scaled X and Y, only for LTSF!

Random seed = 233
--------- PatchTST ---------
{
    "num_nodes": 7,
    "in_steps": 336,
    "out_steps": 336,
    "lr": 0.0001,
    "weight_decay": 0,
    "milestones": [
        10
    ],
    "lr_decay_rate": 0.1,
    "clip_grad": 0,
    "batch_size": 64,
    "max_epochs": 200,
    "dataloader": "ltsf",
    "runner": "ltsf",
    "loss": "mse",
    "model_args": {
        "enc_in": 7,
        "seq_len": 336,
        "pred_len": 336,
        "e_layers": 3,
        "n_heads": 4,
        "d_model": 16,
        "d_ff": 128,
        "dropout": 0.3,
        "fc_dropout": 0.3,
        "head_dropout": 0,
        "patch_len": 16,
        "stride": 8,
        "individual": 0,
        "padding_patch": "end",
        "revin": 1,
        "affine": 0,
        "subtract_last": 0,
        "decomposition": 0,
        "kernel_size": 25
    }
}
========================================================================================================================
Layer (type:depth-idx)                                                 Output Shape              Param #
========================================================================================================================
PatchTST                                                               [64, 336, 7, 1]           --
├─PatchTST_backbone: 1-1                                               [64, 7, 336]              --
│    └─RevIN: 2-1                                                      [64, 336, 7]              --
│    └─ReplicationPad1d: 2-2                                           [64, 7, 344]              --
│    └─TSTiEncoder: 2-3                                                [64, 7, 16, 42]           672
│    │    └─Linear: 3-1                                                [64, 7, 42, 16]           272
│    │    └─Dropout: 3-2                                               [448, 42, 16]             --
│    │    └─TSTEncoder: 3-3                                            [448, 42, 16]             16,179
│    └─Flatten_Head: 2-4                                               [64, 7, 336]              --
│    │    └─Flatten: 3-4                                               [64, 7, 672]              --
│    │    └─Linear: 3-5                                                [64, 7, 336]              226,128
│    │    └─Dropout: 3-6                                               [64, 7, 336]              --
│    └─RevIN: 2-5                                                      [64, 336, 7]              --
========================================================================================================================
Total params: 243,251
Trainable params: 243,248
Non-trainable params: 3
Total mult-adds (M): 21.74
========================================================================================================================
Input size (MB): 0.60
Forward/backward pass size (MB): 111.99
Params size (MB): 0.97
Estimated Total Size (MB): 113.57
========================================================================================================================

Loss: MSELoss

2024-04-04 16:40:24.622269 Epoch 1  	Train Loss = 0.70960 Val Loss = 0.38176
2024-04-04 16:40:27.426849 Epoch 2  	Train Loss = 0.64163 Val Loss = 0.36595
2024-04-04 16:40:30.246912 Epoch 3  	Train Loss = 0.62351 Val Loss = 0.36058
2024-04-04 16:40:33.058834 Epoch 4  	Train Loss = 0.61123 Val Loss = 0.35614
2024-04-04 16:40:35.824998 Epoch 5  	Train Loss = 0.60392 Val Loss = 0.35600
2024-04-04 16:40:38.571716 Epoch 6  	Train Loss = 0.59526 Val Loss = 0.35674
2024-04-04 16:40:41.180021 Epoch 7  	Train Loss = 0.58714 Val Loss = 0.35612
2024-04-04 16:40:43.925826 Epoch 8  	Train Loss = 0.58289 Val Loss = 0.35519
2024-04-04 16:40:46.824092 Epoch 9  	Train Loss = 0.57863 Val Loss = 0.35547
2024-04-04 16:40:49.585062 Epoch 10  	Train Loss = 0.57505 Val Loss = 0.35421
2024-04-04 16:40:52.442189 Epoch 11  	Train Loss = 0.57228 Val Loss = 0.35399
2024-04-04 16:40:55.204369 Epoch 12  	Train Loss = 0.57219 Val Loss = 0.35355
2024-04-04 16:40:57.850079 Epoch 13  	Train Loss = 0.57125 Val Loss = 0.35382
2024-04-04 16:41:00.584504 Epoch 14  	Train Loss = 0.57105 Val Loss = 0.35282
2024-04-04 16:41:03.297158 Epoch 15  	Train Loss = 0.57060 Val Loss = 0.35296
2024-04-04 16:41:05.999979 Epoch 16  	Train Loss = 0.57041 Val Loss = 0.35282
2024-04-04 16:41:08.738925 Epoch 17  	Train Loss = 0.57072 Val Loss = 0.35251
2024-04-04 16:41:11.549890 Epoch 18  	Train Loss = 0.57056 Val Loss = 0.35256
2024-04-04 16:41:14.361003 Epoch 19  	Train Loss = 0.57101 Val Loss = 0.35208
2024-04-04 16:41:17.140671 Epoch 20  	Train Loss = 0.56881 Val Loss = 0.35274
2024-04-04 16:41:19.826163 Epoch 21  	Train Loss = 0.56879 Val Loss = 0.35223
2024-04-04 16:41:22.626266 Epoch 22  	Train Loss = 0.56972 Val Loss = 0.35232
2024-04-04 16:41:25.419177 Epoch 23  	Train Loss = 0.56920 Val Loss = 0.35220
2024-04-04 16:41:28.162961 Epoch 24  	Train Loss = 0.56797 Val Loss = 0.35246
2024-04-04 16:41:30.879981 Epoch 25  	Train Loss = 0.56840 Val Loss = 0.35190
2024-04-04 16:41:33.604617 Epoch 26  	Train Loss = 0.56830 Val Loss = 0.35181
2024-04-04 16:41:36.381925 Epoch 27  	Train Loss = 0.56805 Val Loss = 0.35189
2024-04-04 16:41:39.146277 Epoch 28  	Train Loss = 0.56788 Val Loss = 0.35210
2024-04-04 16:41:42.041242 Epoch 29  	Train Loss = 0.56802 Val Loss = 0.35132
2024-04-04 16:41:44.811241 Epoch 30  	Train Loss = 0.56614 Val Loss = 0.35149
2024-04-04 16:41:47.673338 Epoch 31  	Train Loss = 0.56688 Val Loss = 0.35119
2024-04-04 16:41:50.320055 Epoch 32  	Train Loss = 0.56700 Val Loss = 0.35167
2024-04-04 16:41:53.011116 Epoch 33  	Train Loss = 0.56667 Val Loss = 0.35165
2024-04-04 16:41:55.663052 Epoch 34  	Train Loss = 0.56593 Val Loss = 0.35132
2024-04-04 16:41:58.238640 Epoch 35  	Train Loss = 0.56586 Val Loss = 0.35115
2024-04-04 16:42:00.928830 Epoch 36  	Train Loss = 0.56549 Val Loss = 0.35071
2024-04-04 16:42:03.670127 Epoch 37  	Train Loss = 0.56553 Val Loss = 0.35061
2024-04-04 16:42:06.323299 Epoch 38  	Train Loss = 0.56520 Val Loss = 0.35109
2024-04-04 16:42:08.929924 Epoch 39  	Train Loss = 0.56532 Val Loss = 0.35079
2024-04-04 16:42:11.511042 Epoch 40  	Train Loss = 0.56500 Val Loss = 0.35139
2024-04-04 16:42:14.237308 Epoch 41  	Train Loss = 0.56412 Val Loss = 0.35039
2024-04-04 16:42:16.865265 Epoch 42  	Train Loss = 0.56475 Val Loss = 0.35080
2024-04-04 16:42:19.619720 Epoch 43  	Train Loss = 0.56490 Val Loss = 0.34974
2024-04-04 16:42:22.385383 Epoch 44  	Train Loss = 0.56396 Val Loss = 0.35035
2024-04-04 16:42:25.030719 Epoch 45  	Train Loss = 0.56256 Val Loss = 0.35047
2024-04-04 16:42:27.835596 Epoch 46  	Train Loss = 0.56320 Val Loss = 0.35120
2024-04-04 16:42:30.699880 Epoch 47  	Train Loss = 0.56298 Val Loss = 0.35026
2024-04-04 16:42:33.399550 Epoch 48  	Train Loss = 0.56387 Val Loss = 0.35001
2024-04-04 16:42:36.296880 Epoch 49  	Train Loss = 0.56271 Val Loss = 0.35043
2024-04-04 16:42:39.079718 Epoch 50  	Train Loss = 0.56299 Val Loss = 0.35016
2024-04-04 16:42:41.927985 Epoch 51  	Train Loss = 0.56245 Val Loss = 0.34985
2024-04-04 16:42:44.679209 Epoch 52  	Train Loss = 0.56157 Val Loss = 0.35003
2024-04-04 16:42:47.480182 Epoch 53  	Train Loss = 0.56137 Val Loss = 0.35017
Early stopping at epoch: 53
Best at epoch 43:
Train Loss = 0.56490
Train MSE = 0.55380, MAE = 0.42904
Val Loss = 0.34974
Val MSE = 0.35012, MAE = 0.40334
Model checkpoint saved to: ../saved_models/PatchTST/PatchTST-ETTH2-2024-04-04-16-40-20.pt
--------- Test ---------
All Steps (1-336) MSE = 0.35594, MAE = 0.39015
Inference time: 0.17 s
