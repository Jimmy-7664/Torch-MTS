ETTH1
Trainset:	x-(8324, 336, 7, 1)	y-(8324, 192, 7, 1)
Valset:  	x-(2775, 336, 7, 1)  	y-(2775, 192, 7, 1)
Testset:	x-(2774, 336, 7, 1)	y-(2774, 192, 7, 1)
INFO: Using scaled X and Y, only for LTSF!

Random seed = 233
--------- PatchTST ---------
{
    "num_nodes": 7,
    "in_steps": 336,
    "out_steps": 192,
    "lr": 0.0001,
    "weight_decay": 0,
    "milestones": [
        10
    ],
    "lr_decay_rate": 0.1,
    "clip_grad": 0,
    "batch_size": 64,
    "max_epochs": 200,
    "dataloader": "ltsf",
    "runner": "ltsf",
    "loss": "mse",
    "model_args": {
        "enc_in": 7,
        "seq_len": 336,
        "pred_len": 192,
        "e_layers": 3,
        "n_heads": 4,
        "d_model": 16,
        "d_ff": 128,
        "dropout": 0.3,
        "fc_dropout": 0.3,
        "head_dropout": 0,
        "patch_len": 16,
        "stride": 8,
        "individual": 0,
        "padding_patch": "end",
        "revin": 1,
        "affine": 0,
        "subtract_last": 0,
        "decomposition": 0,
        "kernel_size": 25
    }
}
========================================================================================================================
Layer (type:depth-idx)                                                 Output Shape              Param #
========================================================================================================================
PatchTST                                                               [64, 192, 7, 1]           --
├─PatchTST_backbone: 1-1                                               [64, 7, 192]              --
│    └─RevIN: 2-1                                                      [64, 336, 7]              --
│    └─ReplicationPad1d: 2-2                                           [64, 7, 344]              --
│    └─TSTiEncoder: 2-3                                                [64, 7, 16, 42]           672
│    │    └─Linear: 3-1                                                [64, 7, 42, 16]           272
│    │    └─Dropout: 3-2                                               [448, 42, 16]             --
│    │    └─TSTEncoder: 3-3                                            [448, 42, 16]             16,179
│    └─Flatten_Head: 2-4                                               [64, 7, 192]              --
│    │    └─Flatten: 3-4                                               [64, 7, 672]              --
│    │    └─Linear: 3-5                                                [64, 7, 192]              129,216
│    │    └─Dropout: 3-6                                               [64, 7, 192]              --
│    └─RevIN: 2-5                                                      [64, 192, 7]              --
========================================================================================================================
Total params: 146,339
Trainable params: 146,336
Non-trainable params: 3
Total mult-adds (M): 15.53
========================================================================================================================
Input size (MB): 0.60
Forward/backward pass size (MB): 111.48
Params size (MB): 0.58
Estimated Total Size (MB): 112.66
========================================================================================================================

Loss: MSELoss

2024-04-04 16:32:58.634010 Epoch 1  	Train Loss = 0.56070 Val Loss = 0.98912
2024-04-04 16:33:01.238356 Epoch 2  	Train Loss = 0.45825 Val Loss = 0.92291
2024-04-04 16:33:03.660235 Epoch 3  	Train Loss = 0.43097 Val Loss = 0.90894
2024-04-04 16:33:06.168033 Epoch 4  	Train Loss = 0.42133 Val Loss = 0.90296
2024-04-04 16:33:08.651436 Epoch 5  	Train Loss = 0.41718 Val Loss = 0.90300
2024-04-04 16:33:11.325121 Epoch 6  	Train Loss = 0.41325 Val Loss = 0.90095
2024-04-04 16:33:14.004761 Epoch 7  	Train Loss = 0.41170 Val Loss = 0.89841
2024-04-04 16:33:16.750716 Epoch 8  	Train Loss = 0.40792 Val Loss = 0.89765
2024-04-04 16:33:19.616070 Epoch 9  	Train Loss = 0.40659 Val Loss = 0.89761
2024-04-04 16:33:22.433462 Epoch 10  	Train Loss = 0.40488 Val Loss = 0.90779
2024-04-04 16:33:25.284854 Epoch 11  	Train Loss = 0.40386 Val Loss = 0.90303
2024-04-04 16:33:28.092990 Epoch 12  	Train Loss = 0.40330 Val Loss = 0.90051
2024-04-04 16:33:30.826932 Epoch 13  	Train Loss = 0.40298 Val Loss = 0.90046
2024-04-04 16:33:33.523440 Epoch 14  	Train Loss = 0.40220 Val Loss = 0.89846
2024-04-04 16:33:36.338447 Epoch 15  	Train Loss = 0.40114 Val Loss = 0.89768
2024-04-04 16:33:39.165503 Epoch 16  	Train Loss = 0.40304 Val Loss = 0.89731
2024-04-04 16:33:41.946275 Epoch 17  	Train Loss = 0.40257 Val Loss = 0.89730
2024-04-04 16:33:44.750216 Epoch 18  	Train Loss = 0.40173 Val Loss = 0.89708
2024-04-04 16:33:47.741217 Epoch 19  	Train Loss = 0.40212 Val Loss = 0.89705
2024-04-04 16:33:50.542718 Epoch 20  	Train Loss = 0.40099 Val Loss = 0.89693
2024-04-04 16:33:53.398450 Epoch 21  	Train Loss = 0.40283 Val Loss = 0.89693
2024-04-04 16:33:56.421291 Epoch 22  	Train Loss = 0.40283 Val Loss = 0.89631
2024-04-04 16:33:59.325216 Epoch 23  	Train Loss = 0.40126 Val Loss = 0.89611
2024-04-04 16:34:02.174564 Epoch 24  	Train Loss = 0.40046 Val Loss = 0.89622
2024-04-04 16:34:05.059024 Epoch 25  	Train Loss = 0.40046 Val Loss = 0.89673
2024-04-04 16:34:07.941803 Epoch 26  	Train Loss = 0.40033 Val Loss = 0.89664
2024-04-04 16:34:10.634859 Epoch 27  	Train Loss = 0.39974 Val Loss = 0.89716
2024-04-04 16:34:13.380866 Epoch 28  	Train Loss = 0.39944 Val Loss = 0.89642
2024-04-04 16:34:16.154289 Epoch 29  	Train Loss = 0.40135 Val Loss = 0.89715
2024-04-04 16:34:19.045957 Epoch 30  	Train Loss = 0.39974 Val Loss = 0.89820
2024-04-04 16:34:21.821189 Epoch 31  	Train Loss = 0.40004 Val Loss = 0.89691
2024-04-04 16:34:24.610101 Epoch 32  	Train Loss = 0.40087 Val Loss = 0.89667
2024-04-04 16:34:27.500775 Epoch 33  	Train Loss = 0.39975 Val Loss = 0.89688
Early stopping at epoch: 33
Best at epoch 23:
Train Loss = 0.40126
Train MSE = 0.39042, MAE = 0.43419
Val Loss = 0.89611
Val MSE = 0.90385, MAE = 0.63627
Model checkpoint saved to: ../saved_models/PatchTST/PatchTST-ETTH1-2024-04-04-16-32-54.pt
--------- Test ---------
All Steps (1-192) MSE = 0.40680, MAE = 0.41652
Inference time: 0.18 s
