ELECTRICITY
Trainset:	x-(17674, 336, 321, 1)	y-(17674, 720, 321, 1)
Valset:  	x-(2525, 336, 321, 1)  	y-(2525, 720, 321, 1)
Testset:	x-(5050, 336, 321, 1)	y-(5050, 720, 321, 1)
INFO: Using scaled X and Y, only for LTSF!

Random seed = 233
--------- PatchTST ---------
{
    "num_nodes": 321,
    "in_steps": 336,
    "out_steps": 720,
    "lr": 0.0001,
    "weight_decay": 0,
    "milestones": [
        20,
        30
    ],
    "lr_decay_rate": 0.1,
    "clip_grad": 0,
    "batch_size": 32,
    "max_epochs": 200,
    "dataloader": "ltsf",
    "runner": "ltsf",
    "loss": "mse",
    "model_args": {
        "enc_in": 321,
        "seq_len": 336,
        "pred_len": 720,
        "e_layers": 3,
        "n_heads": 16,
        "d_model": 128,
        "d_ff": 256,
        "dropout": 0.2,
        "fc_dropout": 0.2,
        "head_dropout": 0,
        "patch_len": 16,
        "stride": 8,
        "individual": 0,
        "padding_patch": "end",
        "revin": 1,
        "affine": 0,
        "subtract_last": 0,
        "decomposition": 0,
        "kernel_size": 25
    }
}
========================================================================================================================
Layer (type:depth-idx)                                                 Output Shape              Param #
========================================================================================================================
PatchTST                                                               [32, 720, 321, 1]         --
├─PatchTST_backbone: 1-1                                               [32, 321, 720]            --
│    └─RevIN: 2-1                                                      [32, 336, 321]            --
│    └─ReplicationPad1d: 2-2                                           [32, 321, 344]            --
│    └─TSTiEncoder: 2-3                                                [32, 321, 128, 42]        5,376
│    │    └─Linear: 3-1                                                [32, 321, 42, 128]        2,176
│    │    └─Dropout: 3-2                                               [10272, 42, 128]          --
│    │    └─TSTEncoder: 3-3                                            [10272, 42, 128]          397,443
│    └─Flatten_Head: 2-4                                               [32, 321, 720]            --
│    │    └─Flatten: 3-4                                               [32, 321, 5376]           --
│    │    └─Linear: 3-5                                                [32, 321, 720]            3,871,440
│    │    └─Dropout: 3-6                                               [32, 321, 720]            --
│    └─RevIN: 2-5                                                      [32, 720, 321]            --
========================================================================================================================
Total params: 4,276,435
Trainable params: 4,276,432
Non-trainable params: 3
Total mult-adds (G): 4.21
========================================================================================================================
Input size (MB): 13.81
Forward/backward pass size (MB): 12428.96
Params size (MB): 17.08
Estimated Total Size (MB): 12459.85
========================================================================================================================

Loss: MSELoss

2024-04-02 21:41:07.624936 Epoch 1  	Train Loss = 0.27402 Val Loss = 0.17702
2024-04-02 21:45:59.345810 Epoch 2  	Train Loss = 0.24308 Val Loss = 0.17791
2024-04-02 21:50:50.679317 Epoch 3  	Train Loss = 0.23801 Val Loss = 0.17343
2024-04-02 21:55:42.561273 Epoch 4  	Train Loss = 0.23453 Val Loss = 0.17252
2024-04-02 22:00:34.274765 Epoch 5  	Train Loss = 0.23167 Val Loss = 0.17243
2024-04-02 22:05:25.499391 Epoch 6  	Train Loss = 0.22943 Val Loss = 0.17312
2024-04-02 22:10:16.781131 Epoch 7  	Train Loss = 0.22800 Val Loss = 0.17147
2024-04-02 22:15:08.446337 Epoch 8  	Train Loss = 0.22633 Val Loss = 0.17255
2024-04-02 22:20:00.150564 Epoch 9  	Train Loss = 0.22484 Val Loss = 0.17329
2024-04-02 22:24:52.049172 Epoch 10  	Train Loss = 0.22384 Val Loss = 0.17216
2024-04-02 22:29:44.151544 Epoch 11  	Train Loss = 0.22235 Val Loss = 0.17144
2024-04-02 22:34:35.693293 Epoch 12  	Train Loss = 0.22144 Val Loss = 0.17095
2024-04-02 22:39:27.268046 Epoch 13  	Train Loss = 0.22010 Val Loss = 0.17150
2024-04-02 22:44:18.670039 Epoch 14  	Train Loss = 0.21937 Val Loss = 0.16995
2024-04-02 22:49:09.985931 Epoch 15  	Train Loss = 0.21826 Val Loss = 0.16941
2024-04-02 22:54:01.468380 Epoch 16  	Train Loss = 0.21723 Val Loss = 0.17036
2024-04-02 22:58:53.145129 Epoch 17  	Train Loss = 0.21636 Val Loss = 0.16996
2024-04-02 23:03:44.639252 Epoch 18  	Train Loss = 0.21536 Val Loss = 0.16906
2024-04-02 23:08:35.996929 Epoch 19  	Train Loss = 0.21464 Val Loss = 0.16849
2024-04-02 23:13:27.434969 Epoch 20  	Train Loss = 0.21380 Val Loss = 0.16777
2024-04-02 23:18:18.857609 Epoch 21  	Train Loss = 0.21077 Val Loss = 0.16629
2024-04-02 23:23:10.271210 Epoch 22  	Train Loss = 0.21055 Val Loss = 0.16645
2024-04-02 23:28:01.873326 Epoch 23  	Train Loss = 0.21044 Val Loss = 0.16629
2024-04-02 23:32:53.197228 Epoch 24  	Train Loss = 0.21028 Val Loss = 0.16613
2024-04-02 23:37:44.469450 Epoch 25  	Train Loss = 0.21030 Val Loss = 0.16631
2024-04-02 23:42:36.059601 Epoch 26  	Train Loss = 0.21017 Val Loss = 0.16549
2024-04-02 23:47:27.509163 Epoch 27  	Train Loss = 0.21013 Val Loss = 0.16645
2024-04-02 23:52:18.812698 Epoch 28  	Train Loss = 0.20999 Val Loss = 0.16573
2024-04-02 23:57:10.416284 Epoch 29  	Train Loss = 0.20991 Val Loss = 0.16617
2024-04-03 00:02:02.047813 Epoch 30  	Train Loss = 0.20980 Val Loss = 0.16588
2024-04-03 00:06:53.313036 Epoch 31  	Train Loss = 0.20952 Val Loss = 0.16579
2024-04-03 00:11:44.638447 Epoch 32  	Train Loss = 0.20945 Val Loss = 0.16585
2024-04-03 00:16:35.805740 Epoch 33  	Train Loss = 0.20947 Val Loss = 0.16578
2024-04-03 00:21:27.008964 Epoch 34  	Train Loss = 0.20945 Val Loss = 0.16587
2024-04-03 00:26:18.723461 Epoch 35  	Train Loss = 0.20937 Val Loss = 0.16580
2024-04-03 00:31:10.425419 Epoch 36  	Train Loss = 0.20939 Val Loss = 0.16577
Early stopping at epoch: 36
Best at epoch 26:
Train Loss = 0.21017
Train MSE = 0.20548, MAE = 0.29113
Val Loss = 0.16549
Val MSE = 0.16551, MAE = 0.25565
Model checkpoint saved to: ../saved_models/PatchTST/PatchTST-ELECTRICITY-2024-04-02-21-35-32.pt
--------- Test ---------
All Steps (1-720) MSE = 0.20024, MAE = 0.28966
Inference time: 38.93 s
