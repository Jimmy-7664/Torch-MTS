ELECTRICITY
Trainset:	x-(18044, 336, 321, 1)	y-(18044, 192, 321, 1)
Valset:  	x-(2578, 336, 321, 1)  	y-(2578, 192, 321, 1)
Testset:	x-(5155, 336, 321, 1)	y-(5155, 192, 321, 1)
INFO: Using scaled X and Y, only for LTSF!

Random seed = 233
--------- PatchTST ---------
{
    "num_nodes": 321,
    "in_steps": 336,
    "out_steps": 192,
    "lr": 0.0001,
    "weight_decay": 0,
    "milestones": [
        20,
        30
    ],
    "lr_decay_rate": 0.1,
    "clip_grad": 0,
    "batch_size": 32,
    "max_epochs": 200,
    "dataloader": "ltsf",
    "runner": "ltsf",
    "loss": "mse",
    "model_args": {
        "enc_in": 321,
        "seq_len": 336,
        "pred_len": 192,
        "e_layers": 3,
        "n_heads": 16,
        "d_model": 128,
        "d_ff": 256,
        "dropout": 0.2,
        "fc_dropout": 0.2,
        "head_dropout": 0,
        "patch_len": 16,
        "stride": 8,
        "individual": 0,
        "padding_patch": "end",
        "revin": 1,
        "affine": 0,
        "subtract_last": 0,
        "decomposition": 0,
        "kernel_size": 25
    }
}
========================================================================================================================
Layer (type:depth-idx)                                                 Output Shape              Param #
========================================================================================================================
PatchTST                                                               [32, 192, 321, 1]         --
├─PatchTST_backbone: 1-1                                               [32, 321, 192]            --
│    └─RevIN: 2-1                                                      [32, 336, 321]            --
│    └─ReplicationPad1d: 2-2                                           [32, 321, 344]            --
│    └─TSTiEncoder: 2-3                                                [32, 321, 128, 42]        5,376
│    │    └─Linear: 3-1                                                [32, 321, 42, 128]        2,176
│    │    └─Dropout: 3-2                                               [10272, 42, 128]          --
│    │    └─TSTEncoder: 3-3                                            [10272, 42, 128]          397,443
│    └─Flatten_Head: 2-4                                               [32, 321, 192]            --
│    │    └─Flatten: 3-4                                               [32, 321, 5376]           --
│    │    └─Linear: 3-5                                                [32, 321, 192]            1,032,384
│    │    └─Dropout: 3-6                                               [32, 321, 192]            --
│    └─RevIN: 2-5                                                      [32, 192, 321]            --
========================================================================================================================
Total params: 1,437,379
Trainable params: 1,437,376
Non-trainable params: 3
Total mult-adds (G): 4.12
========================================================================================================================
Input size (MB): 13.81
Forward/backward pass size (MB): 12385.57
Params size (MB): 5.73
Estimated Total Size (MB): 12405.10
========================================================================================================================

Loss: MSELoss

2024-04-02 21:04:36.861116 Epoch 1  	Train Loss = 0.20613 Val Loss = 0.13862
2024-04-02 21:09:27.668666 Epoch 2  	Train Loss = 0.17415 Val Loss = 0.13524
2024-04-02 21:14:18.531931 Epoch 3  	Train Loss = 0.16878 Val Loss = 0.13377
2024-04-02 21:19:09.142333 Epoch 4  	Train Loss = 0.16548 Val Loss = 0.13297
2024-04-02 21:24:00.090291 Epoch 5  	Train Loss = 0.16294 Val Loss = 0.13192
2024-04-02 21:28:51.358172 Epoch 6  	Train Loss = 0.16135 Val Loss = 0.13277
2024-04-02 21:33:42.024986 Epoch 7  	Train Loss = 0.15968 Val Loss = 0.12989
2024-04-02 21:38:32.939125 Epoch 8  	Train Loss = 0.15858 Val Loss = 0.13125
2024-04-02 21:43:23.919444 Epoch 9  	Train Loss = 0.15750 Val Loss = 0.13026
2024-04-02 21:48:14.760775 Epoch 10  	Train Loss = 0.15668 Val Loss = 0.13038
2024-04-02 21:53:05.588088 Epoch 11  	Train Loss = 0.15575 Val Loss = 0.13035
2024-04-02 21:57:56.649801 Epoch 12  	Train Loss = 0.15513 Val Loss = 0.12873
2024-04-02 22:02:47.448261 Epoch 13  	Train Loss = 0.15423 Val Loss = 0.12898
2024-04-02 22:07:38.207066 Epoch 14  	Train Loss = 0.15362 Val Loss = 0.12825
2024-04-02 22:12:29.156862 Epoch 15  	Train Loss = 0.15305 Val Loss = 0.12869
2024-04-02 22:17:20.022622 Epoch 16  	Train Loss = 0.15250 Val Loss = 0.12835
2024-04-02 22:22:10.896689 Epoch 17  	Train Loss = 0.15177 Val Loss = 0.12840
2024-04-02 22:27:01.999867 Epoch 18  	Train Loss = 0.15130 Val Loss = 0.12786
2024-04-02 22:31:52.848631 Epoch 19  	Train Loss = 0.15075 Val Loss = 0.12796
2024-04-02 22:36:43.636336 Epoch 20  	Train Loss = 0.15029 Val Loss = 0.12735
2024-04-02 22:41:34.734871 Epoch 21  	Train Loss = 0.14792 Val Loss = 0.12577
2024-04-02 22:46:25.514046 Epoch 22  	Train Loss = 0.14775 Val Loss = 0.12588
2024-04-02 22:51:16.249009 Epoch 23  	Train Loss = 0.14770 Val Loss = 0.12562
2024-04-02 22:56:07.249166 Epoch 24  	Train Loss = 0.14765 Val Loss = 0.12572
2024-04-02 23:00:57.966615 Epoch 25  	Train Loss = 0.14762 Val Loss = 0.12577
2024-04-02 23:05:48.621489 Epoch 26  	Train Loss = 0.14755 Val Loss = 0.12570
2024-04-02 23:10:39.498918 Epoch 27  	Train Loss = 0.14748 Val Loss = 0.12569
2024-04-02 23:15:30.232444 Epoch 28  	Train Loss = 0.14746 Val Loss = 0.12568
2024-04-02 23:20:20.811498 Epoch 29  	Train Loss = 0.14737 Val Loss = 0.12565
2024-04-02 23:25:11.632772 Epoch 30  	Train Loss = 0.14735 Val Loss = 0.12569
2024-04-02 23:30:02.417462 Epoch 31  	Train Loss = 0.14707 Val Loss = 0.12542
2024-04-02 23:34:53.001339 Epoch 32  	Train Loss = 0.14704 Val Loss = 0.12542
2024-04-02 23:39:43.720084 Epoch 33  	Train Loss = 0.14705 Val Loss = 0.12545
2024-04-02 23:44:34.580403 Epoch 34  	Train Loss = 0.14703 Val Loss = 0.12548
2024-04-02 23:49:25.208808 Epoch 35  	Train Loss = 0.14702 Val Loss = 0.12549
2024-04-02 23:54:15.931370 Epoch 36  	Train Loss = 0.14703 Val Loss = 0.12541
2024-04-02 23:59:06.915926 Epoch 37  	Train Loss = 0.14702 Val Loss = 0.12541
2024-04-03 00:03:57.589697 Epoch 38  	Train Loss = 0.14703 Val Loss = 0.12549
2024-04-03 00:08:48.350044 Epoch 39  	Train Loss = 0.14700 Val Loss = 0.12544
2024-04-03 00:13:39.105339 Epoch 40  	Train Loss = 0.14700 Val Loss = 0.12542
2024-04-03 00:18:29.800288 Epoch 41  	Train Loss = 0.14700 Val Loss = 0.12543
2024-04-03 00:23:20.578562 Epoch 42  	Train Loss = 0.14698 Val Loss = 0.12543
2024-04-03 00:28:11.452973 Epoch 43  	Train Loss = 0.14700 Val Loss = 0.12544
2024-04-03 00:33:02.512515 Epoch 44  	Train Loss = 0.14697 Val Loss = 0.12537
2024-04-03 00:37:53.537251 Epoch 45  	Train Loss = 0.14697 Val Loss = 0.12544
2024-04-03 00:42:44.696826 Epoch 46  	Train Loss = 0.14698 Val Loss = 0.12538
2024-04-03 00:47:35.584515 Epoch 47  	Train Loss = 0.14696 Val Loss = 0.12544
2024-04-03 00:52:26.168124 Epoch 48  	Train Loss = 0.14698 Val Loss = 0.12542
2024-04-03 00:57:16.943610 Epoch 49  	Train Loss = 0.14695 Val Loss = 0.12539
2024-04-03 01:02:07.623011 Epoch 50  	Train Loss = 0.14695 Val Loss = 0.12548
2024-04-03 01:06:58.351181 Epoch 51  	Train Loss = 0.14696 Val Loss = 0.12542
2024-04-03 01:11:49.355522 Epoch 52  	Train Loss = 0.14694 Val Loss = 0.12543
2024-04-03 01:16:40.096663 Epoch 53  	Train Loss = 0.14694 Val Loss = 0.12540
2024-04-03 01:21:31.064338 Epoch 54  	Train Loss = 0.14695 Val Loss = 0.12551
Early stopping at epoch: 54
Best at epoch 44:
Train Loss = 0.14697
Train MSE = 0.14386, MAE = 0.23860
Val Loss = 0.12537
Val MSE = 0.12557, MAE = 0.21807
Model checkpoint saved to: ../saved_models/PatchTST/PatchTST-ELECTRICITY-2024-04-02-20-59-24.pt
--------- Test ---------
All Steps (1-192) MSE = 0.14706, MAE = 0.23973
Inference time: 27.84 s
