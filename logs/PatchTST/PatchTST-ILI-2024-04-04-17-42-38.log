ILI
Trainset:	x-(584, 96, 7, 1)	y-(584, 36, 7, 1)
Valset:  	x-(84, 96, 7, 1)  	y-(84, 36, 7, 1)
Testset:	x-(167, 96, 7, 1)	y-(167, 36, 7, 1)
INFO: Using scaled X and Y, only for LTSF!

Random seed = 233
--------- PatchTST ---------
{
    "num_nodes": 7,
    "in_steps": 96,
    "out_steps": 36,
    "lr": 0.01,
    "weight_decay": 0,
    "milestones": [
        10
    ],
    "lr_decay_rate": 0.1,
    "clip_grad": 0,
    "batch_size": 64,
    "max_epochs": 200,
    "dataloader": "ltsf",
    "runner": "ltsf",
    "loss": "mse",
    "model_args": {
        "enc_in": 7,
        "seq_len": 96,
        "pred_len": 36,
        "e_layers": 3,
        "n_heads": 4,
        "d_model": 16,
        "d_ff": 128,
        "dropout": 0.3,
        "fc_dropout": 0.3,
        "head_dropout": 0,
        "patch_len": 16,
        "stride": 8,
        "individual": 0,
        "padding_patch": "end",
        "revin": 1,
        "affine": 0,
        "subtract_last": 0,
        "decomposition": 0,
        "kernel_size": 25
    }
}
========================================================================================================================
Layer (type:depth-idx)                                                 Output Shape              Param #
========================================================================================================================
PatchTST                                                               [64, 36, 7, 1]            --
├─PatchTST_backbone: 1-1                                               [64, 7, 36]               --
│    └─RevIN: 2-1                                                      [64, 96, 7]               --
│    └─ReplicationPad1d: 2-2                                           [64, 7, 104]              --
│    └─TSTiEncoder: 2-3                                                [64, 7, 16, 12]           192
│    │    └─Linear: 3-1                                                [64, 7, 12, 16]           272
│    │    └─Dropout: 3-2                                               [448, 12, 16]             --
│    │    └─TSTEncoder: 3-3                                            [448, 12, 16]             16,179
│    └─Flatten_Head: 2-4                                               [64, 7, 36]               --
│    │    └─Flatten: 3-4                                               [64, 7, 192]              --
│    │    └─Linear: 3-5                                                [64, 7, 36]               6,948
│    │    └─Dropout: 3-6                                               [64, 7, 36]               --
│    └─RevIN: 2-5                                                      [64, 36, 7]               --
========================================================================================================================
Total params: 23,591
Trainable params: 23,588
Non-trainable params: 3
Total mult-adds (M): 7.71
========================================================================================================================
Input size (MB): 0.17
Forward/backward pass size (MB): 31.78
Params size (MB): 0.09
Estimated Total Size (MB): 32.05
========================================================================================================================

Loss: MSELoss

2024-04-04 17:42:39.360033 Epoch 1  	Train Loss = 0.67933 Val Loss = 0.91949
2024-04-04 17:42:39.518266 Epoch 2  	Train Loss = 0.56377 Val Loss = 0.29559
2024-04-04 17:42:39.686816 Epoch 3  	Train Loss = 0.47880 Val Loss = 0.24349
2024-04-04 17:42:39.885020 Epoch 4  	Train Loss = 0.43328 Val Loss = 0.30777
2024-04-04 17:42:40.069921 Epoch 5  	Train Loss = 0.44653 Val Loss = 0.32456
2024-04-04 17:42:40.256602 Epoch 6  	Train Loss = 0.40709 Val Loss = 0.28037
2024-04-04 17:42:40.429721 Epoch 7  	Train Loss = 0.39026 Val Loss = 0.23895
2024-04-04 17:42:40.613372 Epoch 8  	Train Loss = 0.40314 Val Loss = 0.22083
2024-04-04 17:42:40.798062 Epoch 9  	Train Loss = 0.37433 Val Loss = 0.21117
2024-04-04 17:42:41.008870 Epoch 10  	Train Loss = 0.40155 Val Loss = 0.23731
2024-04-04 17:42:41.200207 Epoch 11  	Train Loss = 0.38044 Val Loss = 0.21476
2024-04-04 17:42:41.398811 Epoch 12  	Train Loss = 0.36802 Val Loss = 0.19148
2024-04-04 17:42:41.603575 Epoch 13  	Train Loss = 0.33605 Val Loss = 0.19826
2024-04-04 17:42:41.787757 Epoch 14  	Train Loss = 0.32794 Val Loss = 0.19877
2024-04-04 17:42:41.960732 Epoch 15  	Train Loss = 0.32008 Val Loss = 0.20843
2024-04-04 17:42:42.136668 Epoch 16  	Train Loss = 0.31949 Val Loss = 0.19671
2024-04-04 17:42:42.309159 Epoch 17  	Train Loss = 0.31875 Val Loss = 0.20296
2024-04-04 17:42:42.489154 Epoch 18  	Train Loss = 0.31569 Val Loss = 0.19582
2024-04-04 17:42:42.674716 Epoch 19  	Train Loss = 0.31874 Val Loss = 0.19874
2024-04-04 17:42:42.864652 Epoch 20  	Train Loss = 0.31722 Val Loss = 0.20157
2024-04-04 17:42:43.057229 Epoch 21  	Train Loss = 0.32922 Val Loss = 0.19982
2024-04-04 17:42:43.232605 Epoch 22  	Train Loss = 0.31411 Val Loss = 0.20373
Early stopping at epoch: 22
Best at epoch 12:
Train Loss = 0.36802
Train MSE = 0.30562, MAE = 0.33576
Val Loss = 0.19148
Val MSE = 0.20020, MAE = 0.28174
Model checkpoint saved to: ../saved_models/PatchTST/PatchTST-ILI-2024-04-04-17-42-38.pt
--------- Test ---------
All Steps (1-36) MSE = 1.75383, MAE = 0.83921
Inference time: 0.01 s
