ETTH2
Trainset:	x-(8324, 336, 7, 1)	y-(8324, 192, 7, 1)
Valset:  	x-(2775, 336, 7, 1)  	y-(2775, 192, 7, 1)
Testset:	x-(2774, 336, 7, 1)	y-(2774, 192, 7, 1)
INFO: Using scaled X and Y, only for LTSF!

Random seed = 233
--------- PatchTST ---------
{
    "num_nodes": 7,
    "in_steps": 336,
    "out_steps": 192,
    "lr": 0.0001,
    "weight_decay": 0,
    "milestones": [
        10
    ],
    "lr_decay_rate": 0.1,
    "clip_grad": 0,
    "batch_size": 64,
    "max_epochs": 200,
    "dataloader": "ltsf",
    "runner": "ltsf",
    "loss": "mse",
    "model_args": {
        "enc_in": 7,
        "seq_len": 336,
        "pred_len": 192,
        "e_layers": 3,
        "n_heads": 4,
        "d_model": 16,
        "d_ff": 128,
        "dropout": 0.3,
        "fc_dropout": 0.3,
        "head_dropout": 0,
        "patch_len": 16,
        "stride": 8,
        "individual": 0,
        "padding_patch": "end",
        "revin": 1,
        "affine": 0,
        "subtract_last": 0,
        "decomposition": 0,
        "kernel_size": 25
    }
}
========================================================================================================================
Layer (type:depth-idx)                                                 Output Shape              Param #
========================================================================================================================
PatchTST                                                               [64, 192, 7, 1]           --
├─PatchTST_backbone: 1-1                                               [64, 7, 192]              --
│    └─RevIN: 2-1                                                      [64, 336, 7]              --
│    └─ReplicationPad1d: 2-2                                           [64, 7, 344]              --
│    └─TSTiEncoder: 2-3                                                [64, 7, 16, 42]           672
│    │    └─Linear: 3-1                                                [64, 7, 42, 16]           272
│    │    └─Dropout: 3-2                                               [448, 42, 16]             --
│    │    └─TSTEncoder: 3-3                                            [448, 42, 16]             16,179
│    └─Flatten_Head: 2-4                                               [64, 7, 192]              --
│    │    └─Flatten: 3-4                                               [64, 7, 672]              --
│    │    └─Linear: 3-5                                                [64, 7, 192]              129,216
│    │    └─Dropout: 3-6                                               [64, 7, 192]              --
│    └─RevIN: 2-5                                                      [64, 192, 7]              --
========================================================================================================================
Total params: 146,339
Trainable params: 146,336
Non-trainable params: 3
Total mult-adds (M): 15.53
========================================================================================================================
Input size (MB): 0.60
Forward/backward pass size (MB): 111.48
Params size (MB): 0.58
Estimated Total Size (MB): 112.66
========================================================================================================================

Loss: MSELoss

2024-04-04 16:39:00.292882 Epoch 1  	Train Loss = 0.62563 Val Loss = 0.29737
2024-04-04 16:39:03.132446 Epoch 2  	Train Loss = 0.56220 Val Loss = 0.28373
2024-04-04 16:39:05.775523 Epoch 3  	Train Loss = 0.52983 Val Loss = 0.27734
2024-04-04 16:39:08.691685 Epoch 4  	Train Loss = 0.51617 Val Loss = 0.27676
2024-04-04 16:39:11.534289 Epoch 5  	Train Loss = 0.50840 Val Loss = 0.27213
2024-04-04 16:39:14.515323 Epoch 6  	Train Loss = 0.51355 Val Loss = 0.27424
2024-04-04 16:39:17.367527 Epoch 7  	Train Loss = 0.49606 Val Loss = 0.27658
2024-04-04 16:39:20.233398 Epoch 8  	Train Loss = 0.49116 Val Loss = 0.27416
2024-04-04 16:39:23.178825 Epoch 9  	Train Loss = 0.48673 Val Loss = 0.27276
2024-04-04 16:39:26.204651 Epoch 10  	Train Loss = 0.48557 Val Loss = 0.27431
2024-04-04 16:39:28.847696 Epoch 11  	Train Loss = 0.48421 Val Loss = 0.27210
2024-04-04 16:39:31.701808 Epoch 12  	Train Loss = 0.48278 Val Loss = 0.27162
2024-04-04 16:39:34.655433 Epoch 13  	Train Loss = 0.47964 Val Loss = 0.27161
2024-04-04 16:39:37.504914 Epoch 14  	Train Loss = 0.48260 Val Loss = 0.27183
2024-04-04 16:39:40.229157 Epoch 15  	Train Loss = 0.47889 Val Loss = 0.27176
2024-04-04 16:39:42.992903 Epoch 16  	Train Loss = 0.48164 Val Loss = 0.27096
2024-04-04 16:39:45.753018 Epoch 17  	Train Loss = 0.47954 Val Loss = 0.27128
2024-04-04 16:39:48.609500 Epoch 18  	Train Loss = 0.48651 Val Loss = 0.27056
2024-04-04 16:39:51.345694 Epoch 19  	Train Loss = 0.47747 Val Loss = 0.27056
2024-04-04 16:39:54.063795 Epoch 20  	Train Loss = 0.47761 Val Loss = 0.27135
2024-04-04 16:39:56.763980 Epoch 21  	Train Loss = 0.47815 Val Loss = 0.27127
2024-04-04 16:39:59.453195 Epoch 22  	Train Loss = 0.47915 Val Loss = 0.27098
2024-04-04 16:40:02.140726 Epoch 23  	Train Loss = 0.48107 Val Loss = 0.27116
2024-04-04 16:40:04.939390 Epoch 24  	Train Loss = 0.47595 Val Loss = 0.27136
2024-04-04 16:40:07.712859 Epoch 25  	Train Loss = 0.47567 Val Loss = 0.27084
2024-04-04 16:40:10.386058 Epoch 26  	Train Loss = 0.47498 Val Loss = 0.27075
2024-04-04 16:40:13.146428 Epoch 27  	Train Loss = 0.47533 Val Loss = 0.27077
2024-04-04 16:40:15.965834 Epoch 28  	Train Loss = 0.48001 Val Loss = 0.27082
Early stopping at epoch: 28
Best at epoch 18:
Train Loss = 0.48651
Train MSE = 0.46634, MAE = 0.38968
Val Loss = 0.27056
Val MSE = 0.27248, MAE = 0.35722
Model checkpoint saved to: ../saved_models/PatchTST/PatchTST-ETTH2-2024-04-04-16-38-56.pt
--------- Test ---------
All Steps (1-192) MSE = 0.33481, MAE = 0.37400
Inference time: 0.18 s
