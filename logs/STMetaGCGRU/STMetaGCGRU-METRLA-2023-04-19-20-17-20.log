METRLA
Trainset:	x-(23974, 12, 207, 3)	y-(23974, 12, 207, 1)
Valset:  	x-(3425, 12, 207, 3)  	y-(3425, 12, 207, 1)
Testset:	x-(6850, 12, 207, 3)	y-(6850, 12, 207, 1)

--------- STMetaGCGRU ---------
{
    "num_nodes": 207,
    "in_steps": 12,
    "out_steps": 12,
    "time_of_day": true,
    "day_of_week": true,
    "lr": 0.0001,
    "weight_decay": 0,
    "early_stop": 20,
    "milestones": [
        40,
        80
    ],
    "clip_grad": false,
    "batch_size": 64,
    "max_epochs": 200,
    "use_cl": false,
    "pass_device": true,
    "model_args": {
        "num_nodes": 207,
        "node_emb_file": "../data/METRLA/spatial_embeddings.npz",
        "adj_path": "../data/METRLA/adj_mx.pkl",
        "adj_type": "doubletransition",
        "in_steps": 12,
        "out_steps": 12,
        "input_dim": 1,
        "output_dim": 1,
        "gru_hidden_dim": 32,
        "tod_embedding_dim": 24,
        "dow_embedding_dim": 7,
        "node_embedding_dim": 64,
        "learner_hidden_dim": 128,
        "z_dim": 32,
        "num_layers": 1,
        "cheb_k": 3,
        "seq2seq": true,
        "device": "cuda:0"
    }
}
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
STMetaGCGRU                              [64, 12, 207, 1]          --
├─Sequential: 1-1                        [64, 207, 32]             --
│    └─Linear: 2-1                       [64, 207, 32]             416
│    └─Tanh: 2-2                         [64, 207, 32]             --
│    └─Linear: 2-3                       [64, 207, 32]             1,056
│    └─Tanh: 2-4                         [64, 207, 32]             --
│    └─Linear: 2-5                       [64, 207, 32]             1,056
├─Sequential: 1-2                        [64, 207, 32]             --
│    └─Linear: 2-6                       [64, 207, 32]             416
│    └─Tanh: 2-7                         [64, 207, 32]             --
│    └─Linear: 2-8                       [64, 207, 32]             1,056
│    └─Tanh: 2-9                         [64, 207, 32]             --
│    └─Linear: 2-10                      [64, 207, 32]             1,056
├─ModuleList: 1-3                        --                        --
│    └─STMetaGCGRUEncoder: 2-11          [64, 12, 207, 32]         --
│    │    └─Sequential: 3-1              [64, 207, 12672]          1,651,072
│    │    └─Sequential: 3-2              [64, 207, 64]             24,640
│    │    └─Sequential: 3-3              [64, 207, 6336]           833,728
│    │    └─Sequential: 3-4              [64, 207, 32]             20,512
│    │    └─STMetaGCGRUCell: 3-5         [64, 207, 32]             --
│    │    └─STMetaGCGRUCell: 3-6         [64, 207, 32]             --
│    │    └─STMetaGCGRUCell: 3-7         [64, 207, 32]             --
│    │    └─STMetaGCGRUCell: 3-8         [64, 207, 32]             --
│    │    └─STMetaGCGRUCell: 3-9         [64, 207, 32]             --
│    │    └─STMetaGCGRUCell: 3-10        [64, 207, 32]             --
│    │    └─STMetaGCGRUCell: 3-11        [64, 207, 32]             --
│    │    └─STMetaGCGRUCell: 3-12        [64, 207, 32]             --
│    │    └─STMetaGCGRUCell: 3-13        [64, 207, 32]             --
│    │    └─STMetaGCGRUCell: 3-14        [64, 207, 32]             --
│    │    └─STMetaGCGRUCell: 3-15        [64, 207, 32]             --
│    │    └─STMetaGCGRUCell: 3-16        [64, 207, 32]             --
├─ModuleList: 1-26                       --                        (recursive)
│    └─STMetaGCGRUDecoder: 2-12          --                        (recursive)
│    │    └─Sequential: 3-17             [64, 207, 12672]          1,651,072
│    │    └─Sequential: 3-18             [64, 207, 64]             24,640
│    │    └─Sequential: 3-19             [64, 207, 6336]           833,728
│    │    └─Sequential: 3-20             [64, 207, 32]             20,512
│    └─STMetaGCGRUDecoder: 2-13          [64, 207, 32]             2,529,952
│    │    └─STMetaGCGRUCell: 3-21        [64, 207, 32]             --
├─Linear: 1-5                            [64, 207, 1]              33
├─ModuleList: 1-26                       --                        (recursive)
│    └─STMetaGCGRUDecoder: 2-14          [64, 207, 32]             (recursive)
│    │    └─STMetaGCGRUCell: 3-22        [64, 207, 32]             --
├─Linear: 1-7                            [64, 207, 1]              (recursive)
├─ModuleList: 1-26                       --                        (recursive)
│    └─STMetaGCGRUDecoder: 2-15          [64, 207, 32]             (recursive)
│    │    └─STMetaGCGRUCell: 3-23        [64, 207, 32]             --
├─Linear: 1-9                            [64, 207, 1]              (recursive)
├─ModuleList: 1-26                       --                        (recursive)
│    └─STMetaGCGRUDecoder: 2-16          [64, 207, 32]             (recursive)
│    │    └─STMetaGCGRUCell: 3-24        [64, 207, 32]             --
├─Linear: 1-11                           [64, 207, 1]              (recursive)
├─ModuleList: 1-26                       --                        (recursive)
│    └─STMetaGCGRUDecoder: 2-17          [64, 207, 32]             (recursive)
│    │    └─STMetaGCGRUCell: 3-25        [64, 207, 32]             --
├─Linear: 1-13                           [64, 207, 1]              (recursive)
├─ModuleList: 1-26                       --                        (recursive)
│    └─STMetaGCGRUDecoder: 2-18          [64, 207, 32]             (recursive)
│    │    └─STMetaGCGRUCell: 3-26        [64, 207, 32]             --
├─Linear: 1-15                           [64, 207, 1]              (recursive)
├─ModuleList: 1-26                       --                        (recursive)
│    └─STMetaGCGRUDecoder: 2-19          [64, 207, 32]             (recursive)
│    │    └─STMetaGCGRUCell: 3-27        [64, 207, 32]             --
├─Linear: 1-17                           [64, 207, 1]              (recursive)
├─ModuleList: 1-26                       --                        (recursive)
│    └─STMetaGCGRUDecoder: 2-20          [64, 207, 32]             (recursive)
│    │    └─STMetaGCGRUCell: 3-28        [64, 207, 32]             --
├─Linear: 1-19                           [64, 207, 1]              (recursive)
├─ModuleList: 1-26                       --                        (recursive)
│    └─STMetaGCGRUDecoder: 2-21          [64, 207, 32]             (recursive)
│    │    └─STMetaGCGRUCell: 3-29        [64, 207, 32]             --
├─Linear: 1-21                           [64, 207, 1]              (recursive)
├─ModuleList: 1-26                       --                        (recursive)
│    └─STMetaGCGRUDecoder: 2-22          [64, 207, 32]             (recursive)
│    │    └─STMetaGCGRUCell: 3-30        [64, 207, 32]             --
├─Linear: 1-23                           [64, 207, 1]              (recursive)
├─ModuleList: 1-26                       --                        (recursive)
│    └─STMetaGCGRUDecoder: 2-23          [64, 207, 32]             (recursive)
│    │    └─STMetaGCGRUCell: 3-31        [64, 207, 32]             --
├─Linear: 1-25                           [64, 207, 1]              (recursive)
├─ModuleList: 1-26                       --                        (recursive)
│    └─STMetaGCGRUDecoder: 2-24          [64, 207, 32]             (recursive)
│    │    └─STMetaGCGRUCell: 3-32        [64, 207, 32]             --
├─Linear: 1-27                           [64, 207, 1]              (recursive)
==========================================================================================
Total params: 7,594,945
Trainable params: 7,594,945
Non-trainable params: 0
Total mult-adds (M): 324.18
==========================================================================================
Input size (MB): 1.91
Forward/backward pass size (MB): 4179.59
Params size (MB): 20.26
Estimated Total Size (MB): 4201.75
==========================================================================================

Loss: MaskedMAELoss

2023-04-19 20:19:50.950692 Epoch 1  	Train Loss = 6.48538 Val Loss = 4.51814
2023-04-19 20:22:22.234188 Epoch 2  	Train Loss = 4.29162 Val Loss = 3.95078
2023-04-19 20:24:53.807744 Epoch 3  	Train Loss = 4.01518 Val Loss = 3.79309
2023-04-19 20:27:25.638965 Epoch 4  	Train Loss = 3.88457 Val Loss = 3.67690
2023-04-19 20:29:57.116089 Epoch 5  	Train Loss = 3.80977 Val Loss = 3.61180
2023-04-19 20:32:28.864560 Epoch 6  	Train Loss = 3.75567 Val Loss = 3.56379
2023-04-19 20:35:00.648636 Epoch 7  	Train Loss = 3.72109 Val Loss = 3.53790
2023-04-19 20:37:32.410154 Epoch 8  	Train Loss = 3.68535 Val Loss = 3.49666
2023-04-19 20:40:04.249163 Epoch 9  	Train Loss = 3.65864 Val Loss = 3.46253
2023-04-19 20:42:36.000085 Epoch 10  	Train Loss = 3.63250 Val Loss = 3.44187
2023-04-19 20:45:07.636262 Epoch 11  	Train Loss = 3.61231 Val Loss = 3.43378
2023-04-19 20:47:39.417320 Epoch 12  	Train Loss = 3.59698 Val Loss = 3.41898
2023-04-19 20:50:11.115173 Epoch 13  	Train Loss = 3.57158 Val Loss = 3.38481
2023-04-19 20:52:42.826496 Epoch 14  	Train Loss = 3.55518 Val Loss = 3.39615
2023-04-19 20:55:14.631541 Epoch 15  	Train Loss = 3.54847 Val Loss = 3.39209
2023-04-19 20:57:46.248993 Epoch 16  	Train Loss = 3.54149 Val Loss = 3.36207
2023-04-19 21:00:17.909827 Epoch 17  	Train Loss = 3.52229 Val Loss = 3.34251
2023-04-19 21:02:49.594186 Epoch 18  	Train Loss = 3.50921 Val Loss = 3.33045
2023-04-19 21:05:21.258502 Epoch 19  	Train Loss = 3.49109 Val Loss = 3.31274
2023-04-19 21:07:52.920103 Epoch 20  	Train Loss = 3.48034 Val Loss = 3.30526
2023-04-19 21:10:24.634229 Epoch 21  	Train Loss = 3.46647 Val Loss = 3.28804
2023-04-19 21:12:56.252583 Epoch 22  	Train Loss = 3.45451 Val Loss = 3.28866
2023-04-19 21:15:27.974752 Epoch 23  	Train Loss = 3.43445 Val Loss = 3.25771
2023-04-19 21:17:59.678234 Epoch 24  	Train Loss = 3.41431 Val Loss = 3.24381
2023-04-19 21:20:31.368698 Epoch 25  	Train Loss = 3.39527 Val Loss = 3.24042
2023-04-19 21:23:03.099059 Epoch 26  	Train Loss = 3.39111 Val Loss = 3.21512
2023-04-19 21:25:34.872158 Epoch 27  	Train Loss = 3.38659 Val Loss = 3.23100
2023-04-19 21:28:06.502531 Epoch 28  	Train Loss = 3.36937 Val Loss = 3.20753
2023-04-19 21:30:38.248920 Epoch 29  	Train Loss = 3.36050 Val Loss = 3.20858
2023-04-19 21:33:09.927354 Epoch 30  	Train Loss = 3.34802 Val Loss = 3.18680
2023-04-19 21:35:41.615450 Epoch 31  	Train Loss = 3.33398 Val Loss = 3.18018
2023-04-19 21:38:13.358867 Epoch 32  	Train Loss = 3.33025 Val Loss = 3.17646
2023-04-19 21:40:44.959843 Epoch 33  	Train Loss = 3.32690 Val Loss = 3.18479
2023-04-19 21:43:16.518054 Epoch 34  	Train Loss = 3.32462 Val Loss = 3.17591
2023-04-19 21:45:48.254902 Epoch 35  	Train Loss = 3.32288 Val Loss = 3.17407
2023-04-19 21:48:19.900762 Epoch 36  	Train Loss = 3.30865 Val Loss = 3.16531
2023-04-19 21:50:51.692674 Epoch 37  	Train Loss = 3.30229 Val Loss = 3.18090
2023-04-19 21:53:23.562895 Epoch 38  	Train Loss = 3.29703 Val Loss = 3.15933
2023-04-19 21:55:55.319466 Epoch 39  	Train Loss = 3.28883 Val Loss = 3.14959
2023-04-19 21:58:27.167331 Epoch 40  	Train Loss = 3.28153 Val Loss = 3.13552
2023-04-19 22:00:59.001287 Epoch 41  	Train Loss = 3.27173 Val Loss = 3.13376
2023-04-19 22:03:30.700909 Epoch 42  	Train Loss = 3.26889 Val Loss = 3.13762
2023-04-19 22:06:02.267529 Epoch 43  	Train Loss = 3.26787 Val Loss = 3.13087
2023-04-19 22:08:33.501730 Epoch 44  	Train Loss = 3.26533 Val Loss = 3.12864
2023-04-19 22:11:05.161525 Epoch 45  	Train Loss = 3.26265 Val Loss = 3.12994
2023-04-19 22:13:37.110943 Epoch 46  	Train Loss = 3.26187 Val Loss = 3.12498
2023-04-19 22:16:08.925605 Epoch 47  	Train Loss = 3.26055 Val Loss = 3.12813
2023-04-19 22:18:40.465857 Epoch 48  	Train Loss = 3.25851 Val Loss = 3.13391
2023-04-19 22:21:12.002563 Epoch 49  	Train Loss = 3.25745 Val Loss = 3.12937
2023-04-19 22:23:57.629521 Epoch 50  	Train Loss = 3.25614 Val Loss = 3.12888
2023-04-19 22:28:24.021832 Epoch 51  	Train Loss = 3.25469 Val Loss = 3.12414
2023-04-19 22:32:49.610355 Epoch 52  	Train Loss = 3.25326 Val Loss = 3.12331
2023-04-19 22:37:13.945734 Epoch 53  	Train Loss = 3.25282 Val Loss = 3.11658
2023-04-19 22:41:35.268482 Epoch 54  	Train Loss = 3.25083 Val Loss = 3.11823
2023-04-19 22:46:07.480594 Epoch 55  	Train Loss = 3.25189 Val Loss = 3.12075
2023-04-19 22:50:39.356427 Epoch 56  	Train Loss = 3.25256 Val Loss = 3.12546
2023-04-19 22:55:10.554010 Epoch 57  	Train Loss = 3.25094 Val Loss = 3.12488
2023-04-19 22:58:31.205826 Epoch 58  	Train Loss = 3.24886 Val Loss = 3.11510
2023-04-19 23:01:02.659955 Epoch 59  	Train Loss = 3.24839 Val Loss = 3.11679
2023-04-19 23:03:33.841965 Epoch 60  	Train Loss = 3.24820 Val Loss = 3.11671
2023-04-19 23:06:05.170068 Epoch 61  	Train Loss = 3.24516 Val Loss = 3.12220
2023-04-19 23:08:36.707751 Epoch 62  	Train Loss = 3.24606 Val Loss = 3.12152
2023-04-19 23:11:08.384861 Epoch 63  	Train Loss = 3.24299 Val Loss = 3.11400
2023-04-19 23:13:40.060872 Epoch 64  	Train Loss = 3.24310 Val Loss = 3.11228
2023-04-19 23:16:11.419030 Epoch 65  	Train Loss = 3.24200 Val Loss = 3.11117
2023-04-19 23:18:42.705858 Epoch 66  	Train Loss = 3.23898 Val Loss = 3.11360
2023-04-19 23:21:14.112815 Epoch 67  	Train Loss = 3.23767 Val Loss = 3.10907
2023-04-19 23:23:45.417041 Epoch 68  	Train Loss = 3.23628 Val Loss = 3.10554
2023-04-19 23:26:16.775281 Epoch 69  	Train Loss = 3.23568 Val Loss = 3.10414
2023-04-19 23:28:48.233450 Epoch 70  	Train Loss = 3.23468 Val Loss = 3.11041
2023-04-19 23:31:19.475237 Epoch 71  	Train Loss = 3.23316 Val Loss = 3.10718
2023-04-19 23:33:50.971135 Epoch 72  	Train Loss = 3.23206 Val Loss = 3.09939
2023-04-19 23:36:22.328779 Epoch 73  	Train Loss = 3.23028 Val Loss = 3.10484
2023-04-19 23:38:53.848623 Epoch 74  	Train Loss = 3.23058 Val Loss = 3.10203
2023-04-19 23:41:25.490395 Epoch 75  	Train Loss = 3.22847 Val Loss = 3.10399
2023-04-19 23:43:57.064267 Epoch 76  	Train Loss = 3.22749 Val Loss = 3.09376
2023-04-19 23:46:28.538091 Epoch 77  	Train Loss = 3.22797 Val Loss = 3.10846
2023-04-19 23:49:00.161962 Epoch 78  	Train Loss = 3.22608 Val Loss = 3.09357
2023-04-19 23:51:31.756393 Epoch 79  	Train Loss = 3.22365 Val Loss = 3.09291
2023-04-19 23:54:03.281708 Epoch 80  	Train Loss = 3.22230 Val Loss = 3.09622
2023-04-19 23:56:34.948631 Epoch 81  	Train Loss = 3.22089 Val Loss = 3.09767
2023-04-19 23:59:06.494894 Epoch 82  	Train Loss = 3.22070 Val Loss = 3.10004
2023-04-20 00:01:38.053897 Epoch 83  	Train Loss = 3.22005 Val Loss = 3.10054
2023-04-20 00:04:09.666363 Epoch 84  	Train Loss = 3.21921 Val Loss = 3.10053
2023-04-20 00:06:41.273860 Epoch 85  	Train Loss = 3.21994 Val Loss = 3.10049
2023-04-20 00:09:12.899702 Epoch 86  	Train Loss = 3.22014 Val Loss = 3.09425
2023-04-20 00:11:44.549036 Epoch 87  	Train Loss = 3.21969 Val Loss = 3.09321
2023-04-20 00:14:16.018173 Epoch 88  	Train Loss = 3.21988 Val Loss = 3.09491
2023-04-20 00:16:47.637710 Epoch 89  	Train Loss = 3.21983 Val Loss = 3.09781
2023-04-20 00:19:19.203908 Epoch 90  	Train Loss = 3.21863 Val Loss = 3.09330
2023-04-20 00:21:50.746050 Epoch 91  	Train Loss = 3.22030 Val Loss = 3.09237
2023-04-20 00:24:22.352402 Epoch 92  	Train Loss = 3.21879 Val Loss = 3.09960
2023-04-20 00:26:53.999449 Epoch 93  	Train Loss = 3.21876 Val Loss = 3.09197
2023-04-20 00:29:25.518513 Epoch 94  	Train Loss = 3.21789 Val Loss = 3.09414
2023-04-20 00:31:57.108001 Epoch 95  	Train Loss = 3.21896 Val Loss = 3.09790
2023-04-20 00:34:28.629280 Epoch 96  	Train Loss = 3.21681 Val Loss = 3.09391
2023-04-20 00:37:00.128308 Epoch 97  	Train Loss = 3.21867 Val Loss = 3.09245
2023-04-20 00:39:31.680724 Epoch 98  	Train Loss = 3.21832 Val Loss = 3.09530
2023-04-20 00:42:03.175826 Epoch 99  	Train Loss = 3.21795 Val Loss = 3.09978
2023-04-20 00:44:34.603175 Epoch 100  	Train Loss = 3.21899 Val Loss = 3.09625
2023-04-20 00:47:06.087248 Epoch 101  	Train Loss = 3.21876 Val Loss = 3.09221
2023-04-20 00:49:37.479136 Epoch 102  	Train Loss = 3.21814 Val Loss = 3.09371
2023-04-20 00:52:08.942595 Epoch 103  	Train Loss = 3.21795 Val Loss = 3.09314
2023-04-20 00:54:40.598425 Epoch 104  	Train Loss = 3.21855 Val Loss = 3.09119
2023-04-20 00:57:12.130386 Epoch 105  	Train Loss = 3.21716 Val Loss = 3.08936
2023-04-20 00:59:43.676124 Epoch 106  	Train Loss = 3.21592 Val Loss = 3.09681
2023-04-20 01:02:15.153403 Epoch 107  	Train Loss = 3.21595 Val Loss = 3.09489
2023-04-20 01:04:46.482594 Epoch 108  	Train Loss = 3.21668 Val Loss = 3.09216
2023-04-20 01:07:17.591852 Epoch 109  	Train Loss = 3.21722 Val Loss = 3.08811
2023-04-20 01:09:48.395162 Epoch 110  	Train Loss = 3.21510 Val Loss = 3.09241
2023-04-20 01:12:19.593965 Epoch 111  	Train Loss = 3.21858 Val Loss = 3.09006
2023-04-20 01:14:51.085336 Epoch 112  	Train Loss = 3.21670 Val Loss = 3.09296
2023-04-20 01:17:22.609284 Epoch 113  	Train Loss = 3.21668 Val Loss = 3.08999
2023-04-20 01:19:53.702775 Epoch 114  	Train Loss = 3.21547 Val Loss = 3.09593
2023-04-20 01:22:24.717912 Epoch 115  	Train Loss = 3.21580 Val Loss = 3.09986
2023-04-20 01:24:55.824302 Epoch 116  	Train Loss = 3.21453 Val Loss = 3.09137
2023-04-20 01:27:27.214299 Epoch 117  	Train Loss = 3.21493 Val Loss = 3.09562
2023-04-20 01:29:58.746373 Epoch 118  	Train Loss = 3.21549 Val Loss = 3.09183
2023-04-20 01:32:30.229098 Epoch 119  	Train Loss = 3.21634 Val Loss = 3.08909
2023-04-20 01:35:01.219595 Epoch 120  	Train Loss = 3.21529 Val Loss = 3.08994
2023-04-20 01:37:32.236527 Epoch 121  	Train Loss = 3.21547 Val Loss = 3.09488
2023-04-20 01:40:03.409052 Epoch 122  	Train Loss = 3.21583 Val Loss = 3.09517
2023-04-20 01:42:34.836680 Epoch 123  	Train Loss = 3.21521 Val Loss = 3.08690
2023-04-20 01:45:06.403026 Epoch 124  	Train Loss = 3.21344 Val Loss = 3.09108
2023-04-20 01:47:37.637805 Epoch 125  	Train Loss = 3.21489 Val Loss = 3.09054
2023-04-20 01:50:08.361538 Epoch 126  	Train Loss = 3.21504 Val Loss = 3.09161
2023-04-20 01:52:39.196548 Epoch 127  	Train Loss = 3.21460 Val Loss = 3.08856
2023-04-20 01:55:10.218398 Epoch 128  	Train Loss = 3.21375 Val Loss = 3.09175
2023-04-20 01:57:41.433714 Epoch 129  	Train Loss = 3.21451 Val Loss = 3.09251
2023-04-20 02:00:12.720132 Epoch 130  	Train Loss = 3.21365 Val Loss = 3.10085
2023-04-20 02:02:43.676028 Epoch 131  	Train Loss = 3.21448 Val Loss = 3.08518
2023-04-20 02:05:14.364160 Epoch 132  	Train Loss = 3.21255 Val Loss = 3.09632
2023-04-20 02:07:45.140394 Epoch 133  	Train Loss = 3.21371 Val Loss = 3.09119
2023-04-20 02:10:16.211035 Epoch 134  	Train Loss = 3.21515 Val Loss = 3.09419
2023-04-20 02:12:47.463963 Epoch 135  	Train Loss = 3.21297 Val Loss = 3.09055
2023-04-20 02:15:18.704487 Epoch 136  	Train Loss = 3.21237 Val Loss = 3.08862
2023-04-20 02:17:49.539700 Epoch 137  	Train Loss = 3.21183 Val Loss = 3.09042
2023-04-20 02:20:20.296847 Epoch 138  	Train Loss = 3.21358 Val Loss = 3.08594
2023-04-20 02:22:51.126766 Epoch 139  	Train Loss = 3.21339 Val Loss = 3.09034
2023-04-20 02:25:21.908234 Epoch 140  	Train Loss = 3.21357 Val Loss = 3.09455
2023-04-20 02:27:52.634003 Epoch 141  	Train Loss = 3.21159 Val Loss = 3.08901
2023-04-20 02:30:23.549758 Epoch 142  	Train Loss = 3.21167 Val Loss = 3.08961
2023-04-20 02:32:54.176887 Epoch 143  	Train Loss = 3.21058 Val Loss = 3.08962
2023-04-20 02:35:25.073085 Epoch 144  	Train Loss = 3.21295 Val Loss = 3.09335
2023-04-20 02:37:55.929885 Epoch 145  	Train Loss = 3.21236 Val Loss = 3.08971
2023-04-20 02:40:26.816969 Epoch 146  	Train Loss = 3.21201 Val Loss = 3.08968
2023-04-20 02:42:57.799551 Epoch 147  	Train Loss = 3.21154 Val Loss = 3.08734
2023-04-20 02:45:28.819030 Epoch 148  	Train Loss = 3.21206 Val Loss = 3.08799
2023-04-20 02:47:59.716533 Epoch 149  	Train Loss = 3.21135 Val Loss = 3.09170
2023-04-20 02:50:30.683117 Epoch 150  	Train Loss = 3.21144 Val Loss = 3.08797
2023-04-20 02:53:01.508520 Epoch 151  	Train Loss = 3.21004 Val Loss = 3.08543
Early stopping at epoch: 151
Best at epoch 131:
Train Loss = 3.21448
Train RMSE = 6.37431, MAE = 3.21084, MAPE = 8.78843
Val Loss = 3.08518
Val RMSE = 6.35485, MAE = 3.13399, MAPE = 8.91047
--------- Test ---------
All Steps RMSE = 6.73327, MAE = 3.40759, MAPE = 9.62976
Step 1 RMSE = 4.45545, MAE = 2.58737, MAPE = 6.50989
Step 2 RMSE = 5.19342, MAE = 2.82368, MAPE = 7.28765
Step 3 RMSE = 5.71340, MAE = 3.00763, MAPE = 8.01716
Step 4 RMSE = 6.11795, MAE = 3.16326, MAPE = 8.64670
Step 5 RMSE = 6.45858, MAE = 3.30012, MAPE = 9.20200
Step 6 RMSE = 6.75485, MAE = 3.42406, MAPE = 9.70338
Step 7 RMSE = 7.01298, MAE = 3.53380, MAPE = 10.13998
Step 8 RMSE = 7.24414, MAE = 3.63521, MAPE = 10.53783
Step 9 RMSE = 7.45048, MAE = 3.72932, MAPE = 10.90754
Step 10 RMSE = 7.63641, MAE = 3.81509, MAPE = 11.23504
Step 11 RMSE = 7.80150, MAE = 3.89587, MAPE = 11.53700
Step 12 RMSE = 7.96634, MAE = 3.97572, MAPE = 11.83323
Inference time: 8.76 s
