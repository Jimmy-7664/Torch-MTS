PEMSBAY
Trainset:	x-(36465, 12, 325, 1)	y-(36465, 12, 325, 2)
Valset:  	x-(5209, 12, 325, 1)  	y-(5209, 12, 325, 2)
Testset:	x-(10419, 12, 325, 1)	y-(10419, 12, 325, 2)

--------- MegaCRN ---------
{
    "num_nodes": 325,
    "in_steps": 12,
    "out_steps": 12,
    "y_time_of_day": true,
    "runner": "megacrn",
    "loss": "megacrn",
    "loss_args": {
        "l1": 0.01,
        "l2": 0.01
    },
    "lr": 0.01,
    "eps": 0.001,
    "milestones": [
        50,
        100
    ],
    "clip_grad": 5,
    "batch_size": 64,
    "max_epochs": 200,
    "early_stop": 30,
    "model_args": {
        "num_nodes": 325,
        "input_dim": 1,
        "output_dim": 1,
        "horizon": 12,
        "rnn_units": 64,
        "num_layers": 1,
        "cheb_k": 3,
        "ycov_dim": 1,
        "mem_num": 20,
        "mem_dim": 64,
        "tf_decay_steps": 2000,
        "use_teacher_forcing": true
    }
}
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
MegaCRN                                  [64, 12, 325, 1]          18,376
├─ADCRNN_Encoder: 1-1                    [64, 12, 325, 64]         --
│    └─ModuleList: 2-1                   --                        --
│    │    └─AGCRNCell: 3-1               [64, 325, 64]             75,072
│    │    └─AGCRNCell: 3-2               [64, 325, 64]             (recursive)
│    │    └─AGCRNCell: 3-3               [64, 325, 64]             (recursive)
│    │    └─AGCRNCell: 3-4               [64, 325, 64]             (recursive)
│    │    └─AGCRNCell: 3-5               [64, 325, 64]             (recursive)
│    │    └─AGCRNCell: 3-6               [64, 325, 64]             (recursive)
│    │    └─AGCRNCell: 3-7               [64, 325, 64]             (recursive)
│    │    └─AGCRNCell: 3-8               [64, 325, 64]             (recursive)
│    │    └─AGCRNCell: 3-9               [64, 325, 64]             (recursive)
│    │    └─AGCRNCell: 3-10              [64, 325, 64]             (recursive)
│    │    └─AGCRNCell: 3-11              [64, 325, 64]             (recursive)
│    │    └─AGCRNCell: 3-12              [64, 325, 64]             (recursive)
├─ADCRNN_Decoder: 1-2                    [64, 325, 128]            --
│    └─ModuleList: 2-24                  --                        (recursive)
│    │    └─AGCRNCell: 3-13              [64, 325, 128]            299,904
├─Sequential: 1-3                        [64, 325, 1]              --
│    └─Linear: 2-3                       [64, 325, 1]              129
├─ADCRNN_Decoder: 1-4                    [64, 325, 128]            (recursive)
│    └─ModuleList: 2-24                  --                        (recursive)
│    │    └─AGCRNCell: 3-14              [64, 325, 128]            (recursive)
├─Sequential: 1-5                        [64, 325, 1]              (recursive)
│    └─Linear: 2-5                       [64, 325, 1]              (recursive)
├─ADCRNN_Decoder: 1-6                    [64, 325, 128]            (recursive)
│    └─ModuleList: 2-24                  --                        (recursive)
│    │    └─AGCRNCell: 3-15              [64, 325, 128]            (recursive)
├─Sequential: 1-7                        [64, 325, 1]              (recursive)
│    └─Linear: 2-7                       [64, 325, 1]              (recursive)
├─ADCRNN_Decoder: 1-8                    [64, 325, 128]            (recursive)
│    └─ModuleList: 2-24                  --                        (recursive)
│    │    └─AGCRNCell: 3-16              [64, 325, 128]            (recursive)
├─Sequential: 1-9                        [64, 325, 1]              (recursive)
│    └─Linear: 2-9                       [64, 325, 1]              (recursive)
├─ADCRNN_Decoder: 1-10                   [64, 325, 128]            (recursive)
│    └─ModuleList: 2-24                  --                        (recursive)
│    │    └─AGCRNCell: 3-17              [64, 325, 128]            (recursive)
├─Sequential: 1-11                       [64, 325, 1]              (recursive)
│    └─Linear: 2-11                      [64, 325, 1]              (recursive)
├─ADCRNN_Decoder: 1-12                   [64, 325, 128]            (recursive)
│    └─ModuleList: 2-24                  --                        (recursive)
│    │    └─AGCRNCell: 3-18              [64, 325, 128]            (recursive)
├─Sequential: 1-13                       [64, 325, 1]              (recursive)
│    └─Linear: 2-13                      [64, 325, 1]              (recursive)
├─ADCRNN_Decoder: 1-14                   [64, 325, 128]            (recursive)
│    └─ModuleList: 2-24                  --                        (recursive)
│    │    └─AGCRNCell: 3-19              [64, 325, 128]            (recursive)
├─Sequential: 1-15                       [64, 325, 1]              (recursive)
│    └─Linear: 2-15                      [64, 325, 1]              (recursive)
├─ADCRNN_Decoder: 1-16                   [64, 325, 128]            (recursive)
│    └─ModuleList: 2-24                  --                        (recursive)
│    │    └─AGCRNCell: 3-20              [64, 325, 128]            (recursive)
├─Sequential: 1-17                       [64, 325, 1]              (recursive)
│    └─Linear: 2-17                      [64, 325, 1]              (recursive)
├─ADCRNN_Decoder: 1-18                   [64, 325, 128]            (recursive)
│    └─ModuleList: 2-24                  --                        (recursive)
│    │    └─AGCRNCell: 3-21              [64, 325, 128]            (recursive)
├─Sequential: 1-19                       [64, 325, 1]              (recursive)
│    └─Linear: 2-19                      [64, 325, 1]              (recursive)
├─ADCRNN_Decoder: 1-20                   [64, 325, 128]            (recursive)
│    └─ModuleList: 2-24                  --                        (recursive)
│    │    └─AGCRNCell: 3-22              [64, 325, 128]            (recursive)
├─Sequential: 1-21                       [64, 325, 1]              (recursive)
│    └─Linear: 2-21                      [64, 325, 1]              (recursive)
├─ADCRNN_Decoder: 1-22                   [64, 325, 128]            (recursive)
│    └─ModuleList: 2-24                  --                        (recursive)
│    │    └─AGCRNCell: 3-23              [64, 325, 128]            (recursive)
├─Sequential: 1-23                       [64, 325, 1]              (recursive)
│    └─Linear: 2-23                      [64, 325, 1]              (recursive)
├─ADCRNN_Decoder: 1-24                   [64, 325, 128]            (recursive)
│    └─ModuleList: 2-24                  --                        (recursive)
│    │    └─AGCRNCell: 3-24              [64, 325, 128]            (recursive)
├─Sequential: 1-25                       [64, 325, 1]              (recursive)
│    └─Linear: 2-25                      [64, 325, 1]              (recursive)
==========================================================================================
Total params: 393,481
Trainable params: 393,481
Non-trainable params: 0
Total mult-adds (G): 93.45
==========================================================================================
Input size (MB): 2.00
Forward/backward pass size (MB): 1152.15
Params size (MB): 1.50
Estimated Total Size (MB): 1155.65
==========================================================================================

Loss: MegaCRNLoss

2023-09-25 10:48:23.743023 Epoch 1  	Train Loss = 0.95540 Val Loss = 2.35061
2023-09-25 10:51:20.086863 Epoch 2  	Train Loss = 0.86763 Val Loss = 2.23632
2023-09-25 10:54:16.179979 Epoch 3  	Train Loss = 0.85616 Val Loss = 2.21540
2023-09-25 10:57:11.451718 Epoch 4  	Train Loss = 0.84760 Val Loss = 1.96198
2023-09-25 11:00:06.822670 Epoch 5  	Train Loss = 0.83956 Val Loss = 2.10366
2023-09-25 11:03:03.188205 Epoch 6  	Train Loss = 0.83638 Val Loss = 1.91132
2023-09-25 11:05:59.328313 Epoch 7  	Train Loss = 0.83232 Val Loss = 1.90962
2023-09-25 11:08:55.514573 Epoch 8  	Train Loss = 0.83030 Val Loss = 1.92951
2023-09-25 11:11:51.265158 Epoch 9  	Train Loss = 0.82799 Val Loss = 1.84177
2023-09-25 11:14:47.358576 Epoch 10  	Train Loss = 0.82546 Val Loss = 2.31460
2023-09-25 11:17:45.434100 Epoch 11  	Train Loss = 0.82315 Val Loss = 1.84337
2023-09-25 11:20:42.316549 Epoch 12  	Train Loss = 0.81881 Val Loss = 1.82867
2023-09-25 11:23:38.438839 Epoch 13  	Train Loss = 0.82053 Val Loss = 1.89143
2023-09-25 11:26:34.182181 Epoch 14  	Train Loss = 0.81502 Val Loss = 1.84144
2023-09-25 11:29:29.444958 Epoch 15  	Train Loss = 0.81365 Val Loss = 1.80345
2023-09-25 11:32:23.256385 Epoch 16  	Train Loss = 0.81266 Val Loss = 1.76230
2023-09-25 11:35:17.588545 Epoch 17  	Train Loss = 0.81612 Val Loss = 1.85609
2023-09-25 11:38:12.643292 Epoch 18  	Train Loss = 0.82504 Val Loss = 1.76457
2023-09-25 11:41:09.363005 Epoch 19  	Train Loss = 0.82704 Val Loss = 1.88288
2023-09-25 11:44:05.542195 Epoch 20  	Train Loss = 0.83988 Val Loss = 1.77216
2023-09-25 11:47:01.125478 Epoch 21  	Train Loss = 0.84889 Val Loss = 1.96968
2023-09-25 11:49:56.475550 Epoch 22  	Train Loss = 0.85775 Val Loss = 1.80110
2023-09-25 11:52:52.166464 Epoch 23  	Train Loss = 0.87744 Val Loss = 1.92826
2023-09-25 11:55:47.570595 Epoch 24  	Train Loss = 0.90181 Val Loss = 1.77602
2023-09-25 11:58:42.728522 Epoch 25  	Train Loss = 0.93300 Val Loss = 1.82301
2023-09-25 12:01:38.515140 Epoch 26  	Train Loss = 0.97007 Val Loss = 1.73807
2023-09-25 12:04:36.221316 Epoch 27  	Train Loss = 1.00052 Val Loss = 1.71340
2023-09-25 12:07:32.968748 Epoch 28  	Train Loss = 1.05046 Val Loss = 1.77351
2023-09-25 12:10:29.044543 Epoch 29  	Train Loss = 1.10307 Val Loss = 1.74114
2023-09-25 12:13:24.820958 Epoch 30  	Train Loss = 1.14236 Val Loss = 1.74659
2023-09-25 12:16:21.089969 Epoch 31  	Train Loss = 1.19562 Val Loss = 1.69142
2023-09-25 12:19:18.543150 Epoch 32  	Train Loss = 1.23275 Val Loss = 1.71410
2023-09-25 12:22:15.018409 Epoch 33  	Train Loss = 1.27889 Val Loss = 1.66966
2023-09-25 12:25:10.862982 Epoch 34  	Train Loss = 1.31730 Val Loss = 1.64018
2023-09-25 12:28:06.187723 Epoch 35  	Train Loss = 1.34094 Val Loss = 1.64412
2023-09-25 12:31:02.690201 Epoch 36  	Train Loss = 1.35335 Val Loss = 1.62391
2023-09-25 12:34:00.593602 Epoch 37  	Train Loss = 1.37322 Val Loss = 1.65619
2023-09-25 12:36:56.945287 Epoch 38  	Train Loss = 1.35964 Val Loss = 1.60303
2023-09-25 12:39:52.834948 Epoch 39  	Train Loss = 1.37712 Val Loss = 1.61303
2023-09-25 12:42:48.184118 Epoch 40  	Train Loss = 1.37192 Val Loss = 1.58347
2023-09-25 12:45:43.507895 Epoch 41  	Train Loss = 1.38572 Val Loss = 1.61573
2023-09-25 12:48:38.720521 Epoch 42  	Train Loss = 1.37787 Val Loss = 1.59372
2023-09-25 12:51:34.137963 Epoch 43  	Train Loss = 1.37427 Val Loss = 1.59351
2023-09-25 12:54:29.602905 Epoch 44  	Train Loss = 1.37315 Val Loss = 1.59584
2023-09-25 12:57:24.843375 Epoch 45  	Train Loss = 1.36743 Val Loss = 1.58758
2023-09-25 13:00:19.900676 Epoch 46  	Train Loss = 1.36573 Val Loss = 1.60320
2023-09-25 13:03:15.290822 Epoch 47  	Train Loss = 1.35869 Val Loss = 1.59841
2023-09-25 13:06:10.461388 Epoch 48  	Train Loss = 1.35494 Val Loss = 1.58744
2023-09-25 13:09:05.542513 Epoch 49  	Train Loss = 1.35100 Val Loss = 1.57707
2023-09-25 13:12:00.584552 Epoch 50  	Train Loss = 1.34321 Val Loss = 1.57825
2023-09-25 13:14:56.265327 Epoch 51  	Train Loss = 1.28172 Val Loss = 1.54967
2023-09-25 13:17:53.158169 Epoch 52  	Train Loss = 1.27022 Val Loss = 1.55320
2023-09-25 13:20:50.493345 Epoch 53  	Train Loss = 1.26525 Val Loss = 1.55199
2023-09-25 13:23:46.612556 Epoch 54  	Train Loss = 1.26234 Val Loss = 1.55350
2023-09-25 13:26:42.139854 Epoch 55  	Train Loss = 1.25944 Val Loss = 1.55418
2023-09-25 13:29:37.169111 Epoch 56  	Train Loss = 1.25668 Val Loss = 1.55469
2023-09-25 13:32:32.975664 Epoch 57  	Train Loss = 1.25460 Val Loss = 1.55858
2023-09-25 13:35:30.818144 Epoch 58  	Train Loss = 1.25226 Val Loss = 1.55656
2023-09-25 13:38:27.209347 Epoch 59  	Train Loss = 1.25026 Val Loss = 1.55752
2023-09-25 13:41:23.159736 Epoch 60  	Train Loss = 1.24809 Val Loss = 1.56039
2023-09-25 13:44:18.589196 Epoch 61  	Train Loss = 1.24628 Val Loss = 1.56258
2023-09-25 13:47:14.403743 Epoch 62  	Train Loss = 1.24453 Val Loss = 1.56369
2023-09-25 13:50:12.679135 Epoch 63  	Train Loss = 1.24290 Val Loss = 1.56097
2023-09-25 13:53:09.686974 Epoch 64  	Train Loss = 1.24096 Val Loss = 1.56387
2023-09-25 13:56:05.457308 Epoch 65  	Train Loss = 1.23942 Val Loss = 1.56573
2023-09-25 13:59:00.318160 Epoch 66  	Train Loss = 1.23765 Val Loss = 1.56290
2023-09-25 14:01:56.008495 Epoch 67  	Train Loss = 1.23635 Val Loss = 1.56381
2023-09-25 14:04:53.377677 Epoch 68  	Train Loss = 1.23481 Val Loss = 1.56616
2023-09-25 14:07:49.791056 Epoch 69  	Train Loss = 1.23339 Val Loss = 1.56930
2023-09-25 14:10:45.680510 Epoch 70  	Train Loss = 1.23190 Val Loss = 1.56419
2023-09-25 14:13:41.281236 Epoch 71  	Train Loss = 1.23055 Val Loss = 1.57018
2023-09-25 14:16:36.793516 Epoch 72  	Train Loss = 1.22913 Val Loss = 1.56974
2023-09-25 14:19:33.674492 Epoch 73  	Train Loss = 1.22790 Val Loss = 1.57025
2023-09-25 14:22:30.848970 Epoch 74  	Train Loss = 1.22655 Val Loss = 1.57014
2023-09-25 14:25:25.543910 Epoch 75  	Train Loss = 1.22567 Val Loss = 1.57493
2023-09-25 14:28:18.640642 Epoch 76  	Train Loss = 1.22414 Val Loss = 1.57164
2023-09-25 14:31:10.910587 Epoch 77  	Train Loss = 1.22283 Val Loss = 1.57248
2023-09-25 14:34:03.974361 Epoch 78  	Train Loss = 1.22161 Val Loss = 1.57226
2023-09-25 14:36:58.904499 Epoch 79  	Train Loss = 1.22085 Val Loss = 1.57124
2023-09-25 14:39:53.467445 Epoch 80  	Train Loss = 1.21964 Val Loss = 1.57552
2023-09-25 14:42:47.696507 Epoch 81  	Train Loss = 1.21833 Val Loss = 1.57597
Early stopping at epoch: 81
Best at epoch 51:
Train Loss = 1.28172
Train RMSE = 2.53651, MAE = 1.21375, MAPE = 2.48893
Val Loss = 1.54967
Val RMSE = 3.69167, MAE = 1.56430, MAPE = 3.56156
--------- Test ---------
All Steps RMSE = 3.69270, MAE = 1.57098, MAPE = 3.54614
Step 1 RMSE = 1.54304, MAE = 0.85406, MAPE = 1.64940
Step 2 RMSE = 2.20660, MAE = 1.11485, MAPE = 2.25467
Step 3 RMSE = 2.75465, MAE = 1.29908, MAPE = 2.73155
Step 4 RMSE = 3.19667, MAE = 1.44005, MAPE = 3.12324
Step 5 RMSE = 3.53228, MAE = 1.54783, MAPE = 3.43537
Step 6 RMSE = 3.78877, MAE = 1.63347, MAPE = 3.68978
Step 7 RMSE = 3.99289, MAE = 1.70441, MAPE = 3.90363
Step 8 RMSE = 4.15368, MAE = 1.76286, MAPE = 4.08252
Step 9 RMSE = 4.28261, MAE = 1.81263, MAPE = 4.23525
Step 10 RMSE = 4.39081, MAE = 1.85626, MAPE = 4.36857
Step 11 RMSE = 4.48243, MAE = 1.89490, MAPE = 4.48578
Step 12 RMSE = 4.56459, MAE = 1.93128, MAPE = 4.59394
Inference time: 19.58 s
