PEMS08
Trainset:	x-(10700, 12, 170, 3)	y-(10700, 12, 170, 1)
Valset:  	x-(3567, 12, 170, 3)  	y-(3567, 12, 170, 1)
Testset:	x-(3566, 12, 170, 3)	y-(3566, 12, 170, 1)

--------- STAttention ---------
{
    "num_nodes": 170,
    "in_steps": 12,
    "out_steps": 12,
    "train_size": 0.7,
    "val_size": 0.1,
    "time_of_day": true,
    "day_of_week": true,
    "lr": 0.001,
    "weight_decay": 0.0001,
    "milestones": [
        10,
        30
    ],
    "batch_size": 64,
    "max_epochs": 200,
    "use_cl": false,
    "cl_step_size": 2500,
    "model_args": {
        "num_nodes": 170,
        "in_steps": 12,
        "out_steps": 12,
        "steps_per_day": 288,
        "input_dim": 1,
        "output_dim": 1,
        "input_embedding_dim": 12,
        "tod_embedding_dim": 12,
        "dow_embedding_dim": 12,
        "adaptive_embedding_dim": 60,
        "feed_forward_dim": 256,
        "num_heads": 4,
        "num_layers": 3,
        "dropout": 0.1
    }
}
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
STAttention                              --                        --
├─ModuleList: 1-1                        --                        --
├─ModuleList: 1-2                        --                        --
├─Linear: 1-3                            [64, 12, 170, 12]         24
├─Embedding: 1-4                         [64, 12, 170, 12]         3,456
├─Embedding: 1-5                         [64, 12, 170, 12]         84
├─ModuleList: 1-1                        --                        --
│    └─SelfAttentionLayer: 2-1           [64, 12, 170, 96]         --
│    │    └─AttentionLayer: 3-1          [64, 170, 12, 96]         37,248
│    │    └─Dropout: 3-2                 [64, 170, 12, 96]         --
│    │    └─LayerNorm: 3-3               [64, 170, 12, 96]         192
│    │    └─Sequential: 3-4              [64, 170, 12, 96]         49,504
│    │    └─Dropout: 3-5                 [64, 170, 12, 96]         --
│    │    └─LayerNorm: 3-6               [64, 170, 12, 96]         192
│    └─SelfAttentionLayer: 2-2           [64, 12, 170, 96]         --
│    │    └─AttentionLayer: 3-7          [64, 170, 12, 96]         37,248
│    │    └─Dropout: 3-8                 [64, 170, 12, 96]         --
│    │    └─LayerNorm: 3-9               [64, 170, 12, 96]         192
│    │    └─Sequential: 3-10             [64, 170, 12, 96]         49,504
│    │    └─Dropout: 3-11                [64, 170, 12, 96]         --
│    │    └─LayerNorm: 3-12              [64, 170, 12, 96]         192
│    └─SelfAttentionLayer: 2-3           [64, 12, 170, 96]         --
│    │    └─AttentionLayer: 3-13         [64, 170, 12, 96]         37,248
│    │    └─Dropout: 3-14                [64, 170, 12, 96]         --
│    │    └─LayerNorm: 3-15              [64, 170, 12, 96]         192
│    │    └─Sequential: 3-16             [64, 170, 12, 96]         49,504
│    │    └─Dropout: 3-17                [64, 170, 12, 96]         --
│    │    └─LayerNorm: 3-18              [64, 170, 12, 96]         192
├─ModuleList: 1-2                        --                        --
│    └─SelfAttentionLayer: 2-4           [64, 12, 170, 96]         --
│    │    └─AttentionLayer: 3-19         [64, 12, 170, 96]         37,248
│    │    └─Dropout: 3-20                [64, 12, 170, 96]         --
│    │    └─LayerNorm: 3-21              [64, 12, 170, 96]         192
│    │    └─Sequential: 3-22             [64, 12, 170, 96]         49,504
│    │    └─Dropout: 3-23                [64, 12, 170, 96]         --
│    │    └─LayerNorm: 3-24              [64, 12, 170, 96]         192
│    └─SelfAttentionLayer: 2-5           [64, 12, 170, 96]         --
│    │    └─AttentionLayer: 3-25         [64, 12, 170, 96]         37,248
│    │    └─Dropout: 3-26                [64, 12, 170, 96]         --
│    │    └─LayerNorm: 3-27              [64, 12, 170, 96]         192
│    │    └─Sequential: 3-28             [64, 12, 170, 96]         49,504
│    │    └─Dropout: 3-29                [64, 12, 170, 96]         --
│    │    └─LayerNorm: 3-30              [64, 12, 170, 96]         192
│    └─SelfAttentionLayer: 2-6           [64, 12, 170, 96]         --
│    │    └─AttentionLayer: 3-31         [64, 12, 170, 96]         37,248
│    │    └─Dropout: 3-32                [64, 12, 170, 96]         --
│    │    └─LayerNorm: 3-33              [64, 12, 170, 96]         192
│    │    └─Sequential: 3-34             [64, 12, 170, 96]         49,504
│    │    └─Dropout: 3-35                [64, 12, 170, 96]         --
│    │    └─LayerNorm: 3-36              [64, 12, 170, 96]         192
├─Linear: 1-6                            [64, 96, 170, 12]         156
├─Linear: 1-7                            [64, 12, 170, 1]          97
==========================================================================================
Total params: 526,633
Trainable params: 526,633
Non-trainable params: 0
Total mult-adds (M): 33.70
==========================================================================================
Input size (MB): 1.57
Forward/backward pass size (MB): 5954.58
Params size (MB): 2.11
Estimated Total Size (MB): 5958.25
==========================================================================================

Loss: HuberLoss

2023-04-12 20:43:06.622626 Epoch 1  	Train Loss = 45.57818 Val Loss = 22.01403
2023-04-12 20:43:48.317205 Epoch 2  	Train Loss = 20.11544 Val Loss = 19.72481
2023-04-12 20:44:30.636176 Epoch 3  	Train Loss = 19.25329 Val Loss = 18.72031
2023-04-12 20:45:13.523924 Epoch 4  	Train Loss = 18.22728 Val Loss = 17.79933
2023-04-12 20:45:56.655871 Epoch 5  	Train Loss = 17.50028 Val Loss = 17.13705
2023-04-12 20:46:39.895623 Epoch 6  	Train Loss = 17.03835 Val Loss = 16.70813
2023-04-12 20:47:23.166701 Epoch 7  	Train Loss = 16.60022 Val Loss = 16.75549
2023-04-12 20:48:06.204690 Epoch 8  	Train Loss = 16.16906 Val Loss = 16.14885
2023-04-12 20:48:49.605528 Epoch 9  	Train Loss = 15.98519 Val Loss = 15.72815
2023-04-12 20:49:32.912514 Epoch 10  	Train Loss = 15.66575 Val Loss = 15.66203
2023-04-12 20:50:16.360785 Epoch 11  	Train Loss = 15.26251 Val Loss = 15.33669
2023-04-12 20:50:59.738425 Epoch 12  	Train Loss = 15.20718 Val Loss = 15.28499
2023-04-12 20:51:42.747780 Epoch 13  	Train Loss = 15.17601 Val Loss = 15.21429
2023-04-12 20:52:25.741584 Epoch 14  	Train Loss = 15.13803 Val Loss = 15.28606
2023-04-12 20:53:08.691921 Epoch 15  	Train Loss = 15.13702 Val Loss = 15.18899
2023-04-12 20:53:51.719105 Epoch 16  	Train Loss = 15.09818 Val Loss = 15.19693
2023-04-12 20:54:34.610314 Epoch 17  	Train Loss = 15.06173 Val Loss = 15.16781
2023-04-12 20:55:17.681677 Epoch 18  	Train Loss = 15.02122 Val Loss = 15.12980
2023-04-12 20:56:00.784673 Epoch 19  	Train Loss = 14.98630 Val Loss = 15.15590
2023-04-12 20:56:43.331370 Epoch 20  	Train Loss = 14.95950 Val Loss = 15.13537
2023-04-12 20:57:26.407017 Epoch 21  	Train Loss = 14.95034 Val Loss = 15.08032
2023-04-12 20:58:09.600570 Epoch 22  	Train Loss = 14.89390 Val Loss = 15.08088
2023-04-12 20:58:52.738822 Epoch 23  	Train Loss = 14.85919 Val Loss = 15.05824
2023-04-12 20:59:36.017071 Epoch 24  	Train Loss = 14.82400 Val Loss = 15.00975
2023-04-12 21:00:19.112799 Epoch 25  	Train Loss = 14.79427 Val Loss = 14.92984
2023-04-12 21:01:02.348327 Epoch 26  	Train Loss = 14.77831 Val Loss = 14.86454
2023-04-12 21:01:45.615304 Epoch 27  	Train Loss = 14.72965 Val Loss = 14.90545
2023-04-12 21:02:28.809470 Epoch 28  	Train Loss = 14.71457 Val Loss = 15.06361
2023-04-12 21:03:12.212529 Epoch 29  	Train Loss = 14.69452 Val Loss = 14.93191
2023-04-12 21:03:55.524470 Epoch 30  	Train Loss = 14.66143 Val Loss = 14.84571
2023-04-12 21:04:38.879342 Epoch 31  	Train Loss = 14.57662 Val Loss = 14.80433
2023-04-12 21:05:22.053455 Epoch 32  	Train Loss = 14.58329 Val Loss = 14.78311
2023-04-12 21:06:05.170210 Epoch 33  	Train Loss = 14.57801 Val Loss = 14.78655
2023-04-12 21:06:48.205982 Epoch 34  	Train Loss = 14.57995 Val Loss = 14.78724
2023-04-12 21:07:31.096944 Epoch 35  	Train Loss = 14.57502 Val Loss = 14.77848
2023-04-12 21:08:14.035986 Epoch 36  	Train Loss = 14.57221 Val Loss = 14.77135
2023-04-12 21:08:57.086371 Epoch 37  	Train Loss = 14.57256 Val Loss = 14.78514
2023-04-12 21:09:40.105415 Epoch 38  	Train Loss = 14.55572 Val Loss = 14.78168
2023-04-12 21:10:22.787540 Epoch 39  	Train Loss = 14.56830 Val Loss = 14.78604
2023-04-12 21:11:05.676812 Epoch 40  	Train Loss = 14.55533 Val Loss = 14.76415
2023-04-12 21:11:48.632258 Epoch 41  	Train Loss = 14.55664 Val Loss = 14.77460
2023-04-12 21:12:31.624966 Epoch 42  	Train Loss = 14.53689 Val Loss = 14.75638
2023-04-12 21:13:14.767535 Epoch 43  	Train Loss = 14.55696 Val Loss = 14.76889
2023-04-12 21:13:57.814178 Epoch 44  	Train Loss = 14.53182 Val Loss = 14.73646
2023-04-12 21:14:40.619432 Epoch 45  	Train Loss = 14.52214 Val Loss = 14.74002
2023-04-12 21:15:23.727983 Epoch 46  	Train Loss = 14.51925 Val Loss = 14.74022
2023-04-12 21:16:06.897137 Epoch 47  	Train Loss = 14.52443 Val Loss = 14.75234
2023-04-12 21:16:50.109028 Epoch 48  	Train Loss = 14.52559 Val Loss = 14.73501
2023-04-12 21:17:33.288433 Epoch 49  	Train Loss = 14.52549 Val Loss = 14.72158
2023-04-12 21:18:16.425557 Epoch 50  	Train Loss = 14.49488 Val Loss = 14.73736
2023-04-12 21:18:59.640871 Epoch 51  	Train Loss = 14.49970 Val Loss = 14.72815
2023-04-12 21:19:42.864495 Epoch 52  	Train Loss = 14.49827 Val Loss = 14.70966
2023-04-12 21:20:25.903687 Epoch 53  	Train Loss = 14.50257 Val Loss = 14.73363
2023-04-12 21:21:08.228873 Epoch 54  	Train Loss = 14.49066 Val Loss = 14.70617
2023-04-12 21:21:51.078751 Epoch 55  	Train Loss = 14.49140 Val Loss = 14.72130
2023-04-12 21:22:34.002656 Epoch 56  	Train Loss = 14.47891 Val Loss = 14.71795
2023-04-12 21:23:16.920111 Epoch 57  	Train Loss = 14.48062 Val Loss = 14.69792
2023-04-12 21:23:59.764698 Epoch 58  	Train Loss = 14.47766 Val Loss = 14.71739
2023-04-12 21:24:42.698331 Epoch 59  	Train Loss = 14.47888 Val Loss = 14.71104
2023-04-12 21:25:25.586623 Epoch 60  	Train Loss = 14.46149 Val Loss = 14.69691
2023-04-12 21:26:08.100115 Epoch 61  	Train Loss = 14.44843 Val Loss = 14.69201
2023-04-12 21:26:51.042853 Epoch 62  	Train Loss = 14.46086 Val Loss = 14.69414
2023-04-12 21:27:34.078516 Epoch 63  	Train Loss = 14.44525 Val Loss = 14.69815
2023-04-12 21:28:17.119373 Epoch 64  	Train Loss = 14.45285 Val Loss = 14.67320
2023-04-12 21:29:00.139308 Epoch 65  	Train Loss = 14.44705 Val Loss = 14.66707
2023-04-12 21:29:43.263040 Epoch 66  	Train Loss = 14.43614 Val Loss = 14.71964
2023-04-12 21:30:26.287240 Epoch 67  	Train Loss = 14.43156 Val Loss = 14.67081
2023-04-12 21:31:09.387050 Epoch 68  	Train Loss = 14.44082 Val Loss = 14.67146
2023-04-12 21:31:52.470277 Epoch 69  	Train Loss = 14.42132 Val Loss = 14.67499
2023-04-12 21:32:35.237978 Epoch 70  	Train Loss = 14.42190 Val Loss = 14.67883
2023-04-12 21:33:18.232440 Epoch 71  	Train Loss = 14.41700 Val Loss = 14.67350
2023-04-12 21:34:01.191821 Epoch 72  	Train Loss = 14.41951 Val Loss = 14.66458
2023-04-12 21:34:44.062289 Epoch 73  	Train Loss = 14.40541 Val Loss = 14.65546
2023-04-12 21:35:26.812140 Epoch 74  	Train Loss = 14.39899 Val Loss = 14.65711
2023-04-12 21:36:09.571606 Epoch 75  	Train Loss = 14.39519 Val Loss = 14.66666
2023-04-12 21:36:52.209760 Epoch 76  	Train Loss = 14.40241 Val Loss = 14.65663
2023-04-12 21:37:34.998048 Epoch 77  	Train Loss = 14.38855 Val Loss = 14.68065
2023-04-12 21:38:17.520732 Epoch 78  	Train Loss = 14.39593 Val Loss = 14.65452
2023-04-12 21:39:00.308080 Epoch 79  	Train Loss = 14.38951 Val Loss = 14.64282
2023-04-12 21:39:43.184711 Epoch 80  	Train Loss = 14.37428 Val Loss = 14.62309
2023-04-12 21:40:26.067609 Epoch 81  	Train Loss = 14.37083 Val Loss = 14.65698
2023-04-12 21:41:09.065685 Epoch 82  	Train Loss = 14.36130 Val Loss = 14.63227
2023-04-12 21:41:52.208590 Epoch 83  	Train Loss = 14.36628 Val Loss = 14.62909
2023-04-12 21:42:35.185598 Epoch 84  	Train Loss = 14.37092 Val Loss = 14.61890
2023-04-12 21:43:18.076437 Epoch 85  	Train Loss = 14.36180 Val Loss = 14.63363
2023-04-12 21:44:01.062269 Epoch 86  	Train Loss = 14.34885 Val Loss = 14.63169
2023-04-12 21:44:43.796670 Epoch 87  	Train Loss = 14.35077 Val Loss = 14.62390
2023-04-12 21:45:26.529241 Epoch 88  	Train Loss = 14.34818 Val Loss = 14.62448
2023-04-12 21:46:09.421948 Epoch 89  	Train Loss = 14.33759 Val Loss = 14.62888
2023-04-12 21:46:52.152985 Epoch 90  	Train Loss = 14.34183 Val Loss = 14.61104
2023-04-12 21:47:34.892338 Epoch 91  	Train Loss = 14.32933 Val Loss = 14.60128
2023-04-12 21:48:17.893920 Epoch 92  	Train Loss = 14.33255 Val Loss = 14.60502
2023-04-12 21:49:00.627099 Epoch 93  	Train Loss = 14.32147 Val Loss = 14.60737
2023-04-12 21:49:43.044790 Epoch 94  	Train Loss = 14.32311 Val Loss = 14.60887
2023-04-12 21:50:25.486604 Epoch 95  	Train Loss = 14.32238 Val Loss = 14.60243
2023-04-12 21:51:07.861515 Epoch 96  	Train Loss = 14.30433 Val Loss = 14.62380
2023-04-12 21:51:50.310683 Epoch 97  	Train Loss = 14.32113 Val Loss = 14.58404
2023-04-12 21:52:32.690996 Epoch 98  	Train Loss = 14.30518 Val Loss = 14.58552
2023-04-12 21:53:15.166928 Epoch 99  	Train Loss = 14.29974 Val Loss = 14.58744
2023-04-12 21:53:57.618024 Epoch 100  	Train Loss = 14.30396 Val Loss = 14.58906
2023-04-12 21:54:39.987102 Epoch 101  	Train Loss = 14.29488 Val Loss = 14.61313
2023-04-12 21:55:22.459185 Epoch 102  	Train Loss = 14.28067 Val Loss = 14.56368
2023-04-12 21:56:05.073051 Epoch 103  	Train Loss = 14.29169 Val Loss = 14.57130
2023-04-12 21:56:47.755488 Epoch 104  	Train Loss = 14.28950 Val Loss = 14.56717
2023-04-12 21:57:30.490569 Epoch 105  	Train Loss = 14.26881 Val Loss = 14.55637
2023-04-12 21:58:13.315160 Epoch 106  	Train Loss = 14.29510 Val Loss = 14.57985
2023-04-12 21:58:56.133497 Epoch 107  	Train Loss = 14.26862 Val Loss = 14.57242
2023-04-12 21:59:38.891391 Epoch 108  	Train Loss = 14.27771 Val Loss = 14.57113
2023-04-12 22:00:21.717861 Epoch 109  	Train Loss = 14.26723 Val Loss = 14.58854
2023-04-12 22:01:04.446121 Epoch 110  	Train Loss = 14.26213 Val Loss = 14.56178
2023-04-12 22:01:47.258080 Epoch 111  	Train Loss = 14.25903 Val Loss = 14.56781
2023-04-12 22:02:30.059882 Epoch 112  	Train Loss = 14.25210 Val Loss = 14.55265
2023-04-12 22:03:12.694658 Epoch 113  	Train Loss = 14.25276 Val Loss = 14.55577
2023-04-12 22:03:55.141064 Epoch 114  	Train Loss = 14.24828 Val Loss = 14.56338
2023-04-12 22:04:37.528779 Epoch 115  	Train Loss = 14.24100 Val Loss = 14.56606
2023-04-12 22:05:20.014877 Epoch 116  	Train Loss = 14.23336 Val Loss = 14.53840
2023-04-12 22:06:02.409155 Epoch 117  	Train Loss = 14.23953 Val Loss = 14.55681
2023-04-12 22:06:44.818887 Epoch 118  	Train Loss = 14.22922 Val Loss = 14.55027
2023-04-12 22:07:27.208616 Epoch 119  	Train Loss = 14.22963 Val Loss = 14.52987
2023-04-12 22:08:09.589387 Epoch 120  	Train Loss = 14.22729 Val Loss = 14.52555
2023-04-12 22:08:51.994117 Epoch 121  	Train Loss = 14.22133 Val Loss = 14.52220
2023-04-12 22:09:34.333451 Epoch 122  	Train Loss = 14.22003 Val Loss = 14.54758
2023-04-12 22:10:16.815762 Epoch 123  	Train Loss = 14.21011 Val Loss = 14.53641
2023-04-12 22:10:59.397547 Epoch 124  	Train Loss = 14.20718 Val Loss = 14.53633
2023-04-12 22:11:42.125355 Epoch 125  	Train Loss = 14.21393 Val Loss = 14.54431
2023-04-12 22:12:24.851489 Epoch 126  	Train Loss = 14.20386 Val Loss = 14.52888
2023-04-12 22:13:07.589798 Epoch 127  	Train Loss = 14.20606 Val Loss = 14.51173
2023-04-12 22:13:49.963504 Epoch 128  	Train Loss = 14.19758 Val Loss = 14.52395
2023-04-12 22:14:32.785757 Epoch 129  	Train Loss = 14.19131 Val Loss = 14.49485
2023-04-12 22:15:15.544599 Epoch 130  	Train Loss = 14.19054 Val Loss = 14.51911
2023-04-12 22:15:58.325307 Epoch 131  	Train Loss = 14.18912 Val Loss = 14.50487
2023-04-12 22:16:41.113222 Epoch 132  	Train Loss = 14.18467 Val Loss = 14.51949
2023-04-12 22:17:23.607407 Epoch 133  	Train Loss = 14.17923 Val Loss = 14.49781
2023-04-12 22:18:06.186928 Epoch 134  	Train Loss = 14.17669 Val Loss = 14.49990
2023-04-12 22:18:48.594326 Epoch 135  	Train Loss = 14.16555 Val Loss = 14.49059
2023-04-12 22:19:30.983393 Epoch 136  	Train Loss = 14.17666 Val Loss = 14.49705
2023-04-12 22:20:13.326946 Epoch 137  	Train Loss = 14.16632 Val Loss = 14.50524
2023-04-12 22:20:55.720676 Epoch 138  	Train Loss = 14.15971 Val Loss = 14.47024
2023-04-12 22:21:38.140984 Epoch 139  	Train Loss = 14.15530 Val Loss = 14.49776
2023-04-12 22:22:20.503882 Epoch 140  	Train Loss = 14.15260 Val Loss = 14.47865
2023-04-12 22:23:02.823429 Epoch 141  	Train Loss = 14.15107 Val Loss = 14.49299
2023-04-12 22:23:45.135139 Epoch 142  	Train Loss = 14.15432 Val Loss = 14.48273
2023-04-12 22:24:27.504067 Epoch 143  	Train Loss = 14.15153 Val Loss = 14.47391
2023-04-12 22:25:09.954953 Epoch 144  	Train Loss = 14.14315 Val Loss = 14.47809
2023-04-12 22:25:52.496384 Epoch 145  	Train Loss = 14.12399 Val Loss = 14.46091
2023-04-12 22:26:35.101852 Epoch 146  	Train Loss = 14.13603 Val Loss = 14.47798
2023-04-12 22:27:17.700403 Epoch 147  	Train Loss = 14.14122 Val Loss = 14.47189
2023-04-12 22:28:00.275454 Epoch 148  	Train Loss = 14.12054 Val Loss = 14.47905
2023-04-12 22:28:42.847345 Epoch 149  	Train Loss = 14.12066 Val Loss = 14.49199
2023-04-12 22:29:25.477437 Epoch 150  	Train Loss = 14.11913 Val Loss = 14.48322
2023-04-12 22:30:08.211870 Epoch 151  	Train Loss = 14.11197 Val Loss = 14.46457
2023-04-12 22:30:50.891599 Epoch 152  	Train Loss = 14.12442 Val Loss = 14.47669
2023-04-12 22:31:33.570090 Epoch 153  	Train Loss = 14.09451 Val Loss = 14.48314
2023-04-12 22:32:14.755376 Epoch 154  	Train Loss = 14.10174 Val Loss = 14.44235
2023-04-12 22:32:56.803608 Epoch 155  	Train Loss = 14.09667 Val Loss = 14.44086
2023-04-12 22:33:39.173889 Epoch 156  	Train Loss = 14.08717 Val Loss = 14.47140
2023-04-12 22:34:20.657710 Epoch 157  	Train Loss = 14.08831 Val Loss = 14.45782
2023-04-12 22:35:02.190943 Epoch 158  	Train Loss = 14.10062 Val Loss = 14.43960
2023-04-12 22:35:44.628946 Epoch 159  	Train Loss = 14.08830 Val Loss = 14.44792
2023-04-12 22:36:26.991115 Epoch 160  	Train Loss = 14.07209 Val Loss = 14.46056
2023-04-12 22:37:09.405852 Epoch 161  	Train Loss = 14.08632 Val Loss = 14.44400
2023-04-12 22:37:51.898421 Epoch 162  	Train Loss = 14.06518 Val Loss = 14.42557
2023-04-12 22:38:34.313923 Epoch 163  	Train Loss = 14.06919 Val Loss = 14.46075
2023-04-12 22:39:16.889764 Epoch 164  	Train Loss = 14.06885 Val Loss = 14.43218
2023-04-12 22:39:59.550165 Epoch 165  	Train Loss = 14.07390 Val Loss = 14.47983
2023-04-12 22:40:42.270078 Epoch 166  	Train Loss = 14.07215 Val Loss = 14.45825
2023-04-12 22:41:25.083460 Epoch 167  	Train Loss = 14.06536 Val Loss = 14.45989
2023-04-12 22:42:07.925428 Epoch 168  	Train Loss = 14.06469 Val Loss = 14.41124
2023-04-12 22:42:50.712752 Epoch 169  	Train Loss = 14.06048 Val Loss = 14.43908
2023-04-12 22:43:33.517570 Epoch 170  	Train Loss = 14.04627 Val Loss = 14.40482
2023-04-12 22:44:16.297208 Epoch 171  	Train Loss = 14.04761 Val Loss = 14.43191
2023-04-12 22:44:59.023312 Epoch 172  	Train Loss = 14.04434 Val Loss = 14.42054
2023-04-12 22:45:41.772814 Epoch 173  	Train Loss = 14.04922 Val Loss = 14.41160
2023-04-12 22:46:24.456251 Epoch 174  	Train Loss = 14.03072 Val Loss = 14.41995
2023-04-12 22:47:06.900704 Epoch 175  	Train Loss = 14.03940 Val Loss = 14.45330
2023-04-12 22:47:49.302881 Epoch 176  	Train Loss = 14.03567 Val Loss = 14.40814
2023-04-12 22:48:31.642316 Epoch 177  	Train Loss = 14.03585 Val Loss = 14.41843
2023-04-12 22:49:14.022326 Epoch 178  	Train Loss = 14.03589 Val Loss = 14.40329
2023-04-12 22:49:56.414707 Epoch 179  	Train Loss = 14.03214 Val Loss = 14.42069
2023-04-12 22:50:38.854650 Epoch 180  	Train Loss = 14.01438 Val Loss = 14.40052
2023-04-12 22:51:21.233560 Epoch 181  	Train Loss = 14.01894 Val Loss = 14.40085
2023-04-12 22:52:03.683700 Epoch 182  	Train Loss = 14.01287 Val Loss = 14.39202
2023-04-12 22:52:46.139420 Epoch 183  	Train Loss = 14.01656 Val Loss = 14.40225
2023-04-12 22:53:28.600648 Epoch 184  	Train Loss = 14.01333 Val Loss = 14.39053
2023-04-12 22:54:11.161020 Epoch 185  	Train Loss = 14.00825 Val Loss = 14.41901
2023-04-12 22:54:53.859595 Epoch 186  	Train Loss = 14.00176 Val Loss = 14.42082
2023-04-12 22:55:36.613844 Epoch 187  	Train Loss = 14.01029 Val Loss = 14.38810
2023-04-12 22:56:19.420271 Epoch 188  	Train Loss = 13.99945 Val Loss = 14.40032
2023-04-12 22:57:02.156599 Epoch 189  	Train Loss = 13.99845 Val Loss = 14.38512
2023-04-12 22:57:44.952354 Epoch 190  	Train Loss = 13.99517 Val Loss = 14.39416
2023-04-12 22:58:27.718336 Epoch 191  	Train Loss = 13.98948 Val Loss = 14.37143
2023-04-12 22:59:10.518180 Epoch 192  	Train Loss = 13.98461 Val Loss = 14.37312
2023-04-12 22:59:53.078366 Epoch 193  	Train Loss = 13.98328 Val Loss = 14.38328
2023-04-12 23:00:35.786709 Epoch 194  	Train Loss = 13.98406 Val Loss = 14.40925
2023-04-12 23:01:18.409580 Epoch 195  	Train Loss = 13.97437 Val Loss = 14.40246
2023-04-12 23:02:00.896581 Epoch 196  	Train Loss = 13.97891 Val Loss = 14.39324
2023-04-12 23:02:42.673088 Epoch 197  	Train Loss = 13.97659 Val Loss = 14.37820
2023-04-12 23:03:25.207591 Epoch 198  	Train Loss = 13.96911 Val Loss = 14.39931
2023-04-12 23:04:07.569956 Epoch 199  	Train Loss = 13.95506 Val Loss = 14.37533
2023-04-12 23:04:49.966081 Epoch 200  	Train Loss = 13.95423 Val Loss = 14.37256
Early stopping at epoch: 200
Best at epoch 191:
Train Loss = 13.98948
Train RMSE = 24.02927, MAE = 14.23928, MAPE = 9.44062
Val Loss = 14.37143
Val RMSE = 24.67067, MAE = 14.82097, MAPE = 10.74181
--------- Test ---------
All Steps RMSE = 23.63868, MAE = 14.59488, MAPE = 9.61514
Step 1 RMSE = 20.77316, MAE = 13.31047, MAPE = 8.89140
Step 2 RMSE = 21.59020, MAE = 13.59728, MAPE = 8.90839
Step 3 RMSE = 22.12053, MAE = 13.76925, MAPE = 8.99487
Step 4 RMSE = 22.75529, MAE = 14.15301, MAPE = 9.39033
Step 5 RMSE = 23.24950, MAE = 14.41612, MAPE = 9.49038
Step 6 RMSE = 23.64049, MAE = 14.59963, MAPE = 9.60554
Step 7 RMSE = 23.90963, MAE = 14.64865, MAPE = 9.66140
Step 8 RMSE = 24.34875, MAE = 14.98711, MAPE = 9.89822
Step 9 RMSE = 24.60575, MAE = 15.05107, MAPE = 9.96168
Step 10 RMSE = 24.96261, MAE = 15.29636, MAPE = 10.05012
Step 11 RMSE = 25.29163, MAE = 15.45390, MAPE = 10.17428
Step 12 RMSE = 25.85502, MAE = 15.85569, MAPE = 10.35505
Inference time: 4.12 s
