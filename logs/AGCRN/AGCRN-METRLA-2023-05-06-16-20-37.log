METRLA
Trainset:	x-(23974, 12, 207, 2)	y-(23974, 12, 207, 1)
Valset:  	x-(3425, 12, 207, 2)  	y-(3425, 12, 207, 1)
Testset:	x-(6850, 12, 207, 2)	y-(6850, 12, 207, 1)

--------- AGCRN ---------
{
    "num_nodes": 207,
    "in_steps": 12,
    "out_steps": 12,
    "train_size": 0.7,
    "val_size": 0.1,
    "time_of_day": true,
    "lr": 0.001,
    "milestones": [
        25
    ],
    "clip_grad": 0,
    "batch_size": 64,
    "max_epochs": 200,
    "early_stop": 20,
    "use_cl": false,
    "cl_step_size": 2500,
    "model_args": {
        "num_nodes": 207,
        "out_steps": 12,
        "input_dim": 2,
        "output_dim": 1,
        "embed_dim": 10,
        "rnn_units": 64,
        "num_layers": 2,
        "cheb_k": 2,
        "default_graph": true
    }
}
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
AGCRN                                    [64, 12, 207, 1]          2,070
├─AVWDCRNN: 1-1                          [64, 12, 207, 64]         --
│    └─ModuleList: 2-1                   --                        --
│    │    └─AGCRNCell: 3-1               [64, 207, 64]             255,360
│    │    └─AGCRNCell: 3-2               [64, 207, 64]             (recursive)
│    │    └─AGCRNCell: 3-3               [64, 207, 64]             (recursive)
│    │    └─AGCRNCell: 3-4               [64, 207, 64]             (recursive)
│    │    └─AGCRNCell: 3-5               [64, 207, 64]             (recursive)
│    │    └─AGCRNCell: 3-6               [64, 207, 64]             (recursive)
│    │    └─AGCRNCell: 3-7               [64, 207, 64]             (recursive)
│    │    └─AGCRNCell: 3-8               [64, 207, 64]             (recursive)
│    │    └─AGCRNCell: 3-9               [64, 207, 64]             (recursive)
│    │    └─AGCRNCell: 3-10              [64, 207, 64]             (recursive)
│    │    └─AGCRNCell: 3-11              [64, 207, 64]             (recursive)
│    │    └─AGCRNCell: 3-12              [64, 207, 64]             (recursive)
│    │    └─AGCRNCell: 3-13              [64, 207, 64]             493,440
│    │    └─AGCRNCell: 3-14              [64, 207, 64]             (recursive)
│    │    └─AGCRNCell: 3-15              [64, 207, 64]             (recursive)
│    │    └─AGCRNCell: 3-16              [64, 207, 64]             (recursive)
│    │    └─AGCRNCell: 3-17              [64, 207, 64]             (recursive)
│    │    └─AGCRNCell: 3-18              [64, 207, 64]             (recursive)
│    │    └─AGCRNCell: 3-19              [64, 207, 64]             (recursive)
│    │    └─AGCRNCell: 3-20              [64, 207, 64]             (recursive)
│    │    └─AGCRNCell: 3-21              [64, 207, 64]             (recursive)
│    │    └─AGCRNCell: 3-22              [64, 207, 64]             (recursive)
│    │    └─AGCRNCell: 3-23              [64, 207, 64]             (recursive)
│    │    └─AGCRNCell: 3-24              [64, 207, 64]             (recursive)
├─Conv2d: 1-2                            [64, 12, 207, 1]          780
==========================================================================================
Total params: 751,650
Trainable params: 751,650
Non-trainable params: 0
Total mult-adds (G): 119.05
==========================================================================================
Input size (MB): 1.27
Forward/backward pass size (MB): 41.97
Params size (MB): 3.00
Estimated Total Size (MB): 46.24
==========================================================================================

Loss: MaskedMAELoss

2023-05-06 16:21:07.189196 Epoch 1  	Train Loss = 4.21952 Val Loss = 3.51282
2023-05-06 16:21:32.040295 Epoch 2  	Train Loss = 3.54723 Val Loss = 3.35225
2023-05-06 16:21:56.107202 Epoch 3  	Train Loss = 3.42195 Val Loss = 3.25238
2023-05-06 16:22:20.255567 Epoch 4  	Train Loss = 3.31110 Val Loss = 3.20024
2023-05-06 16:22:44.418166 Epoch 5  	Train Loss = 3.23378 Val Loss = 3.14020
2023-05-06 16:23:08.567112 Epoch 6  	Train Loss = 3.17304 Val Loss = 3.08147
2023-05-06 16:23:32.761646 Epoch 7  	Train Loss = 3.12595 Val Loss = 3.06011
2023-05-06 16:23:57.044433 Epoch 8  	Train Loss = 3.08832 Val Loss = 3.02704
2023-05-06 16:24:21.258876 Epoch 9  	Train Loss = 3.05900 Val Loss = 3.01825
2023-05-06 16:24:45.490154 Epoch 10  	Train Loss = 3.03316 Val Loss = 3.01570
2023-05-06 16:25:09.760362 Epoch 11  	Train Loss = 3.01358 Val Loss = 2.99888
2023-05-06 16:25:33.900920 Epoch 12  	Train Loss = 2.99510 Val Loss = 2.98872
2023-05-06 16:25:58.122906 Epoch 13  	Train Loss = 2.97703 Val Loss = 2.98870
2023-05-06 16:26:22.275913 Epoch 14  	Train Loss = 2.95760 Val Loss = 2.98108
2023-05-06 16:26:46.734755 Epoch 15  	Train Loss = 2.94203 Val Loss = 2.96869
2023-05-06 16:27:11.167013 Epoch 16  	Train Loss = 2.93098 Val Loss = 2.98741
2023-05-06 16:27:35.402397 Epoch 17  	Train Loss = 2.91979 Val Loss = 2.98287
2023-05-06 16:27:59.508901 Epoch 18  	Train Loss = 2.90123 Val Loss = 2.95511
2023-05-06 16:28:23.693113 Epoch 19  	Train Loss = 2.88956 Val Loss = 2.97033
2023-05-06 16:28:47.849578 Epoch 20  	Train Loss = 2.87351 Val Loss = 2.98242
2023-05-06 16:29:12.026956 Epoch 21  	Train Loss = 2.86495 Val Loss = 2.96640
2023-05-06 16:29:36.221836 Epoch 22  	Train Loss = 2.85765 Val Loss = 2.96169
2023-05-06 16:30:00.423207 Epoch 23  	Train Loss = 2.84388 Val Loss = 2.97042
2023-05-06 16:30:24.567733 Epoch 24  	Train Loss = 2.83593 Val Loss = 2.96275
2023-05-06 16:30:48.711133 Epoch 25  	Train Loss = 2.82022 Val Loss = 2.96380
2023-05-06 16:31:12.833784 Epoch 26  	Train Loss = 2.74563 Val Loss = 2.93042
2023-05-06 16:31:37.467032 Epoch 27  	Train Loss = 2.72377 Val Loss = 2.93307
2023-05-06 16:32:01.840098 Epoch 28  	Train Loss = 2.71492 Val Loss = 2.93308
2023-05-06 16:32:26.692504 Epoch 29  	Train Loss = 2.70816 Val Loss = 2.93698
2023-05-06 16:32:51.077616 Epoch 30  	Train Loss = 2.70271 Val Loss = 2.93941
2023-05-06 16:33:15.636659 Epoch 31  	Train Loss = 2.69802 Val Loss = 2.94106
2023-05-06 16:33:40.689728 Epoch 32  	Train Loss = 2.69374 Val Loss = 2.94369
2023-05-06 16:34:05.547429 Epoch 33  	Train Loss = 2.69001 Val Loss = 2.94795
2023-05-06 16:34:29.731225 Epoch 34  	Train Loss = 2.68586 Val Loss = 2.94663
2023-05-06 16:34:53.931417 Epoch 35  	Train Loss = 2.68214 Val Loss = 2.94472
2023-05-06 16:35:18.567909 Epoch 36  	Train Loss = 2.67851 Val Loss = 2.95235
2023-05-06 16:35:42.660866 Epoch 37  	Train Loss = 2.67502 Val Loss = 2.95393
2023-05-06 16:36:06.915338 Epoch 38  	Train Loss = 2.67225 Val Loss = 2.95313
2023-05-06 16:36:31.598527 Epoch 39  	Train Loss = 2.66927 Val Loss = 2.95466
2023-05-06 16:36:55.748167 Epoch 40  	Train Loss = 2.66610 Val Loss = 2.95523
2023-05-06 16:37:20.126579 Epoch 41  	Train Loss = 2.66261 Val Loss = 2.95443
2023-05-06 16:37:44.230307 Epoch 42  	Train Loss = 2.66065 Val Loss = 2.95711
2023-05-06 16:38:08.325565 Epoch 43  	Train Loss = 2.65762 Val Loss = 2.96289
2023-05-06 16:38:32.485953 Epoch 44  	Train Loss = 2.65475 Val Loss = 2.96089
2023-05-06 16:38:56.640957 Epoch 45  	Train Loss = 2.65238 Val Loss = 2.96255
2023-05-06 16:39:20.927126 Epoch 46  	Train Loss = 2.65007 Val Loss = 2.96184
Early stopping at epoch: 46
Best at epoch 26:
Train Loss = 2.74563
Train RMSE = 5.28793, MAE = 2.64358, MAPE = 7.00476
Val Loss = 2.93042
Val RMSE = 6.38235, MAE = 2.99742, MAPE = 8.67442
--------- Test ---------
All Steps RMSE = 6.72241, MAE = 3.25667, MAPE = 9.14122
Step 1 RMSE = 4.31976, MAE = 2.42661, MAPE = 6.15699
Step 2 RMSE = 5.12066, MAE = 2.69921, MAPE = 7.08053
Step 3 RMSE = 5.70183, MAE = 2.90896, MAPE = 7.83592
Step 4 RMSE = 6.20053, MAE = 3.08147, MAPE = 8.46854
Step 5 RMSE = 6.58292, MAE = 3.21023, MAPE = 8.94196
Step 6 RMSE = 6.85529, MAE = 3.31362, MAPE = 9.32383
Step 7 RMSE = 7.07170, MAE = 3.40506, MAPE = 9.66897
Step 8 RMSE = 7.25701, MAE = 3.48330, MAPE = 9.96888
Step 9 RMSE = 7.42588, MAE = 3.54937, MAPE = 10.23083
Step 10 RMSE = 7.57400, MAE = 3.60759, MAPE = 10.45311
Step 11 RMSE = 7.70890, MAE = 3.66574, MAPE = 10.66949
Step 12 RMSE = 7.84306, MAE = 3.72894, MAPE = 10.89575
Inference time: 2.56 s
