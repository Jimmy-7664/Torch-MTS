METRLA
Trainset:	x-(23974, 12, 207, 1)	y-(23974, 12, 207, 1)
Valset:  	x-(3425, 12, 207, 1)  	y-(3425, 12, 207, 1)
Testset:	x-(6850, 12, 207, 1)	y-(6850, 12, 207, 1)

--------- LSTM ---------
{
    "num_nodes": 207,
    "in_steps": 12,
    "out_steps": 12,
    "train_size": 0.7,
    "val_size": 0.1,
    "lr": 0.01,
    "weight_decay": 0,
    "milestones": [
        10,
        20
    ],
    "clip_grad": 0,
    "batch_size": 64,
    "max_epochs": 200,
    "use_cl": false,
    "model_args": {
        "num_nodes": 207,
        "in_steps": 12,
        "out_steps": 12,
        "input_dim": 1,
        "output_dim": 1,
        "lstm_hidden_dim": 64,
        "num_layers": 3,
        "seq2seq": true
    }
}
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
LSTM                                     [64, 12, 207, 1]          --
├─LSTM: 1-1                              [13248, 12, 64]           83,712
├─LSTM: 1-2                              [13248, 1, 64]            83,712
├─Linear: 1-3                            [13248, 1, 1]             65
├─LSTM: 1-4                              [13248, 1, 64]            (recursive)
├─Linear: 1-5                            [13248, 1, 1]             (recursive)
├─LSTM: 1-6                              [13248, 1, 64]            (recursive)
├─Linear: 1-7                            [13248, 1, 1]             (recursive)
├─LSTM: 1-8                              [13248, 1, 64]            (recursive)
├─Linear: 1-9                            [13248, 1, 1]             (recursive)
├─LSTM: 1-10                             [13248, 1, 64]            (recursive)
├─Linear: 1-11                           [13248, 1, 1]             (recursive)
├─LSTM: 1-12                             [13248, 1, 64]            (recursive)
├─Linear: 1-13                           [13248, 1, 1]             (recursive)
├─LSTM: 1-14                             [13248, 1, 64]            (recursive)
├─Linear: 1-15                           [13248, 1, 1]             (recursive)
├─LSTM: 1-16                             [13248, 1, 64]            (recursive)
├─Linear: 1-17                           [13248, 1, 1]             (recursive)
├─LSTM: 1-18                             [13248, 1, 64]            (recursive)
├─Linear: 1-19                           [13248, 1, 1]             (recursive)
├─LSTM: 1-20                             [13248, 1, 64]            (recursive)
├─Linear: 1-21                           [13248, 1, 1]             (recursive)
├─LSTM: 1-22                             [13248, 1, 64]            (recursive)
├─Linear: 1-23                           [13248, 1, 1]             (recursive)
├─LSTM: 1-24                             [13248, 1, 64]            (recursive)
├─Linear: 1-25                           [13248, 1, 1]             (recursive)
==========================================================================================
Total params: 167,489
Trainable params: 167,489
Non-trainable params: 0
Total mult-adds (G): 26.63
==========================================================================================
Input size (MB): 0.64
Forward/backward pass size (MB): 88.28
Params size (MB): 0.67
Estimated Total Size (MB): 89.59
==========================================================================================

Loss: MaskedMAELoss

2023-05-06 21:43:11.164380 Epoch 1  	Train Loss = 4.35824 Val Loss = 3.73737
2023-05-06 21:43:45.685079 Epoch 2  	Train Loss = 3.70890 Val Loss = 3.44122
2023-05-06 21:44:20.069869 Epoch 3  	Train Loss = 3.72189 Val Loss = 3.42058
2023-05-06 21:44:54.577826 Epoch 4  	Train Loss = 3.65108 Val Loss = 3.44475
2023-05-06 21:45:29.196908 Epoch 5  	Train Loss = 3.63680 Val Loss = 3.39455
2023-05-06 21:46:03.827179 Epoch 6  	Train Loss = 3.61268 Val Loss = 3.42423
2023-05-06 21:46:38.519410 Epoch 7  	Train Loss = 3.60341 Val Loss = 3.39566
2023-05-06 21:47:13.172026 Epoch 8  	Train Loss = 3.60214 Val Loss = 3.42661
2023-05-06 21:47:47.784561 Epoch 9  	Train Loss = 3.65779 Val Loss = 3.42667
2023-05-06 21:48:22.423532 Epoch 10  	Train Loss = 3.59864 Val Loss = 3.39760
2023-05-06 21:48:57.086186 Epoch 11  	Train Loss = 3.57412 Val Loss = 3.37235
2023-05-06 21:49:31.821424 Epoch 12  	Train Loss = 3.57068 Val Loss = 3.37546
2023-05-06 21:50:06.595796 Epoch 13  	Train Loss = 3.57000 Val Loss = 3.37482
2023-05-06 21:50:41.281813 Epoch 14  	Train Loss = 3.56831 Val Loss = 3.37629
2023-05-06 21:51:15.937271 Epoch 15  	Train Loss = 3.56725 Val Loss = 3.37173
2023-05-06 21:51:50.615665 Epoch 16  	Train Loss = 3.56686 Val Loss = 3.37499
2023-05-06 21:52:25.291265 Epoch 17  	Train Loss = 3.56724 Val Loss = 3.37440
2023-05-06 21:53:00.125009 Epoch 18  	Train Loss = 3.56495 Val Loss = 3.37498
2023-05-06 21:53:34.804496 Epoch 19  	Train Loss = 3.56446 Val Loss = 3.37186
2023-05-06 21:54:09.436186 Epoch 20  	Train Loss = 3.56410 Val Loss = 3.37685
2023-05-06 21:54:44.052388 Epoch 21  	Train Loss = 3.55809 Val Loss = 3.37232
2023-05-06 21:55:18.701317 Epoch 22  	Train Loss = 3.55687 Val Loss = 3.37213
2023-05-06 21:55:53.345495 Epoch 23  	Train Loss = 3.55707 Val Loss = 3.37169
2023-05-06 21:56:28.018809 Epoch 24  	Train Loss = 3.55712 Val Loss = 3.37186
2023-05-06 21:57:02.649748 Epoch 25  	Train Loss = 3.55703 Val Loss = 3.37294
2023-05-06 21:57:37.410991 Epoch 26  	Train Loss = 3.55624 Val Loss = 3.37322
2023-05-06 21:58:12.061230 Epoch 27  	Train Loss = 3.55646 Val Loss = 3.37311
2023-05-06 21:58:46.841954 Epoch 28  	Train Loss = 3.55687 Val Loss = 3.37367
2023-05-06 21:59:21.520892 Epoch 29  	Train Loss = 3.55677 Val Loss = 3.37262
2023-05-06 21:59:56.156469 Epoch 30  	Train Loss = 3.55549 Val Loss = 3.37215
2023-05-06 22:00:30.785728 Epoch 31  	Train Loss = 3.55606 Val Loss = 3.37312
2023-05-06 22:01:05.451756 Epoch 32  	Train Loss = 3.55596 Val Loss = 3.37264
2023-05-06 22:01:40.085965 Epoch 33  	Train Loss = 3.55502 Val Loss = 3.37212
Early stopping at epoch: 33
Best at epoch 23:
Train Loss = 3.55707
Train RMSE = 7.31923, MAE = 3.55445, MAPE = 9.79252
Val Loss = 3.37169
Val RMSE = 7.24133, MAE = 3.41339, MAPE = 9.74947
--------- Test ---------
All Steps RMSE = 7.73239, MAE = 3.78498, MAPE = 10.76508
Step 1 RMSE = 4.27289, MAE = 2.40933, MAPE = 5.87244
Step 2 RMSE = 5.34028, MAE = 2.78007, MAPE = 7.10466
Step 3 RMSE = 6.08374, MAE = 3.06345, MAPE = 8.09464
Step 4 RMSE = 6.68203, MAE = 3.31231, MAPE = 8.98895
Step 5 RMSE = 7.19557, MAE = 3.54139, MAPE = 9.81748
Step 6 RMSE = 7.65348, MAE = 3.76041, MAPE = 10.61843
Step 7 RMSE = 8.06599, MAE = 3.96434, MAPE = 11.37621
Step 8 RMSE = 8.44124, MAE = 4.15910, MAPE = 12.10838
Step 9 RMSE = 8.78233, MAE = 4.34434, MAPE = 12.80221
Step 10 RMSE = 9.10256, MAE = 4.52255, MAPE = 13.47212
Step 11 RMSE = 9.40385, MAE = 4.69573, MAPE = 14.12932
Step 12 RMSE = 9.69329, MAE = 4.86676, MAPE = 14.79648
Inference time: 6.43 s
