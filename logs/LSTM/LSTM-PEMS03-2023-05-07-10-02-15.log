PEMS03
Trainset:	x-(15711, 12, 358, 1)	y-(15711, 12, 358, 1)
Valset:  	x-(5237, 12, 358, 1)  	y-(5237, 12, 358, 1)
Testset:	x-(5237, 12, 358, 1)	y-(5237, 12, 358, 1)

--------- LSTM ---------
{
    "num_nodes": 358,
    "in_steps": 12,
    "out_steps": 12,
    "train_size": 0.6,
    "val_size": 0.2,
    "lr": 0.01,
    "weight_decay": 0,
    "milestones": [
        10,
        20
    ],
    "clip_grad": 0,
    "batch_size": 64,
    "max_epochs": 200,
    "use_cl": false,
    "model_args": {
        "num_nodes": 358,
        "in_steps": 12,
        "out_steps": 12,
        "input_dim": 1,
        "output_dim": 1,
        "lstm_hidden_dim": 64,
        "num_layers": 3,
        "seq2seq": true
    }
}
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
LSTM                                     [64, 12, 358, 1]          --
├─LSTM: 1-1                              [22912, 12, 64]           83,712
├─LSTM: 1-2                              [22912, 1, 64]            83,712
├─Linear: 1-3                            [22912, 1, 1]             65
├─LSTM: 1-4                              [22912, 1, 64]            (recursive)
├─Linear: 1-5                            [22912, 1, 1]             (recursive)
├─LSTM: 1-6                              [22912, 1, 64]            (recursive)
├─Linear: 1-7                            [22912, 1, 1]             (recursive)
├─LSTM: 1-8                              [22912, 1, 64]            (recursive)
├─Linear: 1-9                            [22912, 1, 1]             (recursive)
├─LSTM: 1-10                             [22912, 1, 64]            (recursive)
├─Linear: 1-11                           [22912, 1, 1]             (recursive)
├─LSTM: 1-12                             [22912, 1, 64]            (recursive)
├─Linear: 1-13                           [22912, 1, 1]             (recursive)
├─LSTM: 1-14                             [22912, 1, 64]            (recursive)
├─Linear: 1-15                           [22912, 1, 1]             (recursive)
├─LSTM: 1-16                             [22912, 1, 64]            (recursive)
├─Linear: 1-17                           [22912, 1, 1]             (recursive)
├─LSTM: 1-18                             [22912, 1, 64]            (recursive)
├─Linear: 1-19                           [22912, 1, 1]             (recursive)
├─LSTM: 1-20                             [22912, 1, 64]            (recursive)
├─Linear: 1-21                           [22912, 1, 1]             (recursive)
├─LSTM: 1-22                             [22912, 1, 64]            (recursive)
├─Linear: 1-23                           [22912, 1, 1]             (recursive)
├─LSTM: 1-24                             [22912, 1, 64]            (recursive)
├─Linear: 1-25                           [22912, 1, 1]             (recursive)
==========================================================================================
Total params: 167,489
Trainable params: 167,489
Non-trainable params: 0
Total mult-adds (G): 46.05
==========================================================================================
Input size (MB): 1.10
Forward/backward pass size (MB): 152.69
Params size (MB): 0.67
Estimated Total Size (MB): 154.46
==========================================================================================

Loss: HuberLoss

2023-05-07 10:03:02.543159 Epoch 1  	Train Loss = 28.96346 Val Loss = 21.69705
2023-05-07 10:03:45.799091 Epoch 2  	Train Loss = 22.41156 Val Loss = 23.50576
2023-05-07 10:04:29.309477 Epoch 3  	Train Loss = 21.76391 Val Loss = 21.90308
2023-05-07 10:05:12.805420 Epoch 4  	Train Loss = 21.71359 Val Loss = 22.08056
2023-05-07 10:05:56.284276 Epoch 5  	Train Loss = 21.44204 Val Loss = 20.94223
2023-05-07 10:06:39.816766 Epoch 6  	Train Loss = 21.33033 Val Loss = 21.17205
2023-05-07 10:07:23.357762 Epoch 7  	Train Loss = 21.09688 Val Loss = 21.29396
2023-05-07 10:08:06.921175 Epoch 8  	Train Loss = 21.01917 Val Loss = 21.26810
2023-05-07 10:08:50.480039 Epoch 9  	Train Loss = 20.73082 Val Loss = 20.52368
2023-05-07 10:09:33.959026 Epoch 10  	Train Loss = 20.69357 Val Loss = 20.97845
2023-05-07 10:10:17.484284 Epoch 11  	Train Loss = 20.23399 Val Loss = 20.10656
2023-05-07 10:11:01.011895 Epoch 12  	Train Loss = 20.17820 Val Loss = 20.15988
2023-05-07 10:11:44.590222 Epoch 13  	Train Loss = 20.16376 Val Loss = 20.12239
2023-05-07 10:12:28.138926 Epoch 14  	Train Loss = 20.15510 Val Loss = 20.08059
2023-05-07 10:13:11.657471 Epoch 15  	Train Loss = 20.15224 Val Loss = 20.08575
2023-05-07 10:13:55.214280 Epoch 16  	Train Loss = 20.12392 Val Loss = 20.05235
2023-05-07 10:14:38.780902 Epoch 17  	Train Loss = 20.11929 Val Loss = 20.14531
2023-05-07 10:15:22.288012 Epoch 18  	Train Loss = 20.11683 Val Loss = 20.06856
2023-05-07 10:16:05.867579 Epoch 19  	Train Loss = 20.10226 Val Loss = 20.24691
2023-05-07 10:16:49.414429 Epoch 20  	Train Loss = 20.07795 Val Loss = 20.14728
2023-05-07 10:17:32.943176 Epoch 21  	Train Loss = 20.02123 Val Loss = 19.99554
2023-05-07 10:18:16.444473 Epoch 22  	Train Loss = 20.01483 Val Loss = 19.99288
2023-05-07 10:18:59.963025 Epoch 23  	Train Loss = 20.01136 Val Loss = 20.00482
2023-05-07 10:19:43.450135 Epoch 24  	Train Loss = 20.00446 Val Loss = 19.98716
2023-05-07 10:20:26.960977 Epoch 25  	Train Loss = 20.00445 Val Loss = 19.99799
2023-05-07 10:21:10.449730 Epoch 26  	Train Loss = 20.00068 Val Loss = 20.00356
2023-05-07 10:21:53.897097 Epoch 27  	Train Loss = 20.00083 Val Loss = 19.98362
2023-05-07 10:22:37.382454 Epoch 28  	Train Loss = 19.99866 Val Loss = 19.99910
2023-05-07 10:23:20.988750 Epoch 29  	Train Loss = 19.99814 Val Loss = 19.98904
2023-05-07 10:24:04.506455 Epoch 30  	Train Loss = 19.99500 Val Loss = 19.97825
2023-05-07 10:24:48.033842 Epoch 31  	Train Loss = 19.99919 Val Loss = 19.98113
2023-05-07 10:25:31.673212 Epoch 32  	Train Loss = 19.99208 Val Loss = 19.98374
2023-05-07 10:26:15.225888 Epoch 33  	Train Loss = 19.98787 Val Loss = 19.97475
2023-05-07 10:26:58.683532 Epoch 34  	Train Loss = 19.98665 Val Loss = 19.97376
2023-05-07 10:27:42.216402 Epoch 35  	Train Loss = 19.98822 Val Loss = 19.97860
2023-05-07 10:28:25.693461 Epoch 36  	Train Loss = 19.98757 Val Loss = 19.98163
2023-05-07 10:29:09.222455 Epoch 37  	Train Loss = 19.98891 Val Loss = 19.98122
2023-05-07 10:29:52.747641 Epoch 38  	Train Loss = 19.98057 Val Loss = 19.97783
2023-05-07 10:30:36.300744 Epoch 39  	Train Loss = 19.98135 Val Loss = 19.97262
2023-05-07 10:31:19.783621 Epoch 40  	Train Loss = 19.97912 Val Loss = 20.00212
2023-05-07 10:32:03.278310 Epoch 41  	Train Loss = 19.98016 Val Loss = 19.96446
2023-05-07 10:32:46.803793 Epoch 42  	Train Loss = 19.97284 Val Loss = 19.96187
2023-05-07 10:33:30.391068 Epoch 43  	Train Loss = 19.98076 Val Loss = 19.97075
2023-05-07 10:34:13.839141 Epoch 44  	Train Loss = 19.97608 Val Loss = 19.97127
2023-05-07 10:34:57.287361 Epoch 45  	Train Loss = 19.97174 Val Loss = 19.96965
2023-05-07 10:35:40.744362 Epoch 46  	Train Loss = 19.96838 Val Loss = 19.95901
2023-05-07 10:36:24.221950 Epoch 47  	Train Loss = 19.97160 Val Loss = 19.96805
2023-05-07 10:37:07.663194 Epoch 48  	Train Loss = 19.96922 Val Loss = 19.96833
2023-05-07 10:37:51.108385 Epoch 49  	Train Loss = 19.96732 Val Loss = 19.95691
2023-05-07 10:38:34.704829 Epoch 50  	Train Loss = 19.95705 Val Loss = 19.96649
2023-05-07 10:39:18.205016 Epoch 51  	Train Loss = 19.96548 Val Loss = 19.95484
2023-05-07 10:40:01.657797 Epoch 52  	Train Loss = 19.96338 Val Loss = 19.95142
2023-05-07 10:40:45.107319 Epoch 53  	Train Loss = 19.95944 Val Loss = 19.95303
2023-05-07 10:41:28.552559 Epoch 54  	Train Loss = 19.96016 Val Loss = 19.95670
2023-05-07 10:42:12.034084 Epoch 55  	Train Loss = 19.96159 Val Loss = 19.96428
2023-05-07 10:42:55.485534 Epoch 56  	Train Loss = 19.95649 Val Loss = 19.95553
2023-05-07 10:43:38.967669 Epoch 57  	Train Loss = 19.95225 Val Loss = 19.95501
2023-05-07 10:44:22.405261 Epoch 58  	Train Loss = 19.95721 Val Loss = 19.95020
2023-05-07 10:45:06.008769 Epoch 59  	Train Loss = 19.95444 Val Loss = 19.94394
2023-05-07 10:45:49.508683 Epoch 60  	Train Loss = 19.94655 Val Loss = 19.94479
2023-05-07 10:46:33.013925 Epoch 61  	Train Loss = 19.94863 Val Loss = 19.94652
2023-05-07 10:47:16.485515 Epoch 62  	Train Loss = 19.94383 Val Loss = 19.95117
2023-05-07 10:48:00.010209 Epoch 63  	Train Loss = 19.94944 Val Loss = 19.94916
2023-05-07 10:48:43.387316 Epoch 64  	Train Loss = 19.94351 Val Loss = 19.94775
2023-05-07 10:49:26.822460 Epoch 65  	Train Loss = 19.94979 Val Loss = 19.94577
2023-05-07 10:50:10.215591 Epoch 66  	Train Loss = 19.94968 Val Loss = 19.94336
2023-05-07 10:50:53.636556 Epoch 67  	Train Loss = 19.93670 Val Loss = 19.94948
2023-05-07 10:51:37.116471 Epoch 68  	Train Loss = 19.93853 Val Loss = 19.93802
2023-05-07 10:52:20.602669 Epoch 69  	Train Loss = 19.94083 Val Loss = 19.94814
2023-05-07 10:53:04.190412 Epoch 70  	Train Loss = 19.94411 Val Loss = 19.94944
2023-05-07 10:53:47.654584 Epoch 71  	Train Loss = 19.94369 Val Loss = 19.93544
2023-05-07 10:54:31.127923 Epoch 72  	Train Loss = 19.92981 Val Loss = 19.93738
2023-05-07 10:55:14.630935 Epoch 73  	Train Loss = 19.93564 Val Loss = 19.94082
2023-05-07 10:55:58.288255 Epoch 74  	Train Loss = 19.93556 Val Loss = 19.94645
2023-05-07 10:56:41.765661 Epoch 75  	Train Loss = 19.93362 Val Loss = 19.93376
2023-05-07 10:57:25.219153 Epoch 76  	Train Loss = 19.93178 Val Loss = 19.94688
2023-05-07 10:58:08.705136 Epoch 77  	Train Loss = 19.93230 Val Loss = 19.93508
2023-05-07 10:58:52.252567 Epoch 78  	Train Loss = 19.92944 Val Loss = 19.95727
2023-05-07 10:59:35.780354 Epoch 79  	Train Loss = 19.92876 Val Loss = 19.94312
2023-05-07 11:00:19.416602 Epoch 80  	Train Loss = 19.92472 Val Loss = 19.93290
2023-05-07 11:01:02.922024 Epoch 81  	Train Loss = 19.91860 Val Loss = 19.93077
2023-05-07 11:01:46.376770 Epoch 82  	Train Loss = 19.91780 Val Loss = 19.93175
2023-05-07 11:02:29.963132 Epoch 83  	Train Loss = 19.92764 Val Loss = 19.93236
2023-05-07 11:03:13.455444 Epoch 84  	Train Loss = 19.92261 Val Loss = 19.92768
2023-05-07 11:03:56.901267 Epoch 85  	Train Loss = 19.91784 Val Loss = 19.92523
2023-05-07 11:04:40.509142 Epoch 86  	Train Loss = 19.91874 Val Loss = 19.92634
2023-05-07 11:05:24.080827 Epoch 87  	Train Loss = 19.92019 Val Loss = 19.92874
2023-05-07 11:06:07.516145 Epoch 88  	Train Loss = 19.91375 Val Loss = 19.92578
2023-05-07 11:06:50.965736 Epoch 89  	Train Loss = 19.91958 Val Loss = 19.93266
2023-05-07 11:07:34.522648 Epoch 90  	Train Loss = 19.91252 Val Loss = 19.94748
2023-05-07 11:08:18.016153 Epoch 91  	Train Loss = 19.91805 Val Loss = 19.94122
2023-05-07 11:09:01.520324 Epoch 92  	Train Loss = 19.91767 Val Loss = 19.93400
2023-05-07 11:09:45.013832 Epoch 93  	Train Loss = 19.91110 Val Loss = 19.92314
2023-05-07 11:10:28.504655 Epoch 94  	Train Loss = 19.91332 Val Loss = 19.92792
2023-05-07 11:11:11.977309 Epoch 95  	Train Loss = 19.90657 Val Loss = 19.91967
2023-05-07 11:11:55.499360 Epoch 96  	Train Loss = 19.91016 Val Loss = 19.92574
2023-05-07 11:12:38.947759 Epoch 97  	Train Loss = 19.90338 Val Loss = 19.92847
2023-05-07 11:13:22.435170 Epoch 98  	Train Loss = 19.90620 Val Loss = 19.92254
2023-05-07 11:14:05.882916 Epoch 99  	Train Loss = 19.90594 Val Loss = 19.93177
2023-05-07 11:14:49.388446 Epoch 100  	Train Loss = 19.90233 Val Loss = 19.92909
2023-05-07 11:15:32.901452 Epoch 101  	Train Loss = 19.89879 Val Loss = 19.92783
2023-05-07 11:16:16.437101 Epoch 102  	Train Loss = 19.90557 Val Loss = 19.92199
2023-05-07 11:16:59.996154 Epoch 103  	Train Loss = 19.90541 Val Loss = 19.91868
2023-05-07 11:17:43.561744 Epoch 104  	Train Loss = 19.89471 Val Loss = 19.91950
2023-05-07 11:18:27.092270 Epoch 105  	Train Loss = 19.90784 Val Loss = 19.92781
2023-05-07 11:19:10.581336 Epoch 106  	Train Loss = 19.90531 Val Loss = 19.91772
2023-05-07 11:19:54.065054 Epoch 107  	Train Loss = 19.89939 Val Loss = 19.91553
2023-05-07 11:20:37.541862 Epoch 108  	Train Loss = 19.90163 Val Loss = 19.92011
2023-05-07 11:21:20.974717 Epoch 109  	Train Loss = 19.90180 Val Loss = 19.90991
2023-05-07 11:22:04.416053 Epoch 110  	Train Loss = 19.89910 Val Loss = 19.93051
2023-05-07 11:22:47.880788 Epoch 111  	Train Loss = 19.89740 Val Loss = 19.91335
2023-05-07 11:23:31.352363 Epoch 112  	Train Loss = 19.89860 Val Loss = 19.91294
2023-05-07 11:24:14.904551 Epoch 113  	Train Loss = 19.89115 Val Loss = 19.91374
2023-05-07 11:24:58.346109 Epoch 114  	Train Loss = 19.89202 Val Loss = 19.91637
2023-05-07 11:25:41.847759 Epoch 115  	Train Loss = 19.89386 Val Loss = 19.91901
2023-05-07 11:26:25.347493 Epoch 116  	Train Loss = 19.89667 Val Loss = 19.92048
2023-05-07 11:27:08.809429 Epoch 117  	Train Loss = 19.89741 Val Loss = 19.91663
2023-05-07 11:27:52.296098 Epoch 118  	Train Loss = 19.89038 Val Loss = 19.93197
2023-05-07 11:28:35.826664 Epoch 119  	Train Loss = 19.88825 Val Loss = 19.91714
Early stopping at epoch: 119
Best at epoch 109:
Train Loss = 19.90180
Train RMSE = 31.87346, MAE = 20.45196, MAPE = 18.56733
Val Loss = 19.90991
Val RMSE = 31.97284, MAE = 20.49235, MAPE = 18.54948
--------- Test ---------
All Steps RMSE = 32.53002, MAE = 19.81609, MAPE = 18.85391
Step 1 RMSE = 22.09936, MAE = 13.35149, MAPE = 12.92631
Step 2 RMSE = 24.52532, MAE = 14.78780, MAPE = 14.14616
Step 3 RMSE = 26.58468, MAE = 16.07075, MAPE = 15.24865
Step 4 RMSE = 28.31094, MAE = 17.16249, MAPE = 16.23102
Step 5 RMSE = 29.86926, MAE = 18.18346, MAPE = 17.10228
Step 6 RMSE = 31.46841, MAE = 19.26708, MAPE = 18.09027
Step 7 RMSE = 33.09887, MAE = 20.40693, MAPE = 19.17009
Step 8 RMSE = 34.64438, MAE = 21.51863, MAPE = 20.29417
Step 9 RMSE = 36.06861, MAE = 22.55937, MAPE = 21.41510
Step 10 RMSE = 37.49728, MAE = 23.60088, MAPE = 22.55062
Step 11 RMSE = 39.11152, MAE = 24.75917, MAPE = 23.80187
Step 12 RMSE = 41.05378, MAE = 26.12525, MAPE = 25.26985
Inference time: 8.45 s
