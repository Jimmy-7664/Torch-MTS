PEMS07
Trainset:	x-(16921, 12, 883, 2)	y-(16921, 12, 883, 1)
Valset:  	x-(5640, 12, 883, 2)  	y-(5640, 12, 883, 1)
Testset:	x-(5640, 12, 883, 2)	y-(5640, 12, 883, 1)

--------- GTS ---------
{
    "num_nodes": 883,
    "in_steps": 12,
    "out_steps": 12,
    "time_of_day": true,
    "runner": "GTS",
    "loss": "GTS",
    "lr": 0.001,
    "eps": 0.001,
    "milestones": [
        20,
        30
    ],
    "clip_grad": 5,
    "batch_size": 64,
    "max_epochs": 200,
    "early_stop": 10,
    "model_args": {
        "num_nodes": 883,
        "input_dim": 2,
        "output_dim": 1,
        "seq_len": 12,
        "horizon": 12,
        "rnn_units": 64,
        "num_rnn_layers": 1,
        "max_diffusion_step": 3,
        "filter_type": "dual_random_walk",
        "tf_decay_steps": 2000,
        "use_teacher_forcing": true,
        "l1_decay": 0,
        "temp": 0.5,
        "k": 30,
        "dim_fc": 270656,
        "dataset_name": "PEMS07",
        "trainset_ratio": 0.6
    }
}
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
GTS                                      [64, 12, 883, 1]          --
├─Conv1d: 1-1                            [883, 8, 16925]           88
├─BatchNorm1d: 1-2                       [883, 8, 16925]           16
├─Conv1d: 1-3                            [883, 16, 16916]          1,296
├─BatchNorm1d: 1-4                       [883, 16, 16916]          32
├─Linear: 1-5                            [883, 100]                27,065,700
├─BatchNorm1d: 1-6                       [883, 100]                200
├─Linear: 1-7                            [779689, 100]             20,100
├─Linear: 1-8                            [779689, 2]               202
├─EncoderModel: 1-9                      [64, 56512]               --
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-1               [64, 56512]               --
├─EncoderModel: 1-10                     [64, 56512]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-2               [64, 56512]               (recursive)
├─EncoderModel: 1-11                     [64, 56512]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-3               [64, 56512]               (recursive)
├─EncoderModel: 1-12                     [64, 56512]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-4               [64, 56512]               (recursive)
├─EncoderModel: 1-13                     [64, 56512]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-5               [64, 56512]               (recursive)
├─EncoderModel: 1-14                     [64, 56512]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-6               [64, 56512]               (recursive)
├─EncoderModel: 1-15                     [64, 56512]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-7               [64, 56512]               (recursive)
├─EncoderModel: 1-16                     [64, 56512]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-8               [64, 56512]               (recursive)
├─EncoderModel: 1-17                     [64, 56512]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-9               [64, 56512]               (recursive)
├─EncoderModel: 1-18                     [64, 56512]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-10              [64, 56512]               (recursive)
├─EncoderModel: 1-19                     [64, 56512]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-11              [64, 56512]               (recursive)
├─EncoderModel: 1-20                     [64, 56512]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-12              [64, 56512]               (recursive)
├─DecoderModel: 1-21                     [64, 883]                 --
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-13              [64, 56512]               --
│    └─Linear: 2-14                      [56512, 1]                65
├─DecoderModel: 1-22                     [64, 883]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-14              [64, 56512]               (recursive)
│    └─Linear: 2-16                      [56512, 1]                (recursive)
├─DecoderModel: 1-23                     [64, 883]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-15              [64, 56512]               (recursive)
│    └─Linear: 2-18                      [56512, 1]                (recursive)
├─DecoderModel: 1-24                     [64, 883]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-16              [64, 56512]               (recursive)
│    └─Linear: 2-20                      [56512, 1]                (recursive)
├─DecoderModel: 1-25                     [64, 883]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-17              [64, 56512]               (recursive)
│    └─Linear: 2-22                      [56512, 1]                (recursive)
├─DecoderModel: 1-26                     [64, 883]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-18              [64, 56512]               (recursive)
│    └─Linear: 2-24                      [56512, 1]                (recursive)
├─DecoderModel: 1-27                     [64, 883]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-19              [64, 56512]               (recursive)
│    └─Linear: 2-26                      [56512, 1]                (recursive)
├─DecoderModel: 1-28                     [64, 883]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-20              [64, 56512]               (recursive)
│    └─Linear: 2-28                      [56512, 1]                (recursive)
├─DecoderModel: 1-29                     [64, 883]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-21              [64, 56512]               (recursive)
│    └─Linear: 2-30                      [56512, 1]                (recursive)
├─DecoderModel: 1-30                     [64, 883]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-22              [64, 56512]               (recursive)
│    └─Linear: 2-32                      [56512, 1]                (recursive)
├─DecoderModel: 1-31                     [64, 883]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-23              [64, 56512]               (recursive)
│    └─Linear: 2-34                      [56512, 1]                (recursive)
├─DecoderModel: 1-32                     [64, 883]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-24              [64, 56512]               (recursive)
│    └─Linear: 2-36                      [56512, 1]                (recursive)
==========================================================================================
Total params: 27,087,699
Trainable params: 27,087,699
Non-trainable params: 0
Total mult-adds (T): 4.44
==========================================================================================
Input size (MB): 5.43
Forward/backward pass size (MB): 7016.37
Params size (MB): 108.35
Estimated Total Size (MB): 7130.15
==========================================================================================

Loss: GTSLoss

2024-03-23 16:30:29.734045 Epoch 1  	Train Loss = 27.19137 Val Loss = 33.71209
2024-03-23 16:36:54.037983 Epoch 2  	Train Loss = 19.52162 Val Loss = 28.73462
2024-03-23 16:43:16.122882 Epoch 3  	Train Loss = 19.04283 Val Loss = 27.69482
2024-03-23 16:49:38.060930 Epoch 4  	Train Loss = 18.80015 Val Loss = 27.04253
2024-03-23 16:55:55.417646 Epoch 5  	Train Loss = 18.63033 Val Loss = 27.69084
2024-03-23 17:02:14.332679 Epoch 6  	Train Loss = 18.56119 Val Loss = 28.90873
2024-03-23 17:08:25.489953 Epoch 7  	Train Loss = 18.50445 Val Loss = 28.50306
2024-03-23 17:14:41.103885 Epoch 8  	Train Loss = 18.42188 Val Loss = 27.49331
2024-03-23 17:20:47.074380 Epoch 9  	Train Loss = 18.41084 Val Loss = 26.39255
2024-03-23 17:26:51.669838 Epoch 10  	Train Loss = 18.32501 Val Loss = 25.66143
2024-03-23 17:32:59.756139 Epoch 11  	Train Loss = 18.26368 Val Loss = 25.97711
2024-03-23 17:39:08.227072 Epoch 12  	Train Loss = 18.21685 Val Loss = 26.11889
2024-03-23 17:45:16.603405 Epoch 13  	Train Loss = 18.15693 Val Loss = 25.26601
2024-03-23 17:51:29.659841 Epoch 14  	Train Loss = 18.12818 Val Loss = 24.63901
2024-03-23 17:57:42.307576 Epoch 15  	Train Loss = 18.08209 Val Loss = 26.46560
2024-03-23 18:03:54.017940 Epoch 16  	Train Loss = 18.06051 Val Loss = 26.02945
2024-03-23 18:10:09.189945 Epoch 17  	Train Loss = 18.00824 Val Loss = 24.73043
2024-03-23 18:16:21.447934 Epoch 18  	Train Loss = 17.98662 Val Loss = 24.50045
2024-03-23 18:22:35.673861 Epoch 19  	Train Loss = 17.93025 Val Loss = 24.50458
2024-03-23 18:28:46.050848 Epoch 20  	Train Loss = 17.91274 Val Loss = 24.36657
2024-03-23 18:34:59.562486 Epoch 21  	Train Loss = 17.78496 Val Loss = 23.42407
2024-03-23 18:41:17.140795 Epoch 22  	Train Loss = 17.77335 Val Loss = 23.77453
2024-03-23 18:47:28.191086 Epoch 23  	Train Loss = 17.76540 Val Loss = 23.36158
2024-03-23 18:53:41.722931 Epoch 24  	Train Loss = 17.75726 Val Loss = 23.51213
2024-03-23 18:59:52.158353 Epoch 25  	Train Loss = 17.75174 Val Loss = 23.28896
2024-03-23 19:06:03.899212 Epoch 26  	Train Loss = 17.74789 Val Loss = 23.38262
2024-03-23 19:12:13.566278 Epoch 27  	Train Loss = 17.73923 Val Loss = 23.40866
2024-03-23 19:18:26.152016 Epoch 28  	Train Loss = 17.73561 Val Loss = 23.15419
2024-03-23 19:24:37.133179 Epoch 29  	Train Loss = 17.74453 Val Loss = 23.26188
2024-03-23 19:30:49.353083 Epoch 30  	Train Loss = 17.73575 Val Loss = 23.15951
2024-03-23 19:37:07.941298 Epoch 31  	Train Loss = 17.72900 Val Loss = 23.10115
2024-03-23 19:43:19.764941 Epoch 32  	Train Loss = 17.73404 Val Loss = 23.14378
2024-03-23 19:49:30.760032 Epoch 33  	Train Loss = 17.73848 Val Loss = 23.07477
2024-03-23 19:55:44.429299 Epoch 34  	Train Loss = 17.75436 Val Loss = 23.06644
2024-03-23 20:01:53.096122 Epoch 35  	Train Loss = 17.75307 Val Loss = 23.06790
2024-03-23 20:07:58.235852 Epoch 36  	Train Loss = 17.75846 Val Loss = 23.07977
2024-03-23 20:14:05.117694 Epoch 37  	Train Loss = 17.79338 Val Loss = 23.08507
2024-03-23 20:20:16.277847 Epoch 38  	Train Loss = 17.83211 Val Loss = 23.03041
2024-03-23 20:26:26.914278 Epoch 39  	Train Loss = 17.82328 Val Loss = 23.05445
2024-03-23 20:32:34.273178 Epoch 40  	Train Loss = 17.85425 Val Loss = 23.03578
2024-03-23 20:38:45.899892 Epoch 41  	Train Loss = 17.88387 Val Loss = 23.05016
2024-03-23 20:44:57.060694 Epoch 42  	Train Loss = 17.91595 Val Loss = 23.04603
2024-03-23 20:51:07.602308 Epoch 43  	Train Loss = 17.94476 Val Loss = 22.99464
2024-03-23 20:57:16.428629 Epoch 44  	Train Loss = 17.99237 Val Loss = 23.01769
2024-03-23 21:03:24.345800 Epoch 45  	Train Loss = 17.99446 Val Loss = 22.99719
2024-03-23 21:09:34.092456 Epoch 46  	Train Loss = 18.06644 Val Loss = 22.97787
2024-03-23 21:15:41.375251 Epoch 47  	Train Loss = 18.04601 Val Loss = 22.97427
2024-03-23 21:21:51.816186 Epoch 48  	Train Loss = 18.14179 Val Loss = 22.97527
2024-03-23 21:28:00.430476 Epoch 49  	Train Loss = 18.17978 Val Loss = 22.96847
2024-03-23 21:34:11.007945 Epoch 50  	Train Loss = 18.29183 Val Loss = 23.01355
2024-03-23 21:40:17.180949 Epoch 51  	Train Loss = 18.36749 Val Loss = 23.02689
2024-03-23 21:46:26.620448 Epoch 52  	Train Loss = 18.43583 Val Loss = 22.93961
2024-03-23 21:52:34.422825 Epoch 53  	Train Loss = 18.52715 Val Loss = 22.95200
2024-03-23 21:58:45.086205 Epoch 54  	Train Loss = 18.60805 Val Loss = 22.95597
2024-03-23 22:04:55.757045 Epoch 55  	Train Loss = 18.64819 Val Loss = 22.91176
2024-03-23 22:11:08.465021 Epoch 56  	Train Loss = 18.82883 Val Loss = 22.90549
2024-03-23 22:17:18.736199 Epoch 57  	Train Loss = 18.89445 Val Loss = 22.87411
2024-03-23 22:23:19.423141 Epoch 58  	Train Loss = 19.11030 Val Loss = 22.86509
2024-03-23 22:29:30.136772 Epoch 59  	Train Loss = 19.17353 Val Loss = 22.87324
2024-03-23 22:35:45.454872 Epoch 60  	Train Loss = 19.40703 Val Loss = 22.93744
2024-03-23 22:41:50.326130 Epoch 61  	Train Loss = 19.53859 Val Loss = 22.86547
2024-03-23 22:48:03.171382 Epoch 62  	Train Loss = 19.71499 Val Loss = 22.81120
2024-03-23 22:54:14.122292 Epoch 63  	Train Loss = 19.92290 Val Loss = 22.84838
2024-03-23 23:00:25.506187 Epoch 64  	Train Loss = 20.02759 Val Loss = 22.82341
2024-03-23 23:06:34.998239 Epoch 65  	Train Loss = 20.13462 Val Loss = 22.84803
2024-03-23 23:12:48.487146 Epoch 66  	Train Loss = 20.37428 Val Loss = 22.77564
2024-03-23 23:19:02.802439 Epoch 67  	Train Loss = 20.52595 Val Loss = 22.79297
2024-03-23 23:25:17.159124 Epoch 68  	Train Loss = 20.58666 Val Loss = 22.80560
2024-03-23 23:31:30.035428 Epoch 69  	Train Loss = 20.84102 Val Loss = 22.78082
2024-03-23 23:37:40.303968 Epoch 70  	Train Loss = 20.95092 Val Loss = 22.85456
2024-03-23 23:43:50.416900 Epoch 71  	Train Loss = 21.25125 Val Loss = 22.79849
2024-03-23 23:50:06.499458 Epoch 72  	Train Loss = 21.34051 Val Loss = 22.81250
2024-03-23 23:56:16.437226 Epoch 73  	Train Loss = 21.45452 Val Loss = 22.74556
2024-03-24 00:02:29.024298 Epoch 74  	Train Loss = 21.59394 Val Loss = 22.72639
2024-03-24 00:08:44.365450 Epoch 75  	Train Loss = 21.63851 Val Loss = 22.77341
2024-03-24 00:15:01.225379 Epoch 76  	Train Loss = 21.82687 Val Loss = 22.75456
2024-03-24 00:21:17.961981 Epoch 77  	Train Loss = 21.87985 Val Loss = 22.72240
2024-03-24 00:27:30.064196 Epoch 78  	Train Loss = 22.02833 Val Loss = 22.73406
2024-03-24 00:33:42.450279 Epoch 79  	Train Loss = 22.02937 Val Loss = 22.73853
2024-03-24 00:39:57.012102 Epoch 80  	Train Loss = 22.00139 Val Loss = 22.70742
2024-03-24 00:46:07.931251 Epoch 81  	Train Loss = 22.13083 Val Loss = 22.71106
2024-03-24 00:52:18.404157 Epoch 82  	Train Loss = 22.17605 Val Loss = 22.69024
2024-03-24 00:58:31.963406 Epoch 83  	Train Loss = 22.22670 Val Loss = 22.70316
2024-03-24 01:04:46.978990 Epoch 84  	Train Loss = 22.33731 Val Loss = 22.68427
2024-03-24 01:11:03.416014 Epoch 85  	Train Loss = 22.28871 Val Loss = 22.69009
2024-03-24 01:17:16.376482 Epoch 86  	Train Loss = 22.37911 Val Loss = 22.71048
2024-03-24 01:23:28.902913 Epoch 87  	Train Loss = 22.40914 Val Loss = 22.69397
2024-03-24 01:29:39.892464 Epoch 88  	Train Loss = 22.50634 Val Loss = 22.67591
2024-03-24 01:35:56.119118 Epoch 89  	Train Loss = 22.48752 Val Loss = 22.68875
2024-03-24 01:42:11.540821 Epoch 90  	Train Loss = 22.48760 Val Loss = 22.69829
2024-03-24 01:48:24.640849 Epoch 91  	Train Loss = 22.51530 Val Loss = 22.64912
2024-03-24 01:54:37.111028 Epoch 92  	Train Loss = 22.47863 Val Loss = 22.68561
2024-03-24 02:00:49.306244 Epoch 93  	Train Loss = 22.55445 Val Loss = 22.63502
2024-03-24 02:06:59.651174 Epoch 94  	Train Loss = 22.52751 Val Loss = 22.63768
2024-03-24 02:13:12.268541 Epoch 95  	Train Loss = 22.58110 Val Loss = 22.65675
2024-03-24 02:19:26.249521 Epoch 96  	Train Loss = 22.55373 Val Loss = 22.60821
2024-03-24 02:25:36.774469 Epoch 97  	Train Loss = 22.54516 Val Loss = 22.60711
2024-03-24 02:31:45.424972 Epoch 98  	Train Loss = 22.56359 Val Loss = 22.65001
2024-03-24 02:37:57.403364 Epoch 99  	Train Loss = 22.57907 Val Loss = 22.65341
2024-03-24 02:44:10.021208 Epoch 100  	Train Loss = 22.53592 Val Loss = 22.64154
2024-03-24 02:50:24.365053 Epoch 101  	Train Loss = 22.58920 Val Loss = 22.71817
2024-03-24 02:56:41.048950 Epoch 102  	Train Loss = 22.55975 Val Loss = 22.63118
2024-03-24 03:02:52.911629 Epoch 103  	Train Loss = 22.56966 Val Loss = 22.71728
2024-03-24 03:09:02.226622 Epoch 104  	Train Loss = 22.56913 Val Loss = 22.64232
2024-03-24 03:15:14.412175 Epoch 105  	Train Loss = 22.55556 Val Loss = 22.62387
2024-03-24 03:21:23.366363 Epoch 106  	Train Loss = 22.53005 Val Loss = 22.60033
2024-03-24 03:27:35.366963 Epoch 107  	Train Loss = 22.55266 Val Loss = 22.63935
2024-03-24 03:33:46.161127 Epoch 108  	Train Loss = 22.56012 Val Loss = 22.58049
2024-03-24 03:39:53.834352 Epoch 109  	Train Loss = 22.56179 Val Loss = 22.70401
2024-03-24 03:46:05.535471 Epoch 110  	Train Loss = 22.55707 Val Loss = 22.59355
2024-03-24 03:52:15.786082 Epoch 111  	Train Loss = 22.54240 Val Loss = 22.56836
2024-03-24 03:58:26.416908 Epoch 112  	Train Loss = 22.54800 Val Loss = 22.60775
2024-03-24 04:04:37.955640 Epoch 113  	Train Loss = 22.52768 Val Loss = 22.60987
2024-03-24 04:10:54.230240 Epoch 114  	Train Loss = 22.53158 Val Loss = 22.58307
2024-03-24 04:17:07.876700 Epoch 115  	Train Loss = 22.53724 Val Loss = 22.56853
2024-03-24 04:23:22.173066 Epoch 116  	Train Loss = 22.52481 Val Loss = 22.57827
2024-03-24 04:29:36.426898 Epoch 117  	Train Loss = 22.52489 Val Loss = 22.57341
2024-03-24 04:35:53.197615 Epoch 118  	Train Loss = 22.51873 Val Loss = 22.56653
2024-03-24 04:42:07.046367 Epoch 119  	Train Loss = 22.50460 Val Loss = 22.59830
2024-03-24 04:48:23.224349 Epoch 120  	Train Loss = 22.51934 Val Loss = 22.60809
2024-03-24 04:54:37.800180 Epoch 121  	Train Loss = 22.51367 Val Loss = 22.59941
2024-03-24 05:00:50.872135 Epoch 122  	Train Loss = 22.51493 Val Loss = 22.55863
2024-03-24 05:07:05.497316 Epoch 123  	Train Loss = 22.50511 Val Loss = 22.57505
2024-03-24 05:13:15.785339 Epoch 124  	Train Loss = 22.49528 Val Loss = 22.56575
2024-03-24 05:19:27.637776 Epoch 125  	Train Loss = 22.49143 Val Loss = 22.53249
2024-03-24 05:25:38.496471 Epoch 126  	Train Loss = 22.49625 Val Loss = 22.55766
2024-03-24 05:31:55.183967 Epoch 127  	Train Loss = 22.48704 Val Loss = 22.55596
2024-03-24 05:38:08.995025 Epoch 128  	Train Loss = 22.48122 Val Loss = 22.54827
2024-03-24 05:44:18.203166 Epoch 129  	Train Loss = 22.47938 Val Loss = 22.57519
2024-03-24 05:50:30.946014 Epoch 130  	Train Loss = 22.48049 Val Loss = 22.58340
2024-03-24 05:56:44.303029 Epoch 131  	Train Loss = 22.47430 Val Loss = 22.55010
2024-03-24 06:03:00.254153 Epoch 132  	Train Loss = 22.46050 Val Loss = 22.57659
2024-03-24 06:09:10.720566 Epoch 133  	Train Loss = 22.46675 Val Loss = 22.54749
2024-03-24 06:15:20.878223 Epoch 134  	Train Loss = 22.46604 Val Loss = 22.53920
2024-03-24 06:21:32.562040 Epoch 135  	Train Loss = 22.45872 Val Loss = 22.58142
Early stopping at epoch: 135
Best at epoch 125:
Train Loss = 22.49143
Train RMSE = 35.35021, MAE = 22.22505, MAPE = 9.74710
Val Loss = 22.53249
Val RMSE = 35.28341, MAE = 22.19202, MAPE = 9.81928
--------- Test ---------
All Steps RMSE = 35.39397, MAE = 22.46700, MAPE = 9.62436
Step 1 RMSE = 28.15033, MAE = 17.74258, MAPE = 7.49693
Step 2 RMSE = 30.63029, MAE = 19.28294, MAPE = 8.14137
Step 3 RMSE = 32.31498, MAE = 20.43827, MAPE = 8.66582
Step 4 RMSE = 33.49596, MAE = 21.23037, MAPE = 9.02150
Step 5 RMSE = 34.47018, MAE = 21.86324, MAPE = 9.29085
Step 6 RMSE = 35.36158, MAE = 22.47560, MAPE = 9.56753
Step 7 RMSE = 36.24017, MAE = 23.10514, MAPE = 9.87102
Step 8 RMSE = 37.02316, MAE = 23.67926, MAPE = 10.15499
Step 9 RMSE = 37.71589, MAE = 24.18507, MAPE = 10.41633
Step 10 RMSE = 38.36502, MAE = 24.64807, MAPE = 10.65976
Step 11 RMSE = 39.08053, MAE = 25.16341, MAPE = 10.93276
Step 12 RMSE = 39.89231, MAE = 25.78670, MAPE = 11.27203
Inference time: 71.00 s
