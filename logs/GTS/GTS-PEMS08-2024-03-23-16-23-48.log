PEMS08
Trainset:	x-(10700, 12, 170, 2)	y-(10700, 12, 170, 1)
Valset:  	x-(3567, 12, 170, 2)  	y-(3567, 12, 170, 1)
Testset:	x-(3566, 12, 170, 2)	y-(3566, 12, 170, 1)

--------- GTS ---------
{
    "num_nodes": 170,
    "in_steps": 12,
    "out_steps": 12,
    "time_of_day": true,
    "runner": "GTS",
    "loss": "GTS",
    "lr": 0.001,
    "eps": 0.001,
    "milestones": [
        20,
        30
    ],
    "clip_grad": 5,
    "batch_size": 64,
    "max_epochs": 200,
    "early_stop": 10,
    "model_args": {
        "num_nodes": 170,
        "input_dim": 2,
        "output_dim": 1,
        "seq_len": 12,
        "horizon": 12,
        "rnn_units": 64,
        "num_rnn_layers": 1,
        "max_diffusion_step": 3,
        "filter_type": "dual_random_walk",
        "tf_decay_steps": 2000,
        "use_teacher_forcing": true,
        "l1_decay": 0,
        "temp": 0.5,
        "k": 30,
        "dim_fc": 171136,
        "dataset_name": "PEMS08",
        "trainset_ratio": 0.6
    }
}
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
GTS                                      [64, 12, 170, 1]          --
├─Conv1d: 1-1                            [170, 8, 10705]           88
├─BatchNorm1d: 1-2                       [170, 8, 10705]           16
├─Conv1d: 1-3                            [170, 16, 10696]          1,296
├─BatchNorm1d: 1-4                       [170, 16, 10696]          32
├─Linear: 1-5                            [170, 100]                17,113,700
├─BatchNorm1d: 1-6                       [170, 100]                200
├─Linear: 1-7                            [28900, 100]              20,100
├─Linear: 1-8                            [28900, 2]                202
├─EncoderModel: 1-9                      [64, 10880]               --
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-1               [64, 10880]               --
├─EncoderModel: 1-10                     [64, 10880]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-2               [64, 10880]               (recursive)
├─EncoderModel: 1-11                     [64, 10880]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-3               [64, 10880]               (recursive)
├─EncoderModel: 1-12                     [64, 10880]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-4               [64, 10880]               (recursive)
├─EncoderModel: 1-13                     [64, 10880]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-5               [64, 10880]               (recursive)
├─EncoderModel: 1-14                     [64, 10880]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-6               [64, 10880]               (recursive)
├─EncoderModel: 1-15                     [64, 10880]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-7               [64, 10880]               (recursive)
├─EncoderModel: 1-16                     [64, 10880]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-8               [64, 10880]               (recursive)
├─EncoderModel: 1-17                     [64, 10880]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-9               [64, 10880]               (recursive)
├─EncoderModel: 1-18                     [64, 10880]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-10              [64, 10880]               (recursive)
├─EncoderModel: 1-19                     [64, 10880]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-11              [64, 10880]               (recursive)
├─EncoderModel: 1-20                     [64, 10880]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-12              [64, 10880]               (recursive)
├─DecoderModel: 1-21                     [64, 170]                 --
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-13              [64, 10880]               --
│    └─Linear: 2-14                      [10880, 1]                65
├─DecoderModel: 1-22                     [64, 170]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-14              [64, 10880]               (recursive)
│    └─Linear: 2-16                      [10880, 1]                (recursive)
├─DecoderModel: 1-23                     [64, 170]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-15              [64, 10880]               (recursive)
│    └─Linear: 2-18                      [10880, 1]                (recursive)
├─DecoderModel: 1-24                     [64, 170]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-16              [64, 10880]               (recursive)
│    └─Linear: 2-20                      [10880, 1]                (recursive)
├─DecoderModel: 1-25                     [64, 170]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-17              [64, 10880]               (recursive)
│    └─Linear: 2-22                      [10880, 1]                (recursive)
├─DecoderModel: 1-26                     [64, 170]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-18              [64, 10880]               (recursive)
│    └─Linear: 2-24                      [10880, 1]                (recursive)
├─DecoderModel: 1-27                     [64, 170]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-19              [64, 10880]               (recursive)
│    └─Linear: 2-26                      [10880, 1]                (recursive)
├─DecoderModel: 1-28                     [64, 170]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-20              [64, 10880]               (recursive)
│    └─Linear: 2-28                      [10880, 1]                (recursive)
├─DecoderModel: 1-29                     [64, 170]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-21              [64, 10880]               (recursive)
│    └─Linear: 2-30                      [10880, 1]                (recursive)
├─DecoderModel: 1-30                     [64, 170]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-22              [64, 10880]               (recursive)
│    └─Linear: 2-32                      [10880, 1]                (recursive)
├─DecoderModel: 1-31                     [64, 170]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-23              [64, 10880]               (recursive)
│    └─Linear: 2-34                      [10880, 1]                (recursive)
├─DecoderModel: 1-32                     [64, 170]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-24              [64, 10880]               (recursive)
│    └─Linear: 2-36                      [10880, 1]                (recursive)
==========================================================================================
Total params: 17,135,699
Trainable params: 17,135,699
Non-trainable params: 0
Total mult-adds (G): 849.89
==========================================================================================
Input size (MB): 1.04
Forward/backward pass size (MB): 845.88
Params size (MB): 68.54
Estimated Total Size (MB): 915.47
==========================================================================================

Loss: GTSLoss

2024-03-23 16:24:14.647118 Epoch 1  	Train Loss = 22.85295 Val Loss = 24.02723
2024-03-23 16:24:36.287734 Epoch 2  	Train Loss = 15.34342 Val Loss = 21.25753
2024-03-23 16:24:59.096816 Epoch 3  	Train Loss = 14.94889 Val Loss = 21.45934
2024-03-23 16:25:21.946430 Epoch 4  	Train Loss = 14.72405 Val Loss = 22.85316
2024-03-23 16:25:43.667546 Epoch 5  	Train Loss = 14.53358 Val Loss = 23.21821
2024-03-23 16:26:04.744727 Epoch 6  	Train Loss = 14.44130 Val Loss = 20.84426
2024-03-23 16:26:26.392151 Epoch 7  	Train Loss = 14.37604 Val Loss = 20.29052
2024-03-23 16:26:47.679204 Epoch 8  	Train Loss = 14.28431 Val Loss = 22.59808
2024-03-23 16:27:09.421574 Epoch 9  	Train Loss = 14.22968 Val Loss = 19.57512
2024-03-23 16:27:31.550566 Epoch 10  	Train Loss = 14.15421 Val Loss = 19.37187
2024-03-23 16:27:53.229558 Epoch 11  	Train Loss = 14.13835 Val Loss = 20.30994
2024-03-23 16:28:15.026346 Epoch 12  	Train Loss = 14.10878 Val Loss = 19.18176
2024-03-23 16:28:37.481387 Epoch 13  	Train Loss = 14.10114 Val Loss = 19.75871
2024-03-23 16:29:00.216549 Epoch 14  	Train Loss = 14.04602 Val Loss = 19.11177
2024-03-23 16:29:22.525239 Epoch 15  	Train Loss = 14.04697 Val Loss = 19.26132
2024-03-23 16:29:45.961895 Epoch 16  	Train Loss = 14.01395 Val Loss = 19.39652
2024-03-23 16:30:07.995644 Epoch 17  	Train Loss = 13.97795 Val Loss = 18.99504
2024-03-23 16:30:30.248869 Epoch 18  	Train Loss = 13.96695 Val Loss = 18.39024
2024-03-23 16:30:52.462546 Epoch 19  	Train Loss = 13.95741 Val Loss = 18.46473
2024-03-23 16:31:14.437421 Epoch 20  	Train Loss = 13.93625 Val Loss = 18.62307
2024-03-23 16:31:36.424995 Epoch 21  	Train Loss = 13.85428 Val Loss = 18.13958
2024-03-23 16:31:59.503889 Epoch 22  	Train Loss = 13.84180 Val Loss = 18.14700
2024-03-23 16:32:22.544459 Epoch 23  	Train Loss = 13.84787 Val Loss = 17.98376
2024-03-23 16:32:44.903894 Epoch 24  	Train Loss = 13.82444 Val Loss = 18.11319
2024-03-23 16:33:07.812488 Epoch 25  	Train Loss = 13.82187 Val Loss = 17.92536
2024-03-23 16:33:29.967480 Epoch 26  	Train Loss = 13.81207 Val Loss = 17.93479
2024-03-23 16:33:51.973963 Epoch 27  	Train Loss = 13.82599 Val Loss = 18.03643
2024-03-23 16:34:14.187465 Epoch 28  	Train Loss = 13.80849 Val Loss = 17.86659
2024-03-23 16:34:36.762728 Epoch 29  	Train Loss = 13.80589 Val Loss = 17.85903
2024-03-23 16:34:58.850534 Epoch 30  	Train Loss = 13.79949 Val Loss = 17.91109
2024-03-23 16:35:21.468967 Epoch 31  	Train Loss = 13.78852 Val Loss = 17.87527
2024-03-23 16:35:43.790911 Epoch 32  	Train Loss = 13.79396 Val Loss = 17.85243
2024-03-23 16:36:05.715998 Epoch 33  	Train Loss = 13.79223 Val Loss = 17.84438
2024-03-23 16:36:27.988635 Epoch 34  	Train Loss = 13.80036 Val Loss = 17.81214
2024-03-23 16:36:49.712767 Epoch 35  	Train Loss = 13.80352 Val Loss = 17.82985
2024-03-23 16:37:11.711060 Epoch 36  	Train Loss = 13.80159 Val Loss = 17.81748
2024-03-23 16:37:33.057198 Epoch 37  	Train Loss = 13.78445 Val Loss = 17.82092
2024-03-23 16:37:55.207684 Epoch 38  	Train Loss = 13.79040 Val Loss = 17.89183
2024-03-23 16:38:16.922876 Epoch 39  	Train Loss = 13.79605 Val Loss = 17.82649
2024-03-23 16:38:39.178310 Epoch 40  	Train Loss = 13.79268 Val Loss = 17.82370
2024-03-23 16:39:01.736157 Epoch 41  	Train Loss = 13.79366 Val Loss = 17.80894
2024-03-23 16:39:23.085665 Epoch 42  	Train Loss = 13.80061 Val Loss = 17.79644
2024-03-23 16:39:44.631865 Epoch 43  	Train Loss = 13.80025 Val Loss = 17.82921
2024-03-23 16:40:06.786342 Epoch 44  	Train Loss = 13.80310 Val Loss = 17.84139
2024-03-23 16:40:29.453681 Epoch 45  	Train Loss = 13.79846 Val Loss = 17.81574
2024-03-23 16:40:52.131368 Epoch 46  	Train Loss = 13.80692 Val Loss = 17.89086
2024-03-23 16:41:13.687633 Epoch 47  	Train Loss = 13.80507 Val Loss = 17.81431
2024-03-23 16:41:35.794371 Epoch 48  	Train Loss = 13.80516 Val Loss = 17.80923
2024-03-23 16:41:57.460648 Epoch 49  	Train Loss = 13.80534 Val Loss = 17.88047
2024-03-23 16:42:19.282803 Epoch 50  	Train Loss = 13.81232 Val Loss = 17.80596
2024-03-23 16:42:40.598874 Epoch 51  	Train Loss = 13.80940 Val Loss = 17.83128
2024-03-23 16:43:03.381480 Epoch 52  	Train Loss = 13.82422 Val Loss = 17.77104
2024-03-23 16:43:25.549580 Epoch 53  	Train Loss = 13.82024 Val Loss = 17.76864
2024-03-23 16:43:47.295816 Epoch 54  	Train Loss = 13.82962 Val Loss = 17.82985
2024-03-23 16:44:09.056357 Epoch 55  	Train Loss = 13.83497 Val Loss = 17.81090
2024-03-23 16:44:30.321169 Epoch 56  	Train Loss = 13.83386 Val Loss = 17.78114
2024-03-23 16:44:52.892887 Epoch 57  	Train Loss = 13.85322 Val Loss = 17.79624
2024-03-23 16:45:14.894091 Epoch 58  	Train Loss = 13.82603 Val Loss = 17.79785
2024-03-23 16:45:36.831315 Epoch 59  	Train Loss = 13.86962 Val Loss = 17.80037
2024-03-23 16:45:58.528104 Epoch 60  	Train Loss = 13.86960 Val Loss = 17.80263
2024-03-23 16:46:20.772243 Epoch 61  	Train Loss = 13.86280 Val Loss = 17.82122
2024-03-23 16:46:42.189756 Epoch 62  	Train Loss = 13.88611 Val Loss = 17.79718
2024-03-23 16:47:03.172794 Epoch 63  	Train Loss = 13.88814 Val Loss = 17.77390
Early stopping at epoch: 63
Best at epoch 53:
Train Loss = 13.82024
Train RMSE = 28.06647, MAE = 17.33048, MAPE = 11.19301
Val Loss = 17.76864
Val RMSE = 28.13859, MAE = 17.63640, MAPE = 12.33354
--------- Test ---------
All Steps RMSE = 26.84823, MAE = 17.03628, MAPE = 11.06086
Step 1 RMSE = 20.56969, MAE = 13.25847, MAPE = 8.61413
Step 2 RMSE = 22.44144, MAE = 14.38462, MAPE = 9.25290
Step 3 RMSE = 23.93857, MAE = 15.31634, MAPE = 9.79604
Step 4 RMSE = 25.06937, MAE = 15.96272, MAPE = 10.23561
Step 5 RMSE = 25.94572, MAE = 16.47983, MAPE = 10.60552
Step 6 RMSE = 26.72334, MAE = 16.95504, MAPE = 10.96874
Step 7 RMSE = 27.52725, MAE = 17.50116, MAPE = 11.35285
Step 8 RMSE = 28.29516, MAE = 18.02976, MAPE = 11.73330
Step 9 RMSE = 28.95107, MAE = 18.48977, MAPE = 12.07428
Step 10 RMSE = 29.52919, MAE = 18.88885, MAPE = 12.37208
Step 11 RMSE = 30.15568, MAE = 19.31689, MAPE = 12.67936
Step 12 RMSE = 30.92721, MAE = 19.85209, MAPE = 13.04559
Inference time: 2.28 s
