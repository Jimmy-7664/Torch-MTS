PEMS04
Trainset:	x-(10181, 12, 307, 2)	y-(10181, 12, 307, 1)
Valset:  	x-(3394, 12, 307, 2)  	y-(3394, 12, 307, 1)
Testset:	x-(3394, 12, 307, 2)	y-(3394, 12, 307, 1)

--------- GTS ---------
{
    "num_nodes": 307,
    "in_steps": 12,
    "out_steps": 12,
    "time_of_day": true,
    "runner": "GTS",
    "loss": "GTS",
    "lr": 0.001,
    "eps": 0.001,
    "milestones": [
        20,
        30
    ],
    "clip_grad": 5,
    "batch_size": 64,
    "max_epochs": 200,
    "early_stop": 10,
    "model_args": {
        "num_nodes": 307,
        "input_dim": 2,
        "output_dim": 1,
        "seq_len": 12,
        "horizon": 12,
        "rnn_units": 64,
        "num_rnn_layers": 1,
        "max_diffusion_step": 3,
        "filter_type": "dual_random_walk",
        "tf_decay_steps": 2000,
        "use_teacher_forcing": true,
        "l1_decay": 0,
        "temp": 0.5,
        "k": 30,
        "dim_fc": 162832,
        "dataset_name": "PEMS04",
        "trainset_ratio": 0.6
    }
}
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
GTS                                      [64, 12, 307, 1]          --
├─Conv1d: 1-1                            [307, 8, 10186]           88
├─BatchNorm1d: 1-2                       [307, 8, 10186]           16
├─Conv1d: 1-3                            [307, 16, 10177]          1,296
├─BatchNorm1d: 1-4                       [307, 16, 10177]          32
├─Linear: 1-5                            [307, 100]                16,283,300
├─BatchNorm1d: 1-6                       [307, 100]                200
├─Linear: 1-7                            [94249, 100]              20,100
├─Linear: 1-8                            [94249, 2]                202
├─EncoderModel: 1-9                      [64, 19648]               --
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-1               [64, 19648]               --
├─EncoderModel: 1-10                     [64, 19648]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-2               [64, 19648]               (recursive)
├─EncoderModel: 1-11                     [64, 19648]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-3               [64, 19648]               (recursive)
├─EncoderModel: 1-12                     [64, 19648]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-4               [64, 19648]               (recursive)
├─EncoderModel: 1-13                     [64, 19648]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-5               [64, 19648]               (recursive)
├─EncoderModel: 1-14                     [64, 19648]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-6               [64, 19648]               (recursive)
├─EncoderModel: 1-15                     [64, 19648]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-7               [64, 19648]               (recursive)
├─EncoderModel: 1-16                     [64, 19648]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-8               [64, 19648]               (recursive)
├─EncoderModel: 1-17                     [64, 19648]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-9               [64, 19648]               (recursive)
├─EncoderModel: 1-18                     [64, 19648]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-10              [64, 19648]               (recursive)
├─EncoderModel: 1-19                     [64, 19648]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-11              [64, 19648]               (recursive)
├─EncoderModel: 1-20                     [64, 19648]               (recursive)
│    └─ModuleList: 2-12                  --                        (recursive)
│    │    └─DCGRUCell: 3-12              [64, 19648]               (recursive)
├─DecoderModel: 1-21                     [64, 307]                 --
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-13              [64, 19648]               --
│    └─Linear: 2-14                      [19648, 1]                65
├─DecoderModel: 1-22                     [64, 307]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-14              [64, 19648]               (recursive)
│    └─Linear: 2-16                      [19648, 1]                (recursive)
├─DecoderModel: 1-23                     [64, 307]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-15              [64, 19648]               (recursive)
│    └─Linear: 2-18                      [19648, 1]                (recursive)
├─DecoderModel: 1-24                     [64, 307]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-16              [64, 19648]               (recursive)
│    └─Linear: 2-20                      [19648, 1]                (recursive)
├─DecoderModel: 1-25                     [64, 307]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-17              [64, 19648]               (recursive)
│    └─Linear: 2-22                      [19648, 1]                (recursive)
├─DecoderModel: 1-26                     [64, 307]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-18              [64, 19648]               (recursive)
│    └─Linear: 2-24                      [19648, 1]                (recursive)
├─DecoderModel: 1-27                     [64, 307]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-19              [64, 19648]               (recursive)
│    └─Linear: 2-26                      [19648, 1]                (recursive)
├─DecoderModel: 1-28                     [64, 307]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-20              [64, 19648]               (recursive)
│    └─Linear: 2-28                      [19648, 1]                (recursive)
├─DecoderModel: 1-29                     [64, 307]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-21              [64, 19648]               (recursive)
│    └─Linear: 2-30                      [19648, 1]                (recursive)
├─DecoderModel: 1-30                     [64, 307]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-22              [64, 19648]               (recursive)
│    └─Linear: 2-32                      [19648, 1]                (recursive)
├─DecoderModel: 1-31                     [64, 307]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-23              [64, 19648]               (recursive)
│    └─Linear: 2-34                      [19648, 1]                (recursive)
├─DecoderModel: 1-32                     [64, 307]                 (recursive)
│    └─ModuleList: 2-35                  --                        (recursive)
│    │    └─DCGRUCell: 3-24              [64, 19648]               (recursive)
│    └─Linear: 2-36                      [19648, 1]                (recursive)
==========================================================================================
Total params: 16,305,299
Trainable params: 16,305,299
Non-trainable params: 0
Total mult-adds (T): 1.54
==========================================================================================
Input size (MB): 1.89
Forward/backward pass size (MB): 1500.70
Params size (MB): 65.22
Estimated Total Size (MB): 1567.81
==========================================================================================

Loss: GTSLoss

2024-03-23 16:24:24.702959 Epoch 1  	Train Loss = 27.53791 Val Loss = 26.61175
2024-03-23 16:24:59.075193 Epoch 2  	Train Loss = 19.03471 Val Loss = 26.91890
2024-03-23 16:25:33.843027 Epoch 3  	Train Loss = 18.55626 Val Loss = 28.09284
2024-03-23 16:26:08.024565 Epoch 4  	Train Loss = 18.44164 Val Loss = 25.85491
2024-03-23 16:26:42.100399 Epoch 5  	Train Loss = 18.23271 Val Loss = 26.17339
2024-03-23 16:27:16.663677 Epoch 6  	Train Loss = 18.13596 Val Loss = 28.43665
2024-03-23 16:27:51.044506 Epoch 7  	Train Loss = 18.00197 Val Loss = 29.99435
2024-03-23 16:28:25.440164 Epoch 8  	Train Loss = 17.93168 Val Loss = 26.12683
2024-03-23 16:29:00.140977 Epoch 9  	Train Loss = 17.86161 Val Loss = 25.90130
2024-03-23 16:29:34.633530 Epoch 10  	Train Loss = 17.79698 Val Loss = 27.51990
2024-03-23 16:30:09.901506 Epoch 11  	Train Loss = 17.75207 Val Loss = 25.00668
2024-03-23 16:30:44.739063 Epoch 12  	Train Loss = 17.69838 Val Loss = 24.74066
2024-03-23 16:31:19.110539 Epoch 13  	Train Loss = 17.66765 Val Loss = 23.61252
2024-03-23 16:31:53.396013 Epoch 14  	Train Loss = 17.64749 Val Loss = 27.34317
2024-03-23 16:32:28.251792 Epoch 15  	Train Loss = 17.60141 Val Loss = 25.80147
2024-03-23 16:33:03.135111 Epoch 16  	Train Loss = 17.62819 Val Loss = 23.77511
2024-03-23 16:33:37.432361 Epoch 17  	Train Loss = 17.56967 Val Loss = 24.34891
2024-03-23 16:34:11.284281 Epoch 18  	Train Loss = 17.51497 Val Loss = 26.58825
2024-03-23 16:34:45.875947 Epoch 19  	Train Loss = 17.51321 Val Loss = 23.44764
2024-03-23 16:35:20.662763 Epoch 20  	Train Loss = 17.48196 Val Loss = 25.06676
2024-03-23 16:35:55.474880 Epoch 21  	Train Loss = 17.40121 Val Loss = 22.63032
2024-03-23 16:36:30.054106 Epoch 22  	Train Loss = 17.36632 Val Loss = 22.37565
2024-03-23 16:37:04.159999 Epoch 23  	Train Loss = 17.35752 Val Loss = 22.30303
2024-03-23 16:37:38.936614 Epoch 24  	Train Loss = 17.36209 Val Loss = 22.70344
2024-03-23 16:38:13.573564 Epoch 25  	Train Loss = 17.31712 Val Loss = 22.31237
2024-03-23 16:38:47.733675 Epoch 26  	Train Loss = 17.35736 Val Loss = 22.28141
2024-03-23 16:39:21.813817 Epoch 27  	Train Loss = 17.35662 Val Loss = 22.21722
2024-03-23 16:39:55.860818 Epoch 28  	Train Loss = 17.32936 Val Loss = 22.15353
2024-03-23 16:40:30.739415 Epoch 29  	Train Loss = 17.29880 Val Loss = 22.14668
2024-03-23 16:41:05.281088 Epoch 30  	Train Loss = 17.35568 Val Loss = 22.34916
2024-03-23 16:41:39.618128 Epoch 31  	Train Loss = 17.25345 Val Loss = 22.12545
2024-03-23 16:42:14.283248 Epoch 32  	Train Loss = 17.30820 Val Loss = 22.12218
2024-03-23 16:42:48.889727 Epoch 33  	Train Loss = 17.31975 Val Loss = 22.09185
2024-03-23 16:43:23.763409 Epoch 34  	Train Loss = 17.30955 Val Loss = 22.09781
2024-03-23 16:43:58.118152 Epoch 35  	Train Loss = 17.31125 Val Loss = 22.11370
2024-03-23 16:44:32.215178 Epoch 36  	Train Loss = 17.28270 Val Loss = 22.09347
2024-03-23 16:45:06.640386 Epoch 37  	Train Loss = 17.27050 Val Loss = 22.07547
2024-03-23 16:45:41.284930 Epoch 38  	Train Loss = 17.30637 Val Loss = 22.07241
2024-03-23 16:46:15.487075 Epoch 39  	Train Loss = 17.33424 Val Loss = 22.10577
2024-03-23 16:46:49.336521 Epoch 40  	Train Loss = 17.31995 Val Loss = 22.08251
2024-03-23 16:47:23.006910 Epoch 41  	Train Loss = 17.29867 Val Loss = 22.09225
2024-03-23 16:47:57.213893 Epoch 42  	Train Loss = 17.32660 Val Loss = 22.05659
2024-03-23 16:48:31.220871 Epoch 43  	Train Loss = 17.33015 Val Loss = 22.06732
2024-03-23 16:49:05.191202 Epoch 44  	Train Loss = 17.31648 Val Loss = 22.08876
2024-03-23 16:49:40.116405 Epoch 45  	Train Loss = 17.33033 Val Loss = 22.06138
2024-03-23 16:50:13.988196 Epoch 46  	Train Loss = 17.30127 Val Loss = 22.10035
2024-03-23 16:50:47.991049 Epoch 47  	Train Loss = 17.29804 Val Loss = 22.12602
2024-03-23 16:51:21.907131 Epoch 48  	Train Loss = 17.32095 Val Loss = 22.05813
2024-03-23 16:51:55.334445 Epoch 49  	Train Loss = 17.32736 Val Loss = 22.09829
2024-03-23 16:52:29.014750 Epoch 50  	Train Loss = 17.27999 Val Loss = 22.05641
2024-03-23 16:53:02.760867 Epoch 51  	Train Loss = 17.32296 Val Loss = 22.11312
2024-03-23 16:53:36.517233 Epoch 52  	Train Loss = 17.32243 Val Loss = 22.05170
2024-03-23 16:54:09.910209 Epoch 53  	Train Loss = 17.32061 Val Loss = 22.05664
2024-03-23 16:54:43.541561 Epoch 54  	Train Loss = 17.30790 Val Loss = 22.05001
2024-03-23 16:55:17.394356 Epoch 55  	Train Loss = 17.31416 Val Loss = 22.06510
2024-03-23 16:55:52.122731 Epoch 56  	Train Loss = 17.30122 Val Loss = 22.09392
2024-03-23 16:56:26.066335 Epoch 57  	Train Loss = 17.34186 Val Loss = 22.02034
2024-03-23 16:57:00.139740 Epoch 58  	Train Loss = 17.34141 Val Loss = 22.05727
2024-03-23 16:57:33.845590 Epoch 59  	Train Loss = 17.37198 Val Loss = 22.05211
2024-03-23 16:58:07.602260 Epoch 60  	Train Loss = 17.32878 Val Loss = 22.02582
2024-03-23 16:58:41.572414 Epoch 61  	Train Loss = 17.35858 Val Loss = 21.96131
2024-03-23 16:59:15.706877 Epoch 62  	Train Loss = 17.40358 Val Loss = 22.03901
2024-03-23 16:59:49.065849 Epoch 63  	Train Loss = 17.37068 Val Loss = 21.98359
2024-03-23 17:00:22.803179 Epoch 64  	Train Loss = 17.32050 Val Loss = 22.03855
2024-03-23 17:00:56.478705 Epoch 65  	Train Loss = 17.38994 Val Loss = 21.98548
2024-03-23 17:01:31.080734 Epoch 66  	Train Loss = 17.39963 Val Loss = 22.01884
2024-03-23 17:02:05.848880 Epoch 67  	Train Loss = 17.44514 Val Loss = 22.00103
2024-03-23 17:02:39.739488 Epoch 68  	Train Loss = 17.43135 Val Loss = 21.97778
2024-03-23 17:03:13.865812 Epoch 69  	Train Loss = 17.46442 Val Loss = 21.98122
2024-03-23 17:03:48.004220 Epoch 70  	Train Loss = 17.45333 Val Loss = 21.99659
2024-03-23 17:04:22.108914 Epoch 71  	Train Loss = 17.44697 Val Loss = 21.96941
Early stopping at epoch: 71
Best at epoch 61:
Train Loss = 17.35858
Train RMSE = 33.55726, MAE = 21.19351, MAPE = 16.08049
Val Loss = 21.96131
Val RMSE = 35.02940, MAE = 22.17457, MAPE = 15.30108
--------- Test ---------
All Steps RMSE = 33.69145, MAE = 21.46529, MAPE = 15.06462
Step 1 RMSE = 27.73334, MAE = 17.35335, MAPE = 11.95024
Step 2 RMSE = 29.33900, MAE = 18.45668, MAPE = 12.72703
Step 3 RMSE = 30.72904, MAE = 19.46292, MAPE = 13.42386
Step 4 RMSE = 31.80455, MAE = 20.22162, MAPE = 14.01839
Step 5 RMSE = 32.66033, MAE = 20.80300, MAPE = 14.50403
Step 6 RMSE = 33.45429, MAE = 21.34863, MAPE = 14.94365
Step 7 RMSE = 34.30803, MAE = 21.95708, MAPE = 15.40720
Step 8 RMSE = 35.13199, MAE = 22.57205, MAPE = 15.86851
Step 9 RMSE = 35.88306, MAE = 23.11724, MAPE = 16.31507
Step 10 RMSE = 36.51920, MAE = 23.59076, MAPE = 16.74148
Step 11 RMSE = 37.14837, MAE = 24.06554, MAPE = 17.18987
Step 12 RMSE = 37.90997, MAE = 24.63392, MAPE = 17.68561
Inference time: 4.71 s
