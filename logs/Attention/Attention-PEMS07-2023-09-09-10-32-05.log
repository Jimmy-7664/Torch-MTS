PEMS07
Trainset:	x-(16921, 12, 883, 2)	y-(16921, 12, 883, 1)
Valset:  	x-(5640, 12, 883, 2)  	y-(5640, 12, 883, 1)
Testset:	x-(5640, 12, 883, 2)	y-(5640, 12, 883, 1)

--------- Attention ---------
{
    "num_nodes": 883,
    "in_steps": 12,
    "out_steps": 12,
    "train_size": 0.7,
    "val_size": 0.1,
    "time_of_day": true,
    "lr": 0.001,
    "milestones": [
        10,
        40
    ],
    "batch_size": 32,
    "max_epochs": 200,
    "use_cl": false,
    "model_args": {
        "num_nodes": 883,
        "in_steps": 12,
        "out_steps": 12,
        "input_dim": 1,
        "output_dim": 1,
        "model_dim": 64,
        "feed_forward_dim": 256,
        "num_heads": 4,
        "num_layers": 3,
        "with_spatial": true
    }
}
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Attention                                [32, 12, 883, 1]          --
├─Linear: 1-1                            [32, 12, 883, 64]         128
├─Linear: 1-2                            [32, 12, 883, 64]         128
├─ModuleList: 1-3                        --                        --
│    └─SelfAttentionLayer: 2-1           [32, 12, 883, 64]         --
│    │    └─AttentionLayer: 3-1          [32, 883, 12, 64]         16,640
│    │    └─Dropout: 3-2                 [32, 883, 12, 64]         --
│    │    └─LayerNorm: 3-3               [32, 883, 12, 64]         128
│    │    └─Sequential: 3-4              [32, 883, 12, 64]         33,088
│    │    └─Dropout: 3-5                 [32, 883, 12, 64]         --
│    │    └─LayerNorm: 3-6               [32, 883, 12, 64]         128
│    └─SelfAttentionLayer: 2-2           [32, 12, 883, 64]         --
│    │    └─AttentionLayer: 3-7          [32, 883, 12, 64]         16,640
│    │    └─Dropout: 3-8                 [32, 883, 12, 64]         --
│    │    └─LayerNorm: 3-9               [32, 883, 12, 64]         128
│    │    └─Sequential: 3-10             [32, 883, 12, 64]         33,088
│    │    └─Dropout: 3-11                [32, 883, 12, 64]         --
│    │    └─LayerNorm: 3-12              [32, 883, 12, 64]         128
│    └─SelfAttentionLayer: 2-3           [32, 12, 883, 64]         --
│    │    └─AttentionLayer: 3-13         [32, 883, 12, 64]         16,640
│    │    └─Dropout: 3-14                [32, 883, 12, 64]         --
│    │    └─LayerNorm: 3-15              [32, 883, 12, 64]         128
│    │    └─Sequential: 3-16             [32, 883, 12, 64]         33,088
│    │    └─Dropout: 3-17                [32, 883, 12, 64]         --
│    │    └─LayerNorm: 3-18              [32, 883, 12, 64]         128
├─ModuleList: 1-4                        --                        --
│    └─SelfAttentionLayer: 2-4           [32, 12, 883, 64]         --
│    │    └─AttentionLayer: 3-19         [32, 12, 883, 64]         16,640
│    │    └─Dropout: 3-20                [32, 12, 883, 64]         --
│    │    └─LayerNorm: 3-21              [32, 12, 883, 64]         128
│    │    └─Sequential: 3-22             [32, 12, 883, 64]         33,088
│    │    └─Dropout: 3-23                [32, 12, 883, 64]         --
│    │    └─LayerNorm: 3-24              [32, 12, 883, 64]         128
│    └─SelfAttentionLayer: 2-5           [32, 12, 883, 64]         --
│    │    └─AttentionLayer: 3-25         [32, 12, 883, 64]         16,640
│    │    └─Dropout: 3-26                [32, 12, 883, 64]         --
│    │    └─LayerNorm: 3-27              [32, 12, 883, 64]         128
│    │    └─Sequential: 3-28             [32, 12, 883, 64]         33,088
│    │    └─Dropout: 3-29                [32, 12, 883, 64]         --
│    │    └─LayerNorm: 3-30              [32, 12, 883, 64]         128
│    └─SelfAttentionLayer: 2-6           [32, 12, 883, 64]         --
│    │    └─AttentionLayer: 3-31         [32, 12, 883, 64]         16,640
│    │    └─Dropout: 3-32                [32, 12, 883, 64]         --
│    │    └─LayerNorm: 3-33              [32, 12, 883, 64]         128
│    │    └─Sequential: 3-34             [32, 12, 883, 64]         33,088
│    │    └─Dropout: 3-35                [32, 12, 883, 64]         --
│    │    └─LayerNorm: 3-36              [32, 12, 883, 64]         128
├─Linear: 1-5                            [32, 64, 883, 12]         156
├─Linear: 1-6                            [32, 12, 883, 1]          65
==========================================================================================
Total params: 300,381
Trainable params: 300,381
Non-trainable params: 0
Total mult-adds (M): 9.61
==========================================================================================
Input size (MB): 2.71
Forward/backward pass size (MB): 11981.45
Params size (MB): 1.20
Estimated Total Size (MB): 11985.36
==========================================================================================

Loss: HuberLoss

2023-09-09 10:39:10.147904 Epoch 1  	Train Loss = 37.27057 Val Loss = 27.96599
2023-09-09 10:46:08.753819 Epoch 2  	Train Loss = 28.71479 Val Loss = 27.49912
2023-09-09 10:53:07.383865 Epoch 3  	Train Loss = 27.18110 Val Loss = 27.75984
2023-09-09 11:00:06.035601 Epoch 4  	Train Loss = 26.36129 Val Loss = 25.20279
2023-09-09 11:07:04.781163 Epoch 5  	Train Loss = 25.94571 Val Loss = 25.19280
2023-09-09 11:14:03.460521 Epoch 6  	Train Loss = 25.83194 Val Loss = 25.48163
2023-09-09 11:21:02.128418 Epoch 7  	Train Loss = 25.40801 Val Loss = 24.50549
2023-09-09 11:28:00.845312 Epoch 8  	Train Loss = 25.35596 Val Loss = 24.30451
2023-09-09 11:34:59.579013 Epoch 9  	Train Loss = 25.10537 Val Loss = 25.00014
2023-09-09 11:41:58.290588 Epoch 10  	Train Loss = 24.96746 Val Loss = 24.23641
2023-09-09 11:48:57.096269 Epoch 11  	Train Loss = 24.10844 Val Loss = 23.43159
2023-09-09 11:55:55.860767 Epoch 12  	Train Loss = 24.02421 Val Loss = 23.35563
2023-09-09 12:02:54.688896 Epoch 13  	Train Loss = 23.98224 Val Loss = 23.35772
2023-09-09 12:14:40.399511 Epoch 14  	Train Loss = 23.93235 Val Loss = 23.33645
2023-09-09 12:26:17.424894 Epoch 15  	Train Loss = 23.88451 Val Loss = 23.18536
2023-09-09 12:40:07.830671 Epoch 16  	Train Loss = 23.83748 Val Loss = 23.26556
2023-09-09 12:53:32.628248 Epoch 17  	Train Loss = 23.79667 Val Loss = 23.18733
2023-09-09 13:06:59.370218 Epoch 18  	Train Loss = 23.74879 Val Loss = 23.12891
2023-09-09 13:20:50.246787 Epoch 19  	Train Loss = 23.72516 Val Loss = 23.12391
2023-09-09 13:34:17.786751 Epoch 20  	Train Loss = 23.67388 Val Loss = 23.01096
2023-09-09 13:47:58.453756 Epoch 21  	Train Loss = 23.64165 Val Loss = 22.94879
2023-09-09 14:01:36.029178 Epoch 22  	Train Loss = 23.60425 Val Loss = 22.97879
2023-09-09 14:10:08.782689 Epoch 23  	Train Loss = 23.57996 Val Loss = 23.00256
2023-09-09 14:17:07.659590 Epoch 24  	Train Loss = 23.54250 Val Loss = 22.92672
2023-09-09 14:24:06.475375 Epoch 25  	Train Loss = 23.51783 Val Loss = 22.86450
2023-09-09 14:31:05.254541 Epoch 26  	Train Loss = 23.48386 Val Loss = 22.95661
2023-09-09 14:38:03.876665 Epoch 27  	Train Loss = 23.46210 Val Loss = 22.84144
2023-09-09 14:45:02.477627 Epoch 28  	Train Loss = 23.44891 Val Loss = 23.00300
2023-09-09 14:52:00.994103 Epoch 29  	Train Loss = 23.41734 Val Loss = 22.91135
2023-09-09 14:58:59.447794 Epoch 30  	Train Loss = 23.40819 Val Loss = 22.78200
2023-09-09 15:05:57.814495 Epoch 31  	Train Loss = 23.37730 Val Loss = 22.81052
2023-09-09 15:12:56.205378 Epoch 32  	Train Loss = 23.35225 Val Loss = 22.77315
2023-09-09 15:19:54.563695 Epoch 33  	Train Loss = 23.33418 Val Loss = 22.76114
2023-09-09 15:26:53.041848 Epoch 34  	Train Loss = 23.32378 Val Loss = 22.85973
2023-09-09 15:33:51.580932 Epoch 35  	Train Loss = 23.29885 Val Loss = 22.68959
2023-09-09 15:40:50.137268 Epoch 36  	Train Loss = 23.27445 Val Loss = 22.69801
2023-09-09 15:47:48.778469 Epoch 37  	Train Loss = 23.27151 Val Loss = 22.80092
2023-09-09 15:54:47.308008 Epoch 38  	Train Loss = 23.24988 Val Loss = 22.72264
2023-09-09 16:01:45.800183 Epoch 39  	Train Loss = 23.22770 Val Loss = 22.67731
2023-09-09 16:08:44.289128 Epoch 40  	Train Loss = 23.21933 Val Loss = 22.67273
2023-09-09 16:15:42.736869 Epoch 41  	Train Loss = 23.09162 Val Loss = 22.56732
2023-09-09 16:22:41.211707 Epoch 42  	Train Loss = 23.08131 Val Loss = 22.56448
2023-09-09 16:29:39.686875 Epoch 43  	Train Loss = 23.07674 Val Loss = 22.57527
2023-09-09 16:36:38.182275 Epoch 44  	Train Loss = 23.07575 Val Loss = 22.56861
2023-09-09 16:43:36.674296 Epoch 45  	Train Loss = 23.07289 Val Loss = 22.56680
2023-09-09 16:50:35.170827 Epoch 46  	Train Loss = 23.06791 Val Loss = 22.57903
2023-09-09 16:57:33.668692 Epoch 47  	Train Loss = 23.06584 Val Loss = 22.56149
2023-09-09 17:04:32.137124 Epoch 48  	Train Loss = 23.06296 Val Loss = 22.55960
2023-09-09 17:11:30.750819 Epoch 49  	Train Loss = 23.06083 Val Loss = 22.56652
2023-09-09 17:18:29.290418 Epoch 50  	Train Loss = 23.05693 Val Loss = 22.56643
2023-09-09 17:25:27.876098 Epoch 51  	Train Loss = 23.05268 Val Loss = 22.54728
2023-09-09 17:32:26.386671 Epoch 52  	Train Loss = 23.05166 Val Loss = 22.54506
2023-09-09 17:39:24.880959 Epoch 53  	Train Loss = 23.05001 Val Loss = 22.54540
2023-09-09 17:46:23.341530 Epoch 54  	Train Loss = 23.04527 Val Loss = 22.53747
2023-09-09 17:53:21.803029 Epoch 55  	Train Loss = 23.04377 Val Loss = 22.53626
2023-09-09 18:00:20.236313 Epoch 56  	Train Loss = 23.04132 Val Loss = 22.52675
2023-09-09 18:07:18.411994 Epoch 57  	Train Loss = 23.03947 Val Loss = 22.53722
2023-09-09 18:14:16.578180 Epoch 58  	Train Loss = 23.03452 Val Loss = 22.55075
2023-09-09 18:21:14.741652 Epoch 59  	Train Loss = 23.03129 Val Loss = 22.52789
2023-09-09 18:28:12.901970 Epoch 60  	Train Loss = 23.03123 Val Loss = 22.52840
2023-09-09 18:35:11.075448 Epoch 61  	Train Loss = 23.02759 Val Loss = 22.53362
2023-09-09 18:42:09.239908 Epoch 62  	Train Loss = 23.02462 Val Loss = 22.52871
2023-09-09 18:49:07.398420 Epoch 63  	Train Loss = 23.02156 Val Loss = 22.53674
2023-09-09 18:56:05.538067 Epoch 64  	Train Loss = 23.01889 Val Loss = 22.51429
2023-09-09 19:03:03.708668 Epoch 65  	Train Loss = 23.01838 Val Loss = 22.52235
2023-09-09 19:10:01.860079 Epoch 66  	Train Loss = 23.01410 Val Loss = 22.52544
2023-09-09 19:17:00.030142 Epoch 67  	Train Loss = 23.01269 Val Loss = 22.51216
2023-09-09 19:23:58.196230 Epoch 68  	Train Loss = 23.01100 Val Loss = 22.51024
2023-09-09 19:30:56.332803 Epoch 69  	Train Loss = 23.00814 Val Loss = 22.52796
2023-09-09 19:37:54.487699 Epoch 70  	Train Loss = 23.00645 Val Loss = 22.50533
2023-09-09 19:44:52.641906 Epoch 71  	Train Loss = 23.00260 Val Loss = 22.51517
2023-09-09 19:51:50.783337 Epoch 72  	Train Loss = 23.00068 Val Loss = 22.49345
2023-09-09 19:58:48.917631 Epoch 73  	Train Loss = 22.99999 Val Loss = 22.50010
2023-09-09 20:05:47.068433 Epoch 74  	Train Loss = 22.99514 Val Loss = 22.52724
2023-09-09 20:12:45.176309 Epoch 75  	Train Loss = 22.99441 Val Loss = 22.51382
2023-09-09 20:19:43.295161 Epoch 76  	Train Loss = 22.99065 Val Loss = 22.51841
2023-09-09 20:26:41.434772 Epoch 77  	Train Loss = 22.98787 Val Loss = 22.49568
2023-09-09 20:33:39.496147 Epoch 78  	Train Loss = 22.98786 Val Loss = 22.49865
2023-09-09 20:40:37.518659 Epoch 79  	Train Loss = 22.98459 Val Loss = 22.50201
2023-09-09 20:47:35.602364 Epoch 80  	Train Loss = 22.98217 Val Loss = 22.50296
2023-09-09 20:54:33.585192 Epoch 81  	Train Loss = 22.98061 Val Loss = 22.48641
2023-09-09 21:01:31.538864 Epoch 82  	Train Loss = 22.97872 Val Loss = 22.50638
2023-09-09 21:08:29.549926 Epoch 83  	Train Loss = 22.97556 Val Loss = 22.51602
2023-09-09 21:15:27.539434 Epoch 84  	Train Loss = 22.97485 Val Loss = 22.48241
2023-09-09 21:22:25.629072 Epoch 85  	Train Loss = 22.97210 Val Loss = 22.48777
2023-09-09 21:29:23.578264 Epoch 86  	Train Loss = 22.96932 Val Loss = 22.47292
2023-09-09 21:36:21.520937 Epoch 87  	Train Loss = 22.96723 Val Loss = 22.50557
2023-09-09 21:43:19.553033 Epoch 88  	Train Loss = 22.96519 Val Loss = 22.47387
2023-09-09 21:50:17.591355 Epoch 89  	Train Loss = 22.96280 Val Loss = 22.47474
2023-09-09 21:57:15.557724 Epoch 90  	Train Loss = 22.96028 Val Loss = 22.47809
2023-09-09 22:04:13.466177 Epoch 91  	Train Loss = 22.95849 Val Loss = 22.50647
2023-09-09 22:11:11.329653 Epoch 92  	Train Loss = 22.95801 Val Loss = 22.48779
2023-09-09 22:18:09.211249 Epoch 93  	Train Loss = 22.95491 Val Loss = 22.48763
2023-09-09 22:25:07.103221 Epoch 94  	Train Loss = 22.95200 Val Loss = 22.46516
2023-09-09 22:32:05.028294 Epoch 95  	Train Loss = 22.95074 Val Loss = 22.47801
2023-09-09 22:39:02.972358 Epoch 96  	Train Loss = 22.94844 Val Loss = 22.47552
2023-09-09 22:46:00.971602 Epoch 97  	Train Loss = 22.94646 Val Loss = 22.46117
2023-09-09 22:52:58.906223 Epoch 98  	Train Loss = 22.94466 Val Loss = 22.46958
2023-09-09 22:59:56.831998 Epoch 99  	Train Loss = 22.94308 Val Loss = 22.47150
2023-09-09 23:06:54.839593 Epoch 100  	Train Loss = 22.94098 Val Loss = 22.47187
2023-09-09 23:13:52.767294 Epoch 101  	Train Loss = 22.93837 Val Loss = 22.45357
2023-09-09 23:20:50.695081 Epoch 102  	Train Loss = 22.93631 Val Loss = 22.46016
2023-09-09 23:27:48.643262 Epoch 103  	Train Loss = 22.93367 Val Loss = 22.49313
2023-09-09 23:34:46.590108 Epoch 104  	Train Loss = 22.93353 Val Loss = 22.45374
2023-09-09 23:41:44.601196 Epoch 105  	Train Loss = 22.92959 Val Loss = 22.46075
2023-09-09 23:48:42.636332 Epoch 106  	Train Loss = 22.92724 Val Loss = 22.45336
2023-09-09 23:55:40.719261 Epoch 107  	Train Loss = 22.92720 Val Loss = 22.46587
2023-09-10 00:02:38.874158 Epoch 108  	Train Loss = 22.92396 Val Loss = 22.47283
2023-09-10 00:09:37.010374 Epoch 109  	Train Loss = 22.91992 Val Loss = 22.46152
2023-09-10 00:16:35.096040 Epoch 110  	Train Loss = 22.91983 Val Loss = 22.44622
2023-09-10 00:23:33.151594 Epoch 111  	Train Loss = 22.91945 Val Loss = 22.45756
2023-09-10 00:30:31.275824 Epoch 112  	Train Loss = 22.91646 Val Loss = 22.44465
2023-09-10 00:37:29.370041 Epoch 113  	Train Loss = 22.91450 Val Loss = 22.44238
2023-09-10 00:44:27.472213 Epoch 114  	Train Loss = 22.91274 Val Loss = 22.43884
2023-09-10 00:51:25.550830 Epoch 115  	Train Loss = 22.90970 Val Loss = 22.44742
2023-09-10 00:58:23.561977 Epoch 116  	Train Loss = 22.90888 Val Loss = 22.45519
2023-09-10 01:05:21.688808 Epoch 117  	Train Loss = 22.90669 Val Loss = 22.43581
2023-09-10 01:12:19.808455 Epoch 118  	Train Loss = 22.90590 Val Loss = 22.45944
2023-09-10 01:19:17.949786 Epoch 119  	Train Loss = 22.90100 Val Loss = 22.43897
2023-09-10 01:26:16.082698 Epoch 120  	Train Loss = 22.90034 Val Loss = 22.43560
2023-09-10 01:33:14.229003 Epoch 121  	Train Loss = 22.89895 Val Loss = 22.45502
2023-09-10 01:40:12.358256 Epoch 122  	Train Loss = 22.89744 Val Loss = 22.44285
2023-09-10 01:47:10.435982 Epoch 123  	Train Loss = 22.89771 Val Loss = 22.43962
2023-09-10 01:54:08.441177 Epoch 124  	Train Loss = 22.89444 Val Loss = 22.43756
2023-09-10 02:01:06.516902 Epoch 125  	Train Loss = 22.89098 Val Loss = 22.44739
2023-09-10 02:08:04.539258 Epoch 126  	Train Loss = 22.88935 Val Loss = 22.42163
2023-09-10 02:15:02.638298 Epoch 127  	Train Loss = 22.88889 Val Loss = 22.42204
2023-09-10 02:22:00.701785 Epoch 128  	Train Loss = 22.88582 Val Loss = 22.42005
2023-09-10 02:28:58.807623 Epoch 129  	Train Loss = 22.88439 Val Loss = 22.43955
2023-09-10 02:35:56.891898 Epoch 130  	Train Loss = 22.88312 Val Loss = 22.42131
2023-09-10 02:42:55.000570 Epoch 131  	Train Loss = 22.87996 Val Loss = 22.42900
2023-09-10 02:49:53.132805 Epoch 132  	Train Loss = 22.87822 Val Loss = 22.41515
2023-09-10 02:56:51.263890 Epoch 133  	Train Loss = 22.87477 Val Loss = 22.44198
2023-09-10 03:03:49.403881 Epoch 134  	Train Loss = 22.87570 Val Loss = 22.41585
2023-09-10 03:10:47.532976 Epoch 135  	Train Loss = 22.87480 Val Loss = 22.42123
2023-09-10 03:17:45.653421 Epoch 136  	Train Loss = 22.87191 Val Loss = 22.42134
2023-09-10 03:24:43.763436 Epoch 137  	Train Loss = 22.87084 Val Loss = 22.42664
2023-09-10 03:31:41.906914 Epoch 138  	Train Loss = 22.86929 Val Loss = 22.42352
2023-09-10 03:38:40.057692 Epoch 139  	Train Loss = 22.86726 Val Loss = 22.40259
2023-09-10 03:45:38.218145 Epoch 140  	Train Loss = 22.86505 Val Loss = 22.41510
2023-09-10 03:52:36.356711 Epoch 141  	Train Loss = 22.86213 Val Loss = 22.40722
2023-09-10 03:59:34.521123 Epoch 142  	Train Loss = 22.86153 Val Loss = 22.40463
2023-09-10 04:06:32.694396 Epoch 143  	Train Loss = 22.85866 Val Loss = 22.40880
2023-09-10 04:13:30.867921 Epoch 144  	Train Loss = 22.85601 Val Loss = 22.40896
2023-09-10 04:20:29.033090 Epoch 145  	Train Loss = 22.85564 Val Loss = 22.43389
2023-09-10 04:27:27.187232 Epoch 146  	Train Loss = 22.85529 Val Loss = 22.41351
2023-09-10 04:34:25.326158 Epoch 147  	Train Loss = 22.85164 Val Loss = 22.42348
2023-09-10 04:41:23.486242 Epoch 148  	Train Loss = 22.84939 Val Loss = 22.42051
2023-09-10 04:48:21.641203 Epoch 149  	Train Loss = 22.84839 Val Loss = 22.39458
2023-09-10 04:55:19.746974 Epoch 150  	Train Loss = 22.84831 Val Loss = 22.40325
2023-09-10 05:02:17.871466 Epoch 151  	Train Loss = 22.84508 Val Loss = 22.39956
2023-09-10 05:09:16.013947 Epoch 152  	Train Loss = 22.84244 Val Loss = 22.39765
2023-09-10 05:16:14.144434 Epoch 153  	Train Loss = 22.84046 Val Loss = 22.39155
2023-09-10 05:23:12.306516 Epoch 154  	Train Loss = 22.83895 Val Loss = 22.39869
2023-09-10 05:30:10.463885 Epoch 155  	Train Loss = 22.83903 Val Loss = 22.38739
2023-09-10 05:37:08.630609 Epoch 156  	Train Loss = 22.83681 Val Loss = 22.39194
2023-09-10 05:44:06.754595 Epoch 157  	Train Loss = 22.83489 Val Loss = 22.38894
2023-09-10 05:51:04.918288 Epoch 158  	Train Loss = 22.83182 Val Loss = 22.38902
2023-09-10 05:58:03.090169 Epoch 159  	Train Loss = 22.83119 Val Loss = 22.37275
2023-09-10 06:05:01.254818 Epoch 160  	Train Loss = 22.82883 Val Loss = 22.38963
2023-09-10 06:11:59.415419 Epoch 161  	Train Loss = 22.82839 Val Loss = 22.38588
2023-09-10 06:18:57.578526 Epoch 162  	Train Loss = 22.82421 Val Loss = 22.38633
2023-09-10 06:25:55.720881 Epoch 163  	Train Loss = 22.82405 Val Loss = 22.38770
2023-09-10 06:32:53.880505 Epoch 164  	Train Loss = 22.82329 Val Loss = 22.38056
2023-09-10 06:39:52.048670 Epoch 165  	Train Loss = 22.82050 Val Loss = 22.38550
2023-09-10 06:46:50.208143 Epoch 166  	Train Loss = 22.82079 Val Loss = 22.38980
2023-09-10 06:53:48.378811 Epoch 167  	Train Loss = 22.81842 Val Loss = 22.39528
2023-09-10 07:00:46.541436 Epoch 168  	Train Loss = 22.81754 Val Loss = 22.36803
2023-09-10 07:07:44.712331 Epoch 169  	Train Loss = 22.81436 Val Loss = 22.37003
2023-09-10 07:14:42.878126 Epoch 170  	Train Loss = 22.81249 Val Loss = 22.37666
2023-09-10 07:21:41.047999 Epoch 171  	Train Loss = 22.81098 Val Loss = 22.36819
2023-09-10 07:28:39.229230 Epoch 172  	Train Loss = 22.80931 Val Loss = 22.37383
2023-09-10 07:35:37.400161 Epoch 173  	Train Loss = 22.80861 Val Loss = 22.38513
2023-09-10 07:42:35.590156 Epoch 174  	Train Loss = 22.80698 Val Loss = 22.37234
2023-09-10 07:49:33.753552 Epoch 175  	Train Loss = 22.80402 Val Loss = 22.36803
2023-09-10 07:56:31.929074 Epoch 176  	Train Loss = 22.80451 Val Loss = 22.37760
2023-09-10 08:03:30.102333 Epoch 177  	Train Loss = 22.80237 Val Loss = 22.38948
2023-09-10 08:10:28.250861 Epoch 178  	Train Loss = 22.80218 Val Loss = 22.36442
2023-09-10 08:17:26.412033 Epoch 179  	Train Loss = 22.79768 Val Loss = 22.35966
2023-09-10 08:24:24.584858 Epoch 180  	Train Loss = 22.79613 Val Loss = 22.36143
2023-09-10 08:31:22.761559 Epoch 181  	Train Loss = 22.79523 Val Loss = 22.37760
2023-09-10 08:38:20.927728 Epoch 182  	Train Loss = 22.79259 Val Loss = 22.35234
2023-09-10 08:45:19.082225 Epoch 183  	Train Loss = 22.79125 Val Loss = 22.35835
2023-09-10 08:52:17.256997 Epoch 184  	Train Loss = 22.78871 Val Loss = 22.35195
2023-09-10 08:59:15.432973 Epoch 185  	Train Loss = 22.78979 Val Loss = 22.36432
2023-09-10 09:06:13.607171 Epoch 186  	Train Loss = 22.78817 Val Loss = 22.36010
2023-09-10 09:13:11.777542 Epoch 187  	Train Loss = 22.78784 Val Loss = 22.36294
2023-09-10 09:20:09.937530 Epoch 188  	Train Loss = 22.78421 Val Loss = 22.35383
2023-09-10 09:27:08.101514 Epoch 189  	Train Loss = 22.78312 Val Loss = 22.35566
2023-09-10 09:34:06.255146 Epoch 190  	Train Loss = 22.78149 Val Loss = 22.36200
2023-09-10 09:41:04.384655 Epoch 191  	Train Loss = 22.78042 Val Loss = 22.34165
2023-09-10 09:48:02.374201 Epoch 192  	Train Loss = 22.77569 Val Loss = 22.34147
2023-09-10 09:55:00.406653 Epoch 193  	Train Loss = 22.77701 Val Loss = 22.34974
2023-09-10 10:01:58.394982 Epoch 194  	Train Loss = 22.77658 Val Loss = 22.34973
2023-09-10 10:08:56.392924 Epoch 195  	Train Loss = 22.77384 Val Loss = 22.34496
2023-09-10 10:15:54.516694 Epoch 196  	Train Loss = 22.77128 Val Loss = 22.34206
2023-09-10 10:22:52.543732 Epoch 197  	Train Loss = 22.76999 Val Loss = 22.34992
2023-09-10 10:29:50.581686 Epoch 198  	Train Loss = 22.76796 Val Loss = 22.34611
2023-09-10 10:36:48.640768 Epoch 199  	Train Loss = 22.76767 Val Loss = 22.34766
2023-09-10 10:43:46.741311 Epoch 200  	Train Loss = 22.76591 Val Loss = 22.34954
Early stopping at epoch: 200
Best at epoch 192:
Train Loss = 22.77569
Train RMSE = 38.21909, MAE = 23.33564, MAPE = 9.85041
Val Loss = 22.34147
Val RMSE = 37.54118, MAE = 22.86767, MAPE = 9.79271
--------- Test ---------
All Steps RMSE = 37.72019, MAE = 23.14386, MAPE = 9.56866
Step 1 RMSE = 28.74627, MAE = 17.96872, MAPE = 7.54667
Step 2 RMSE = 31.07394, MAE = 19.21105, MAPE = 8.01242
Step 3 RMSE = 32.92189, MAE = 20.28458, MAPE = 8.41688
Step 4 RMSE = 34.50154, MAE = 21.22128, MAPE = 8.77574
Step 5 RMSE = 35.85596, MAE = 22.01593, MAPE = 9.08566
Step 6 RMSE = 37.19941, MAE = 22.90554, MAPE = 9.44819
Step 7 RMSE = 38.48516, MAE = 23.75519, MAPE = 9.79307
Step 8 RMSE = 39.65689, MAE = 24.46990, MAPE = 10.08050
Step 9 RMSE = 40.83017, MAE = 25.24820, MAPE = 10.40942
Step 10 RMSE = 41.96333, MAE = 25.98612, MAPE = 10.70613
Step 11 RMSE = 43.19547, MAE = 26.79351, MAPE = 11.04785
Step 12 RMSE = 44.61346, MAE = 27.86268, MAPE = 11.50014
Inference time: 40.12 s
