PEMS07
Trainset:	x-(16921, 12, 883, 2)	y-(16921, 12, 883, 1)
Valset:  	x-(5640, 12, 883, 2)  	y-(5640, 12, 883, 1)
Testset:	x-(5640, 12, 883, 2)	y-(5640, 12, 883, 1)

--------- Attention ---------
{
    "num_nodes": 883,
    "in_steps": 12,
    "out_steps": 12,
    "train_size": 0.7,
    "val_size": 0.1,
    "time_of_day": true,
    "lr": 0.001,
    "milestones": [
        10,
        40
    ],
    "batch_size": 64,
    "max_epochs": 200,
    "use_cl": false,
    "model_args": {
        "num_nodes": 883,
        "in_steps": 12,
        "out_steps": 12,
        "input_dim": 1,
        "output_dim": 1,
        "model_dim": 64,
        "feed_forward_dim": 256,
        "num_heads": 4,
        "num_layers": 3
    }
}
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Attention                                [64, 12, 883, 1]          --
├─Linear: 1-1                            [64, 12, 883, 64]         128
├─Linear: 1-2                            [64, 12, 883, 64]         128
├─ModuleList: 1-3                        --                        --
│    └─SelfAttentionLayer: 2-1           [64, 12, 883, 64]         --
│    │    └─AttentionLayer: 3-1          [64, 883, 12, 64]         16,640
│    │    └─Dropout: 3-2                 [64, 883, 12, 64]         --
│    │    └─LayerNorm: 3-3               [64, 883, 12, 64]         128
│    │    └─Sequential: 3-4              [64, 883, 12, 64]         33,088
│    │    └─Dropout: 3-5                 [64, 883, 12, 64]         --
│    │    └─LayerNorm: 3-6               [64, 883, 12, 64]         128
│    └─SelfAttentionLayer: 2-2           [64, 12, 883, 64]         --
│    │    └─AttentionLayer: 3-7          [64, 883, 12, 64]         16,640
│    │    └─Dropout: 3-8                 [64, 883, 12, 64]         --
│    │    └─LayerNorm: 3-9               [64, 883, 12, 64]         128
│    │    └─Sequential: 3-10             [64, 883, 12, 64]         33,088
│    │    └─Dropout: 3-11                [64, 883, 12, 64]         --
│    │    └─LayerNorm: 3-12              [64, 883, 12, 64]         128
│    └─SelfAttentionLayer: 2-3           [64, 12, 883, 64]         --
│    │    └─AttentionLayer: 3-13         [64, 883, 12, 64]         16,640
│    │    └─Dropout: 3-14                [64, 883, 12, 64]         --
│    │    └─LayerNorm: 3-15              [64, 883, 12, 64]         128
│    │    └─Sequential: 3-16             [64, 883, 12, 64]         33,088
│    │    └─Dropout: 3-17                [64, 883, 12, 64]         --
│    │    └─LayerNorm: 3-18              [64, 883, 12, 64]         128
├─Linear: 1-4                            [64, 64, 883, 12]         156
├─Linear: 1-5                            [64, 12, 883, 1]          65
==========================================================================================
Total params: 150,429
Trainable params: 150,429
Non-trainable params: 0
Total mult-adds (M): 9.63
==========================================================================================
Input size (MB): 5.43
Forward/backward pass size (MB): 12504.98
Params size (MB): 0.60
Estimated Total Size (MB): 12511.00
==========================================================================================

Loss: HuberLoss

2023-05-06 18:18:35.299845 Epoch 1  	Train Loss = 43.11586 Val Loss = 30.31892
2023-05-06 18:19:52.362454 Epoch 2  	Train Loss = 29.99543 Val Loss = 28.03412
2023-05-06 18:21:09.399914 Epoch 3  	Train Loss = 29.23851 Val Loss = 27.63544
2023-05-06 18:22:26.585163 Epoch 4  	Train Loss = 28.40588 Val Loss = 26.56997
2023-05-06 18:23:43.745930 Epoch 5  	Train Loss = 27.81017 Val Loss = 28.12610
2023-05-06 18:25:00.756777 Epoch 6  	Train Loss = 27.30654 Val Loss = 26.50893
2023-05-06 18:26:17.737817 Epoch 7  	Train Loss = 26.82478 Val Loss = 26.00100
2023-05-06 18:27:34.682438 Epoch 8  	Train Loss = 26.58563 Val Loss = 26.03182
2023-05-06 18:28:51.613233 Epoch 9  	Train Loss = 26.47461 Val Loss = 25.50068
2023-05-06 18:30:08.542447 Epoch 10  	Train Loss = 26.34481 Val Loss = 25.34617
2023-05-06 18:31:25.567526 Epoch 11  	Train Loss = 25.66571 Val Loss = 24.83279
2023-05-06 18:32:42.488789 Epoch 12  	Train Loss = 25.63380 Val Loss = 24.83360
2023-05-06 18:33:59.435017 Epoch 13  	Train Loss = 25.61319 Val Loss = 24.75892
2023-05-06 18:35:16.353903 Epoch 14  	Train Loss = 25.58283 Val Loss = 24.75944
2023-05-06 18:36:33.404896 Epoch 15  	Train Loss = 25.57220 Val Loss = 24.80053
2023-05-06 18:37:50.436968 Epoch 16  	Train Loss = 25.55866 Val Loss = 24.77494
2023-05-06 18:39:07.450539 Epoch 17  	Train Loss = 25.54082 Val Loss = 24.76415
2023-05-06 18:40:24.472388 Epoch 18  	Train Loss = 25.53271 Val Loss = 24.75836
2023-05-06 18:41:41.453165 Epoch 19  	Train Loss = 25.50210 Val Loss = 24.78095
2023-05-06 18:42:58.407562 Epoch 20  	Train Loss = 25.49170 Val Loss = 24.71843
2023-05-06 18:44:15.455008 Epoch 21  	Train Loss = 25.46520 Val Loss = 24.78734
2023-05-06 18:45:32.454951 Epoch 22  	Train Loss = 25.45026 Val Loss = 24.59132
2023-05-06 18:46:49.419862 Epoch 23  	Train Loss = 25.43657 Val Loss = 24.65682
2023-05-06 18:48:06.369939 Epoch 24  	Train Loss = 25.44664 Val Loss = 24.61778
2023-05-06 18:49:23.303263 Epoch 25  	Train Loss = 25.40331 Val Loss = 24.67693
2023-05-06 18:50:40.449329 Epoch 26  	Train Loss = 25.38788 Val Loss = 24.58009
2023-05-06 18:51:57.422488 Epoch 27  	Train Loss = 25.38644 Val Loss = 24.55300
2023-05-06 18:53:14.574061 Epoch 28  	Train Loss = 25.37695 Val Loss = 24.54190
2023-05-06 18:54:31.618578 Epoch 29  	Train Loss = 25.36123 Val Loss = 24.49407
2023-05-06 18:55:48.700535 Epoch 30  	Train Loss = 25.34613 Val Loss = 24.74167
2023-05-06 18:57:05.593204 Epoch 31  	Train Loss = 25.32847 Val Loss = 24.56849
2023-05-06 18:58:22.515582 Epoch 32  	Train Loss = 25.33123 Val Loss = 24.48348
2023-05-06 18:59:39.408142 Epoch 33  	Train Loss = 25.34028 Val Loss = 24.52240
2023-05-06 19:00:56.326661 Epoch 34  	Train Loss = 25.29044 Val Loss = 24.60860
2023-05-06 19:02:13.266764 Epoch 35  	Train Loss = 25.27446 Val Loss = 24.44302
2023-05-06 19:03:30.214055 Epoch 36  	Train Loss = 25.27249 Val Loss = 24.46062
2023-05-06 19:04:47.157073 Epoch 37  	Train Loss = 25.26396 Val Loss = 24.60463
2023-05-06 19:06:04.154972 Epoch 38  	Train Loss = 25.25533 Val Loss = 24.42600
2023-05-06 19:07:21.163278 Epoch 39  	Train Loss = 25.27077 Val Loss = 24.63570
2023-05-06 19:08:38.150160 Epoch 40  	Train Loss = 25.23510 Val Loss = 24.37595
2023-05-06 19:09:55.125467 Epoch 41  	Train Loss = 25.12747 Val Loss = 24.33780
2023-05-06 19:11:12.241539 Epoch 42  	Train Loss = 25.11036 Val Loss = 24.33897
2023-05-06 19:12:29.216094 Epoch 43  	Train Loss = 25.11619 Val Loss = 24.33767
2023-05-06 19:13:46.154322 Epoch 44  	Train Loss = 25.10871 Val Loss = 24.34347
2023-05-06 19:15:03.084902 Epoch 45  	Train Loss = 25.10789 Val Loss = 24.35255
2023-05-06 19:16:20.001729 Epoch 46  	Train Loss = 25.11045 Val Loss = 24.32788
2023-05-06 19:17:36.937778 Epoch 47  	Train Loss = 25.10375 Val Loss = 24.33461
2023-05-06 19:18:53.958661 Epoch 48  	Train Loss = 25.11178 Val Loss = 24.32482
2023-05-06 19:20:11.181609 Epoch 49  	Train Loss = 25.10775 Val Loss = 24.30980
2023-05-06 19:21:28.221078 Epoch 50  	Train Loss = 25.10180 Val Loss = 24.31754
2023-05-06 19:22:45.353682 Epoch 51  	Train Loss = 25.10005 Val Loss = 24.35450
2023-05-06 19:24:02.279200 Epoch 52  	Train Loss = 25.09937 Val Loss = 24.31889
2023-05-06 19:25:19.367661 Epoch 53  	Train Loss = 25.09280 Val Loss = 24.30763
2023-05-06 19:26:36.223935 Epoch 54  	Train Loss = 25.09831 Val Loss = 24.31564
2023-05-06 19:27:53.209948 Epoch 55  	Train Loss = 25.08942 Val Loss = 24.30685
2023-05-06 19:29:10.068124 Epoch 56  	Train Loss = 25.09496 Val Loss = 24.30908
2023-05-06 19:30:27.121413 Epoch 57  	Train Loss = 25.09256 Val Loss = 24.31958
2023-05-06 19:31:44.204359 Epoch 58  	Train Loss = 25.08985 Val Loss = 24.29646
2023-05-06 19:33:01.269167 Epoch 59  	Train Loss = 25.08588 Val Loss = 24.32446
2023-05-06 19:34:18.327840 Epoch 60  	Train Loss = 25.08746 Val Loss = 24.29555
2023-05-06 19:35:35.563819 Epoch 61  	Train Loss = 25.08152 Val Loss = 24.30660
2023-05-06 19:36:52.706063 Epoch 62  	Train Loss = 25.07873 Val Loss = 24.30921
2023-05-06 19:38:09.793688 Epoch 63  	Train Loss = 25.06708 Val Loss = 24.31400
2023-05-06 19:39:26.975902 Epoch 64  	Train Loss = 25.06819 Val Loss = 24.31220
2023-05-06 19:40:44.073888 Epoch 65  	Train Loss = 25.07699 Val Loss = 24.33159
2023-05-06 19:42:01.193987 Epoch 66  	Train Loss = 25.07334 Val Loss = 24.29840
2023-05-06 19:43:18.234922 Epoch 67  	Train Loss = 25.06956 Val Loss = 24.31337
2023-05-06 19:44:35.289177 Epoch 68  	Train Loss = 25.07113 Val Loss = 24.30862
2023-05-06 19:45:52.418479 Epoch 69  	Train Loss = 25.06391 Val Loss = 24.28663
2023-05-06 19:47:09.563232 Epoch 70  	Train Loss = 25.05861 Val Loss = 24.30212
2023-05-06 19:48:26.751713 Epoch 71  	Train Loss = 25.06915 Val Loss = 24.28756
2023-05-06 19:49:43.902255 Epoch 72  	Train Loss = 25.05899 Val Loss = 24.28073
2023-05-06 19:51:01.117670 Epoch 73  	Train Loss = 25.06316 Val Loss = 24.27865
2023-05-06 19:52:18.299562 Epoch 74  	Train Loss = 25.05340 Val Loss = 24.29066
2023-05-06 19:53:35.403378 Epoch 75  	Train Loss = 25.05709 Val Loss = 24.29153
2023-05-06 19:54:52.559022 Epoch 76  	Train Loss = 25.05910 Val Loss = 24.28737
2023-05-06 19:56:09.626285 Epoch 77  	Train Loss = 25.05221 Val Loss = 24.26720
2023-05-06 19:57:26.790161 Epoch 78  	Train Loss = 25.04759 Val Loss = 24.27447
2023-05-06 19:58:43.855498 Epoch 79  	Train Loss = 25.04352 Val Loss = 24.29248
2023-05-06 20:00:00.921833 Epoch 80  	Train Loss = 25.05368 Val Loss = 24.26679
2023-05-06 20:01:18.110109 Epoch 81  	Train Loss = 25.04745 Val Loss = 24.28960
2023-05-06 20:02:35.293255 Epoch 82  	Train Loss = 25.04629 Val Loss = 24.25466
2023-05-06 20:03:52.514651 Epoch 83  	Train Loss = 25.04459 Val Loss = 24.26172
2023-05-06 20:05:09.769864 Epoch 84  	Train Loss = 25.05127 Val Loss = 24.26566
2023-05-06 20:06:26.942915 Epoch 85  	Train Loss = 25.04772 Val Loss = 24.27790
2023-05-06 20:07:44.042806 Epoch 86  	Train Loss = 25.04451 Val Loss = 24.25018
2023-05-06 20:09:01.052011 Epoch 87  	Train Loss = 25.03286 Val Loss = 24.27514
2023-05-06 20:10:18.023652 Epoch 88  	Train Loss = 25.03986 Val Loss = 24.26562
2023-05-06 20:11:34.963902 Epoch 89  	Train Loss = 25.02729 Val Loss = 24.28087
2023-05-06 20:12:52.053025 Epoch 90  	Train Loss = 25.03381 Val Loss = 24.27721
2023-05-06 20:14:09.001053 Epoch 91  	Train Loss = 25.02152 Val Loss = 24.27954
2023-05-06 20:15:26.028485 Epoch 92  	Train Loss = 25.02583 Val Loss = 24.25487
2023-05-06 20:16:43.099195 Epoch 93  	Train Loss = 25.02607 Val Loss = 24.26155
2023-05-06 20:18:00.184470 Epoch 94  	Train Loss = 25.02824 Val Loss = 24.23847
2023-05-06 20:19:17.298296 Epoch 95  	Train Loss = 25.02177 Val Loss = 24.25195
2023-05-06 20:20:34.411135 Epoch 96  	Train Loss = 25.02480 Val Loss = 24.25662
2023-05-06 20:21:51.450708 Epoch 97  	Train Loss = 25.01935 Val Loss = 24.25620
2023-05-06 20:23:08.469547 Epoch 98  	Train Loss = 25.01852 Val Loss = 24.25992
2023-05-06 20:24:25.422917 Epoch 99  	Train Loss = 25.01998 Val Loss = 24.22793
2023-05-06 20:25:42.402020 Epoch 100  	Train Loss = 25.01960 Val Loss = 24.24722
2023-05-06 20:26:59.446699 Epoch 101  	Train Loss = 25.01383 Val Loss = 24.27211
2023-05-06 20:28:16.488588 Epoch 102  	Train Loss = 25.01262 Val Loss = 24.27139
2023-05-06 20:29:33.495475 Epoch 103  	Train Loss = 25.01584 Val Loss = 24.23366
2023-05-06 20:30:50.567665 Epoch 104  	Train Loss = 25.00872 Val Loss = 24.25764
2023-05-06 20:32:07.571390 Epoch 105  	Train Loss = 25.01244 Val Loss = 24.23488
2023-05-06 20:33:24.694442 Epoch 106  	Train Loss = 25.00425 Val Loss = 24.24492
2023-05-06 20:34:41.886131 Epoch 107  	Train Loss = 25.01113 Val Loss = 24.25607
2023-05-06 20:35:58.971943 Epoch 108  	Train Loss = 25.01246 Val Loss = 24.24688
2023-05-06 20:37:16.029967 Epoch 109  	Train Loss = 24.99918 Val Loss = 24.22303
2023-05-06 20:38:33.010531 Epoch 110  	Train Loss = 25.00279 Val Loss = 24.22472
2023-05-06 20:39:49.929452 Epoch 111  	Train Loss = 25.00216 Val Loss = 24.23533
2023-05-06 20:41:06.889010 Epoch 112  	Train Loss = 24.99798 Val Loss = 24.27548
2023-05-06 20:42:23.792620 Epoch 113  	Train Loss = 24.99689 Val Loss = 24.22033
2023-05-06 20:43:40.727384 Epoch 114  	Train Loss = 24.99029 Val Loss = 24.23769
2023-05-06 20:44:57.883978 Epoch 115  	Train Loss = 25.00648 Val Loss = 24.23906
2023-05-06 20:46:14.903714 Epoch 116  	Train Loss = 24.99359 Val Loss = 24.21721
2023-05-06 20:47:31.998795 Epoch 117  	Train Loss = 24.98982 Val Loss = 24.24379
2023-05-06 20:48:49.162861 Epoch 118  	Train Loss = 24.98820 Val Loss = 24.22979
2023-05-06 20:50:06.338173 Epoch 119  	Train Loss = 24.99433 Val Loss = 24.22786
2023-05-06 20:51:23.424286 Epoch 120  	Train Loss = 24.98493 Val Loss = 24.22139
2023-05-06 20:52:40.348464 Epoch 121  	Train Loss = 24.98367 Val Loss = 24.23995
2023-05-06 20:53:57.322860 Epoch 122  	Train Loss = 24.98490 Val Loss = 24.22158
2023-05-06 20:55:14.337720 Epoch 123  	Train Loss = 24.98786 Val Loss = 24.20413
2023-05-06 20:56:31.309723 Epoch 124  	Train Loss = 24.98358 Val Loss = 24.21856
2023-05-06 20:57:48.351235 Epoch 125  	Train Loss = 24.99106 Val Loss = 24.22454
2023-05-06 20:59:05.307382 Epoch 126  	Train Loss = 24.97633 Val Loss = 24.21167
2023-05-06 21:00:22.337161 Epoch 127  	Train Loss = 24.97855 Val Loss = 24.20843
2023-05-06 21:01:39.275271 Epoch 128  	Train Loss = 24.97997 Val Loss = 24.20877
2023-05-06 21:02:56.270226 Epoch 129  	Train Loss = 24.97637 Val Loss = 24.20768
2023-05-06 21:04:13.317390 Epoch 130  	Train Loss = 24.97306 Val Loss = 24.22529
2023-05-06 21:05:30.259688 Epoch 131  	Train Loss = 24.97837 Val Loss = 24.21677
2023-05-06 21:06:47.244945 Epoch 132  	Train Loss = 24.97454 Val Loss = 24.20591
2023-05-06 21:08:04.194321 Epoch 133  	Train Loss = 24.97575 Val Loss = 24.23066
Early stopping at epoch: 133
Best at epoch 123:
Train Loss = 24.98786
Train RMSE = 40.70700, MAE = 25.56681, MAPE = 10.89387
Val Loss = 24.20413
Val RMSE = 39.45745, MAE = 24.69844, MAPE = 10.69900
--------- Test ---------
All Steps RMSE = 39.64798, MAE = 25.05754, MAPE = 10.50115
Step 1 RMSE = 29.68930, MAE = 18.89334, MAPE = 7.99297
Step 2 RMSE = 32.18618, MAE = 20.41500, MAPE = 8.53883
Step 3 RMSE = 34.32571, MAE = 21.79703, MAPE = 9.15536
Step 4 RMSE = 35.98322, MAE = 22.84025, MAPE = 9.56977
Step 5 RMSE = 37.51263, MAE = 23.79124, MAPE = 9.99984
Step 6 RMSE = 39.03483, MAE = 24.84007, MAPE = 10.42556
Step 7 RMSE = 40.44777, MAE = 25.76487, MAPE = 10.79613
Step 8 RMSE = 41.81093, MAE = 26.69294, MAPE = 11.16137
Step 9 RMSE = 42.98894, MAE = 27.44966, MAPE = 11.48646
Step 10 RMSE = 44.24587, MAE = 28.25259, MAPE = 11.80892
Step 11 RMSE = 45.74347, MAE = 29.30347, MAPE = 12.24673
Step 12 RMSE = 47.53461, MAE = 30.64636, MAPE = 12.83021
Inference time: 7.27 s
