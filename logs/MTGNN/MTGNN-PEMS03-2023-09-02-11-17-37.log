PEMS03
Trainset:	x-(15711, 12, 358, 2)	y-(15711, 12, 358, 1)
Valset:  	x-(5237, 12, 358, 2)  	y-(5237, 12, 358, 1)
Testset:	x-(5237, 12, 358, 2)	y-(5237, 12, 358, 1)

--------- MTGNN ---------
{
    "num_nodes": 358,
    "in_steps": 12,
    "out_steps": 12,
    "time_of_day": true,
    "train_size": 0.6,
    "val_size": 0.2,
    "lr": 0.001,
    "weight_decay": 0.0001,
    "milestones": [
        115
    ],
    "clip_grad": 5,
    "batch_size": 64,
    "max_epochs": 200,
    "use_cl": true,
    "cl_step_size": 2500,
    "pass_device": true,
    "model_args": {
        "num_nodes": 358,
        "in_dim": 2,
        "seq_length": 12,
        "out_dim": 12,
        "device": "cuda:0",
        "gcn_true": true,
        "buildA_true": true,
        "gcn_depth": 2,
        "predefined_A": null,
        "static_feat": null,
        "dropout": 0.3,
        "subgraph_size": 20,
        "node_dim": 40,
        "dilation_exponential": 1,
        "conv_channels": 32,
        "residual_channels": 32,
        "skip_channels": 64,
        "end_channels": 128,
        "layers": 3,
        "propalpha": 0.05,
        "tanhalpha": 3,
        "layer_norm_affline": true
    }
}
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
MTGNN                                    [64, 12, 358, 1]          3,168
├─graph_constructor: 1-1                 [358, 358]                --
│    └─Embedding: 2-1                    [358, 40]                 14,320
│    └─Embedding: 2-2                    [358, 40]                 14,320
│    └─Linear: 2-3                       [358, 40]                 1,640
│    └─Linear: 2-4                       [358, 40]                 1,640
├─Conv2d: 1-2                            [64, 32, 358, 19]         96
├─Conv2d: 1-3                            [64, 64, 358, 1]          2,496
├─ModuleList: 1-16                       --                        (recursive)
│    └─dilated_inception: 2-5            [64, 32, 358, 13]         --
│    │    └─ModuleList: 3-1              --                        4,640
├─ModuleList: 1-17                       --                        (recursive)
│    └─dilated_inception: 2-6            [64, 32, 358, 13]         --
│    │    └─ModuleList: 3-2              --                        4,640
├─ModuleList: 1-18                       --                        (recursive)
│    └─Conv2d: 2-7                       [64, 64, 358, 1]          26,688
├─ModuleList: 1-19                       --                        (recursive)
│    └─mixprop: 2-8                      [64, 32, 358, 13]         --
│    │    └─nconv: 3-3                   [64, 32, 358, 13]         --
│    │    └─nconv: 3-4                   [64, 32, 358, 13]         --
│    │    └─linear: 3-5                  [64, 32, 358, 13]         3,104
├─ModuleList: 1-20                       --                        (recursive)
│    └─mixprop: 2-9                      [64, 32, 358, 13]         --
│    │    └─nconv: 3-6                   [64, 32, 358, 13]         --
│    │    └─nconv: 3-7                   [64, 32, 358, 13]         --
│    │    └─linear: 3-8                  [64, 32, 358, 13]         3,104
├─ModuleList: 1-21                       --                        (recursive)
│    └─LayerNorm: 2-10                   [64, 32, 358, 13]         297,856
├─ModuleList: 1-16                       --                        (recursive)
│    └─dilated_inception: 2-11           [64, 32, 358, 7]          --
│    │    └─ModuleList: 3-9              --                        4,640
├─ModuleList: 1-17                       --                        (recursive)
│    └─dilated_inception: 2-12           [64, 32, 358, 7]          --
│    │    └─ModuleList: 3-10             --                        4,640
├─ModuleList: 1-18                       --                        (recursive)
│    └─Conv2d: 2-13                      [64, 64, 358, 1]          14,400
├─ModuleList: 1-19                       --                        (recursive)
│    └─mixprop: 2-14                     [64, 32, 358, 7]          --
│    │    └─nconv: 3-11                  [64, 32, 358, 7]          --
│    │    └─nconv: 3-12                  [64, 32, 358, 7]          --
│    │    └─linear: 3-13                 [64, 32, 358, 7]          3,104
├─ModuleList: 1-20                       --                        (recursive)
│    └─mixprop: 2-15                     [64, 32, 358, 7]          --
│    │    └─nconv: 3-14                  [64, 32, 358, 7]          --
│    │    └─nconv: 3-15                  [64, 32, 358, 7]          --
│    │    └─linear: 3-16                 [64, 32, 358, 7]          3,104
├─ModuleList: 1-21                       --                        (recursive)
│    └─LayerNorm: 2-16                   [64, 32, 358, 7]          160,384
├─ModuleList: 1-16                       --                        (recursive)
│    └─dilated_inception: 2-17           [64, 32, 358, 1]          --
│    │    └─ModuleList: 3-17             --                        4,640
├─ModuleList: 1-17                       --                        (recursive)
│    └─dilated_inception: 2-18           [64, 32, 358, 1]          --
│    │    └─ModuleList: 3-18             --                        4,640
├─ModuleList: 1-18                       --                        (recursive)
│    └─Conv2d: 2-19                      [64, 64, 358, 1]          2,112
├─ModuleList: 1-19                       --                        (recursive)
│    └─mixprop: 2-20                     [64, 32, 358, 1]          --
│    │    └─nconv: 3-19                  [64, 32, 358, 1]          --
│    │    └─nconv: 3-20                  [64, 32, 358, 1]          --
│    │    └─linear: 3-21                 [64, 32, 358, 1]          3,104
├─ModuleList: 1-20                       --                        (recursive)
│    └─mixprop: 2-21                     [64, 32, 358, 1]          --
│    │    └─nconv: 3-22                  [64, 32, 358, 1]          --
│    │    └─nconv: 3-23                  [64, 32, 358, 1]          --
│    │    └─linear: 3-24                 [64, 32, 358, 1]          3,104
├─ModuleList: 1-21                       --                        (recursive)
│    └─LayerNorm: 2-22                   [64, 32, 358, 1]          22,912
├─Conv2d: 1-22                           [64, 64, 358, 1]          2,112
├─Conv2d: 1-23                           [64, 128, 358, 1]         8,320
├─Conv2d: 1-24                           [64, 12, 358, 1]          1,548
==========================================================================================
Total params: 620,476
Trainable params: 620,476
Non-trainable params: 0
Total mult-adds (G): 9.85
==========================================================================================
Input size (MB): 2.20
Forward/backward pass size (MB): 900.08
Params size (MB): 2.47
Estimated Total Size (MB): 904.74
==========================================================================================

Loss: HuberLoss

CL target length = 1
2023-09-02 11:18:14.885778 Epoch 1  	Train Loss = 17.26009 Val Loss = 111.88627
2023-09-02 11:18:49.381962 Epoch 2  	Train Loss = 13.67541 Val Loss = 111.78835
2023-09-02 11:19:24.322520 Epoch 3  	Train Loss = 13.53632 Val Loss = 111.74295
2023-09-02 11:19:59.170330 Epoch 4  	Train Loss = 13.37945 Val Loss = 111.76940
2023-09-02 11:20:34.190178 Epoch 5  	Train Loss = 13.29289 Val Loss = 111.79371
2023-09-02 11:21:09.318964 Epoch 6  	Train Loss = 13.13623 Val Loss = 111.72410
2023-09-02 11:21:44.507368 Epoch 7  	Train Loss = 13.00429 Val Loss = 111.72795
2023-09-02 11:22:19.708229 Epoch 8  	Train Loss = 12.92183 Val Loss = 111.73727
2023-09-02 11:22:55.081555 Epoch 9  	Train Loss = 12.87859 Val Loss = 111.74456
2023-09-02 11:23:30.475482 Epoch 10  	Train Loss = 12.75652 Val Loss = 111.75143
CL target length = 2
2023-09-02 11:24:05.834389 Epoch 11  	Train Loss = 14.84221 Val Loss = 102.75724
2023-09-02 11:24:41.357016 Epoch 12  	Train Loss = 13.16799 Val Loss = 102.73088
2023-09-02 11:25:16.868264 Epoch 13  	Train Loss = 13.05197 Val Loss = 102.77297
2023-09-02 11:25:52.423558 Epoch 14  	Train Loss = 12.92388 Val Loss = 102.71121
2023-09-02 11:26:27.987760 Epoch 15  	Train Loss = 12.85967 Val Loss = 102.65913
2023-09-02 11:27:03.644586 Epoch 16  	Train Loss = 12.77363 Val Loss = 102.71878
2023-09-02 11:27:39.258202 Epoch 17  	Train Loss = 12.72444 Val Loss = 102.68221
2023-09-02 11:28:14.812371 Epoch 18  	Train Loss = 12.71497 Val Loss = 102.64796
2023-09-02 11:28:50.435765 Epoch 19  	Train Loss = 12.68510 Val Loss = 102.66157
2023-09-02 11:29:25.902384 Epoch 20  	Train Loss = 12.60015 Val Loss = 102.73258
CL target length = 3
2023-09-02 11:30:01.398273 Epoch 21  	Train Loss = 13.96103 Val Loss = 93.72590
2023-09-02 11:30:36.899900 Epoch 22  	Train Loss = 12.98827 Val Loss = 93.78463
2023-09-02 11:31:12.484807 Epoch 23  	Train Loss = 12.94389 Val Loss = 93.74068
2023-09-02 11:31:48.094634 Epoch 24  	Train Loss = 12.93022 Val Loss = 93.76923
2023-09-02 11:32:23.843091 Epoch 25  	Train Loss = 12.91315 Val Loss = 93.68155
2023-09-02 11:32:59.694959 Epoch 26  	Train Loss = 12.76599 Val Loss = 93.68147
2023-09-02 11:33:35.223817 Epoch 27  	Train Loss = 12.72989 Val Loss = 93.67394
2023-09-02 11:34:10.773647 Epoch 28  	Train Loss = 12.69028 Val Loss = 93.64925
2023-09-02 11:34:46.267079 Epoch 29  	Train Loss = 12.65447 Val Loss = 93.64059
2023-09-02 11:35:21.780644 Epoch 30  	Train Loss = 12.63644 Val Loss = 93.67598
CL target length = 4
2023-09-02 11:35:57.249847 Epoch 31  	Train Loss = 13.58483 Val Loss = 84.81039
2023-09-02 11:36:32.792150 Epoch 32  	Train Loss = 12.91455 Val Loss = 84.73557
2023-09-02 11:37:08.451581 Epoch 33  	Train Loss = 12.86928 Val Loss = 84.73343
2023-09-02 11:37:44.075661 Epoch 34  	Train Loss = 12.86787 Val Loss = 84.80531
2023-09-02 11:38:19.794678 Epoch 35  	Train Loss = 12.88750 Val Loss = 84.68904
2023-09-02 11:38:55.487111 Epoch 36  	Train Loss = 12.80333 Val Loss = 84.71071
2023-09-02 11:39:31.241216 Epoch 37  	Train Loss = 12.76980 Val Loss = 84.68998
2023-09-02 11:40:07.032125 Epoch 38  	Train Loss = 12.73587 Val Loss = 84.70880
2023-09-02 11:40:42.767742 Epoch 39  	Train Loss = 12.73852 Val Loss = 84.69153
2023-09-02 11:41:18.570836 Epoch 40  	Train Loss = 12.69230 Val Loss = 84.69186
CL target length = 5
2023-09-02 11:41:54.172893 Epoch 41  	Train Loss = 13.48241 Val Loss = 75.92465
2023-09-02 11:42:29.699731 Epoch 42  	Train Loss = 12.97099 Val Loss = 75.76600
2023-09-02 11:43:05.356345 Epoch 43  	Train Loss = 12.90062 Val Loss = 75.86115
2023-09-02 11:43:40.966686 Epoch 44  	Train Loss = 12.90908 Val Loss = 75.84889
2023-09-02 11:44:16.511722 Epoch 45  	Train Loss = 12.85802 Val Loss = 75.75683
2023-09-02 11:44:52.175662 Epoch 46  	Train Loss = 12.84200 Val Loss = 75.73088
2023-09-02 11:45:27.734817 Epoch 47  	Train Loss = 12.84197 Val Loss = 75.78638
2023-09-02 11:46:03.376420 Epoch 48  	Train Loss = 12.78602 Val Loss = 75.70043
2023-09-02 11:46:39.059688 Epoch 49  	Train Loss = 12.78071 Val Loss = 75.71722
2023-09-02 11:47:14.618513 Epoch 50  	Train Loss = 12.73883 Val Loss = 75.70078
CL target length = 6
2023-09-02 11:47:50.228166 Epoch 51  	Train Loss = 13.33870 Val Loss = 66.91709
2023-09-02 11:48:25.839165 Epoch 52  	Train Loss = 12.96543 Val Loss = 66.87178
2023-09-02 11:49:01.373544 Epoch 53  	Train Loss = 12.94585 Val Loss = 66.82111
2023-09-02 11:49:36.877729 Epoch 54  	Train Loss = 12.90811 Val Loss = 66.83028
2023-09-02 11:50:12.345274 Epoch 55  	Train Loss = 12.89058 Val Loss = 66.87543
2023-09-02 11:50:48.112467 Epoch 56  	Train Loss = 12.86137 Val Loss = 66.84221
2023-09-02 11:51:24.544292 Epoch 57  	Train Loss = 12.84005 Val Loss = 66.96725
2023-09-02 11:52:00.140902 Epoch 58  	Train Loss = 12.84883 Val Loss = 66.78002
2023-09-02 11:52:35.608453 Epoch 59  	Train Loss = 12.81742 Val Loss = 66.85003
2023-09-02 11:53:11.123261 Epoch 60  	Train Loss = 12.80134 Val Loss = 66.83345
CL target length = 7
2023-09-02 11:53:46.718645 Epoch 61  	Train Loss = 13.08723 Val Loss = 62.71808
2023-09-02 11:54:22.352419 Epoch 62  	Train Loss = 13.17582 Val Loss = 57.95389
2023-09-02 11:54:57.865895 Epoch 63  	Train Loss = 12.95633 Val Loss = 57.99440
2023-09-02 11:55:33.433721 Epoch 64  	Train Loss = 12.96682 Val Loss = 58.02081
2023-09-02 11:56:08.939716 Epoch 65  	Train Loss = 12.92604 Val Loss = 57.95445
2023-09-02 11:56:44.370350 Epoch 66  	Train Loss = 12.89320 Val Loss = 57.96492
2023-09-02 11:57:19.914963 Epoch 67  	Train Loss = 12.91377 Val Loss = 57.83392
2023-09-02 11:57:55.365453 Epoch 68  	Train Loss = 12.90967 Val Loss = 57.91903
2023-09-02 11:58:30.762108 Epoch 69  	Train Loss = 12.86994 Val Loss = 57.84078
2023-09-02 11:59:06.202829 Epoch 70  	Train Loss = 12.86002 Val Loss = 57.83724
2023-09-02 11:59:41.602782 Epoch 71  	Train Loss = 12.83373 Val Loss = 57.89637
CL target length = 8
2023-09-02 12:00:17.004746 Epoch 72  	Train Loss = 13.43795 Val Loss = 49.17687
2023-09-02 12:00:52.479309 Epoch 73  	Train Loss = 12.95489 Val Loss = 49.00015
2023-09-02 12:01:27.875656 Epoch 74  	Train Loss = 12.95731 Val Loss = 48.99924
2023-09-02 12:02:03.393222 Epoch 75  	Train Loss = 12.92505 Val Loss = 48.93418
2023-09-02 12:02:38.819647 Epoch 76  	Train Loss = 12.90509 Val Loss = 49.00974
2023-09-02 12:03:14.163457 Epoch 77  	Train Loss = 12.89661 Val Loss = 49.00142
2023-09-02 12:03:49.638243 Epoch 78  	Train Loss = 12.90389 Val Loss = 49.04321
2023-09-02 12:04:25.033069 Epoch 79  	Train Loss = 12.87486 Val Loss = 49.01045
2023-09-02 12:05:00.319876 Epoch 80  	Train Loss = 12.89208 Val Loss = 48.97089
2023-09-02 12:05:35.775623 Epoch 81  	Train Loss = 12.86619 Val Loss = 48.99692
CL target length = 9
2023-09-02 12:06:11.158999 Epoch 82  	Train Loss = 13.41761 Val Loss = 40.17740
2023-09-02 12:06:46.659870 Epoch 83  	Train Loss = 13.03635 Val Loss = 40.21361
2023-09-02 12:07:22.051554 Epoch 84  	Train Loss = 12.98320 Val Loss = 40.13446
2023-09-02 12:07:57.372619 Epoch 85  	Train Loss = 12.96906 Val Loss = 40.29875
2023-09-02 12:08:32.735763 Epoch 86  	Train Loss = 12.95937 Val Loss = 40.12754
2023-09-02 12:09:08.102507 Epoch 87  	Train Loss = 12.93213 Val Loss = 40.19730
2023-09-02 12:09:43.572345 Epoch 88  	Train Loss = 12.92988 Val Loss = 40.10092
2023-09-02 12:10:19.002956 Epoch 89  	Train Loss = 12.89454 Val Loss = 40.17739
2023-09-02 12:10:54.469964 Epoch 90  	Train Loss = 12.91203 Val Loss = 40.39291
2023-09-02 12:11:29.978672 Epoch 91  	Train Loss = 12.90128 Val Loss = 40.18304
CL target length = 10
2023-09-02 12:12:05.458940 Epoch 92  	Train Loss = 13.39449 Val Loss = 31.44372
2023-09-02 12:12:40.968459 Epoch 93  	Train Loss = 13.01583 Val Loss = 31.24456
2023-09-02 12:13:16.420251 Epoch 94  	Train Loss = 13.02742 Val Loss = 31.20846
2023-09-02 12:13:51.885749 Epoch 95  	Train Loss = 12.98936 Val Loss = 31.32442
2023-09-02 12:14:27.436109 Epoch 96  	Train Loss = 12.97568 Val Loss = 31.29908
2023-09-02 12:15:03.044743 Epoch 97  	Train Loss = 12.95634 Val Loss = 31.55007
2023-09-02 12:15:38.899319 Epoch 98  	Train Loss = 12.97251 Val Loss = 31.21742
2023-09-02 12:16:14.812354 Epoch 99  	Train Loss = 12.94835 Val Loss = 31.42135
2023-09-02 12:16:50.604612 Epoch 100  	Train Loss = 12.94996 Val Loss = 31.34360
2023-09-02 12:17:26.565387 Epoch 101  	Train Loss = 12.94415 Val Loss = 31.24495
CL target length = 11
2023-09-02 12:18:02.243398 Epoch 102  	Train Loss = 13.34790 Val Loss = 22.43435
2023-09-02 12:18:37.830284 Epoch 103  	Train Loss = 13.04638 Val Loss = 22.47334
2023-09-02 12:19:13.335047 Epoch 104  	Train Loss = 13.02777 Val Loss = 22.63111
2023-09-02 12:19:48.876902 Epoch 105  	Train Loss = 13.00886 Val Loss = 22.46072
2023-09-02 12:20:24.345931 Epoch 106  	Train Loss = 13.00098 Val Loss = 22.45598
2023-09-02 12:20:59.787212 Epoch 107  	Train Loss = 13.00004 Val Loss = 22.35933
2023-09-02 12:21:35.214895 Epoch 108  	Train Loss = 12.97112 Val Loss = 22.49244
2023-09-02 12:22:10.539817 Epoch 109  	Train Loss = 12.96946 Val Loss = 22.65800
2023-09-02 12:22:45.892278 Epoch 110  	Train Loss = 12.98553 Val Loss = 22.38757
2023-09-02 12:23:21.391226 Epoch 111  	Train Loss = 12.95379 Val Loss = 22.48913
CL target length = 12
2023-09-02 12:23:56.773988 Epoch 112  	Train Loss = 13.32318 Val Loss = 13.74886
2023-09-02 12:24:32.039708 Epoch 113  	Train Loss = 13.06272 Val Loss = 13.59849
2023-09-02 12:25:07.386265 Epoch 114  	Train Loss = 13.04034 Val Loss = 13.60414
2023-09-02 12:25:42.642814 Epoch 115  	Train Loss = 13.03470 Val Loss = 13.57810
2023-09-02 12:26:18.088235 Epoch 116  	Train Loss = 12.77784 Val Loss = 13.36819
2023-09-02 12:26:53.504848 Epoch 117  	Train Loss = 12.74852 Val Loss = 13.38294
2023-09-02 12:27:28.882102 Epoch 118  	Train Loss = 12.73771 Val Loss = 13.36531
2023-09-02 12:28:04.285561 Epoch 119  	Train Loss = 12.72773 Val Loss = 13.39774
2023-09-02 12:28:39.756186 Epoch 120  	Train Loss = 12.72395 Val Loss = 13.36291
2023-09-02 12:29:15.408193 Epoch 121  	Train Loss = 12.72532 Val Loss = 13.36842
2023-09-02 12:29:51.081454 Epoch 122  	Train Loss = 12.71208 Val Loss = 13.38360
2023-09-02 12:30:26.660453 Epoch 123  	Train Loss = 12.70965 Val Loss = 13.34767
2023-09-02 12:31:02.342587 Epoch 124  	Train Loss = 12.70439 Val Loss = 13.38645
2023-09-02 12:31:37.892896 Epoch 125  	Train Loss = 12.70743 Val Loss = 13.33613
2023-09-02 12:32:13.320276 Epoch 126  	Train Loss = 12.69775 Val Loss = 13.34498
2023-09-02 12:32:48.605574 Epoch 127  	Train Loss = 12.69911 Val Loss = 13.35070
2023-09-02 12:33:23.669738 Epoch 128  	Train Loss = 12.69127 Val Loss = 13.34016
2023-09-02 12:33:58.896295 Epoch 129  	Train Loss = 12.68855 Val Loss = 13.34637
2023-09-02 12:34:33.910790 Epoch 130  	Train Loss = 12.68448 Val Loss = 13.35728
2023-09-02 12:35:08.901493 Epoch 131  	Train Loss = 12.67916 Val Loss = 13.31677
2023-09-02 12:35:43.848381 Epoch 132  	Train Loss = 12.67430 Val Loss = 13.33515
2023-09-02 12:36:18.876985 Epoch 133  	Train Loss = 12.67456 Val Loss = 13.33541
2023-09-02 12:36:53.918476 Epoch 134  	Train Loss = 12.67530 Val Loss = 13.34281
2023-09-02 12:37:28.958764 Epoch 135  	Train Loss = 12.66841 Val Loss = 13.33390
2023-09-02 12:38:03.986068 Epoch 136  	Train Loss = 12.67063 Val Loss = 13.34948
2023-09-02 12:38:39.058732 Epoch 137  	Train Loss = 12.66601 Val Loss = 13.33144
2023-09-02 12:39:14.068965 Epoch 138  	Train Loss = 12.66529 Val Loss = 13.31546
2023-09-02 12:39:48.860862 Epoch 139  	Train Loss = 12.66099 Val Loss = 13.32888
2023-09-02 12:40:23.970072 Epoch 140  	Train Loss = 12.65813 Val Loss = 13.32417
2023-09-02 12:40:58.952476 Epoch 141  	Train Loss = 12.66047 Val Loss = 13.34621
2023-09-02 12:41:33.984422 Epoch 142  	Train Loss = 12.65128 Val Loss = 13.32390
2023-09-02 12:42:09.050115 Epoch 143  	Train Loss = 12.64702 Val Loss = 13.33391
2023-09-02 12:42:44.077991 Epoch 144  	Train Loss = 12.64886 Val Loss = 13.31849
2023-09-02 12:43:19.138796 Epoch 145  	Train Loss = 12.64223 Val Loss = 13.31915
2023-09-02 12:43:54.295067 Epoch 146  	Train Loss = 12.63662 Val Loss = 13.31535
2023-09-02 12:44:29.502542 Epoch 147  	Train Loss = 12.64213 Val Loss = 13.34923
2023-09-02 12:45:04.806263 Epoch 148  	Train Loss = 12.63427 Val Loss = 13.32457
2023-09-02 12:45:40.178543 Epoch 149  	Train Loss = 12.63099 Val Loss = 13.31208
2023-09-02 12:46:15.483543 Epoch 150  	Train Loss = 12.63017 Val Loss = 13.32018
2023-09-02 12:46:50.655648 Epoch 151  	Train Loss = 12.62981 Val Loss = 13.32941
2023-09-02 12:47:25.702116 Epoch 152  	Train Loss = 12.62850 Val Loss = 13.34555
2023-09-02 12:48:00.742429 Epoch 153  	Train Loss = 12.62731 Val Loss = 13.31817
2023-09-02 12:48:35.845557 Epoch 154  	Train Loss = 12.62052 Val Loss = 13.30908
2023-09-02 12:49:10.896232 Epoch 155  	Train Loss = 12.61992 Val Loss = 13.32770
2023-09-02 12:49:45.904345 Epoch 156  	Train Loss = 12.62024 Val Loss = 13.35884
2023-09-02 12:50:20.950384 Epoch 157  	Train Loss = 12.61468 Val Loss = 13.34342
2023-09-02 12:50:55.980980 Epoch 158  	Train Loss = 12.61867 Val Loss = 13.30438
2023-09-02 12:51:30.990613 Epoch 159  	Train Loss = 12.61228 Val Loss = 13.30978
2023-09-02 12:52:05.923555 Epoch 160  	Train Loss = 12.60858 Val Loss = 13.32664
2023-09-02 12:52:40.829902 Epoch 161  	Train Loss = 12.60997 Val Loss = 13.30690
2023-09-02 12:53:15.778617 Epoch 162  	Train Loss = 12.60199 Val Loss = 13.30506
2023-09-02 12:53:50.717527 Epoch 163  	Train Loss = 12.60004 Val Loss = 13.29991
2023-09-02 12:54:25.722032 Epoch 164  	Train Loss = 12.60102 Val Loss = 13.31706
2023-09-02 12:55:00.698844 Epoch 165  	Train Loss = 12.59842 Val Loss = 13.30705
2023-09-02 12:55:35.761115 Epoch 166  	Train Loss = 12.59817 Val Loss = 13.29401
2023-09-02 12:56:10.749068 Epoch 167  	Train Loss = 12.59378 Val Loss = 13.34938
2023-09-02 12:56:45.776316 Epoch 168  	Train Loss = 12.59244 Val Loss = 13.31080
2023-09-02 12:57:20.847516 Epoch 169  	Train Loss = 12.59008 Val Loss = 13.32929
2023-09-02 12:57:55.888429 Epoch 170  	Train Loss = 12.58750 Val Loss = 13.28997
2023-09-02 12:58:31.000760 Epoch 171  	Train Loss = 12.58679 Val Loss = 13.30294
2023-09-02 12:59:06.246358 Epoch 172  	Train Loss = 12.58624 Val Loss = 13.29348
2023-09-02 12:59:41.529813 Epoch 173  	Train Loss = 12.57993 Val Loss = 13.29904
2023-09-02 13:00:16.958392 Epoch 174  	Train Loss = 12.58135 Val Loss = 13.30858
2023-09-02 13:00:52.183531 Epoch 175  	Train Loss = 12.58047 Val Loss = 13.29843
2023-09-02 13:01:27.173043 Epoch 176  	Train Loss = 12.57763 Val Loss = 13.29471
2023-09-02 13:02:02.366258 Epoch 177  	Train Loss = 12.57421 Val Loss = 13.32363
2023-09-02 13:02:37.678951 Epoch 178  	Train Loss = 12.57608 Val Loss = 13.31765
2023-09-02 13:03:12.930225 Epoch 179  	Train Loss = 12.57038 Val Loss = 13.32313
2023-09-02 13:03:48.293677 Epoch 180  	Train Loss = 12.57271 Val Loss = 13.29811
Early stopping at epoch: 180
Best at epoch 170:
Train Loss = 12.58750
Train RMSE = 20.96331, MAE = 12.88908, MAPE = 12.28070
Val Loss = 13.28997
Val RMSE = 22.07936, MAE = 13.81781, MAPE = 13.33553
--------- Test ---------
All Steps RMSE = 25.94649, MAE = 14.80968, MAPE = 14.89520
Step 1 RMSE = 19.49358, MAE = 12.08594, MAPE = 12.94956
Step 2 RMSE = 21.96688, MAE = 13.10627, MAPE = 14.23024
Step 3 RMSE = 23.62063, MAE = 13.77039, MAPE = 15.04068
Step 4 RMSE = 24.77028, MAE = 14.20327, MAPE = 14.89962
Step 5 RMSE = 25.62843, MAE = 14.53567, MAPE = 14.60305
Step 6 RMSE = 26.32115, MAE = 14.86478, MAPE = 14.84132
Step 7 RMSE = 26.96957, MAE = 15.19364, MAPE = 14.90811
Step 8 RMSE = 27.53253, MAE = 15.51485, MAPE = 15.31903
Step 9 RMSE = 27.89896, MAE = 15.75888, MAPE = 15.45907
Step 10 RMSE = 28.13573, MAE = 15.96105, MAPE = 15.34695
Step 11 RMSE = 28.39441, MAE = 16.17659, MAPE = 15.34346
Step 12 RMSE = 28.86818, MAE = 16.54476, MAPE = 15.80134
Inference time: 3.97 s
