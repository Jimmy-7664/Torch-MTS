PEMS04
Trainset:	x-(10181, 12, 307, 2)	y-(10181, 12, 307, 1)
Valset:  	x-(3394, 12, 307, 2)  	y-(3394, 12, 307, 1)
Testset:	x-(3394, 12, 307, 2)	y-(3394, 12, 307, 1)

--------- MTGNN ---------
{
    "num_nodes": 307,
    "in_steps": 12,
    "out_steps": 12,
    "time_of_day": true,
    "train_size": 0.6,
    "val_size": 0.2,
    "lr": 0.001,
    "weight_decay": 0.0001,
    "milestones": [
        175
    ],
    "early_stop": 15,
    "clip_grad": 5,
    "batch_size": 64,
    "max_epochs": 500,
    "use_cl": true,
    "cl_step_size": 2500,
    "pass_device": true,
    "model_args": {
        "num_nodes": 307,
        "in_dim": 2,
        "seq_length": 12,
        "out_dim": 12,
        "device": "cuda:0",
        "gcn_true": true,
        "buildA_true": true,
        "gcn_depth": 2,
        "predefined_A": null,
        "static_feat": null,
        "dropout": 0.3,
        "subgraph_size": 20,
        "node_dim": 40,
        "dilation_exponential": 1,
        "conv_channels": 32,
        "residual_channels": 32,
        "skip_channels": 64,
        "end_channels": 128,
        "layers": 3,
        "propalpha": 0.05,
        "tanhalpha": 3,
        "layer_norm_affline": true
    }
}
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
MTGNN                                    [64, 12, 307, 1]          3,168
├─graph_constructor: 1-1                 [307, 307]                --
│    └─Embedding: 2-1                    [307, 40]                 12,280
│    └─Embedding: 2-2                    [307, 40]                 12,280
│    └─Linear: 2-3                       [307, 40]                 1,640
│    └─Linear: 2-4                       [307, 40]                 1,640
├─Conv2d: 1-2                            [64, 32, 307, 19]         96
├─Conv2d: 1-3                            [64, 64, 307, 1]          2,496
├─ModuleList: 1-16                       --                        (recursive)
│    └─dilated_inception: 2-5            [64, 32, 307, 13]         --
│    │    └─ModuleList: 3-1              --                        4,640
├─ModuleList: 1-17                       --                        (recursive)
│    └─dilated_inception: 2-6            [64, 32, 307, 13]         --
│    │    └─ModuleList: 3-2              --                        4,640
├─ModuleList: 1-18                       --                        (recursive)
│    └─Conv2d: 2-7                       [64, 64, 307, 1]          26,688
├─ModuleList: 1-19                       --                        (recursive)
│    └─mixprop: 2-8                      [64, 32, 307, 13]         --
│    │    └─nconv: 3-3                   [64, 32, 307, 13]         --
│    │    └─nconv: 3-4                   [64, 32, 307, 13]         --
│    │    └─linear: 3-5                  [64, 32, 307, 13]         3,104
├─ModuleList: 1-20                       --                        (recursive)
│    └─mixprop: 2-9                      [64, 32, 307, 13]         --
│    │    └─nconv: 3-6                   [64, 32, 307, 13]         --
│    │    └─nconv: 3-7                   [64, 32, 307, 13]         --
│    │    └─linear: 3-8                  [64, 32, 307, 13]         3,104
├─ModuleList: 1-21                       --                        (recursive)
│    └─LayerNorm: 2-10                   [64, 32, 307, 13]         255,424
├─ModuleList: 1-16                       --                        (recursive)
│    └─dilated_inception: 2-11           [64, 32, 307, 7]          --
│    │    └─ModuleList: 3-9              --                        4,640
├─ModuleList: 1-17                       --                        (recursive)
│    └─dilated_inception: 2-12           [64, 32, 307, 7]          --
│    │    └─ModuleList: 3-10             --                        4,640
├─ModuleList: 1-18                       --                        (recursive)
│    └─Conv2d: 2-13                      [64, 64, 307, 1]          14,400
├─ModuleList: 1-19                       --                        (recursive)
│    └─mixprop: 2-14                     [64, 32, 307, 7]          --
│    │    └─nconv: 3-11                  [64, 32, 307, 7]          --
│    │    └─nconv: 3-12                  [64, 32, 307, 7]          --
│    │    └─linear: 3-13                 [64, 32, 307, 7]          3,104
├─ModuleList: 1-20                       --                        (recursive)
│    └─mixprop: 2-15                     [64, 32, 307, 7]          --
│    │    └─nconv: 3-14                  [64, 32, 307, 7]          --
│    │    └─nconv: 3-15                  [64, 32, 307, 7]          --
│    │    └─linear: 3-16                 [64, 32, 307, 7]          3,104
├─ModuleList: 1-21                       --                        (recursive)
│    └─LayerNorm: 2-16                   [64, 32, 307, 7]          137,536
├─ModuleList: 1-16                       --                        (recursive)
│    └─dilated_inception: 2-17           [64, 32, 307, 1]          --
│    │    └─ModuleList: 3-17             --                        4,640
├─ModuleList: 1-17                       --                        (recursive)
│    └─dilated_inception: 2-18           [64, 32, 307, 1]          --
│    │    └─ModuleList: 3-18             --                        4,640
├─ModuleList: 1-18                       --                        (recursive)
│    └─Conv2d: 2-19                      [64, 64, 307, 1]          2,112
├─ModuleList: 1-19                       --                        (recursive)
│    └─mixprop: 2-20                     [64, 32, 307, 1]          --
│    │    └─nconv: 3-19                  [64, 32, 307, 1]          --
│    │    └─nconv: 3-20                  [64, 32, 307, 1]          --
│    │    └─linear: 3-21                 [64, 32, 307, 1]          3,104
├─ModuleList: 1-20                       --                        (recursive)
│    └─mixprop: 2-21                     [64, 32, 307, 1]          --
│    │    └─nconv: 3-22                  [64, 32, 307, 1]          --
│    │    └─nconv: 3-23                  [64, 32, 307, 1]          --
│    │    └─linear: 3-24                 [64, 32, 307, 1]          3,104
├─ModuleList: 1-21                       --                        (recursive)
│    └─LayerNorm: 2-22                   [64, 32, 307, 1]          19,648
├─Conv2d: 1-22                           [64, 64, 307, 1]          2,112
├─Conv2d: 1-23                           [64, 128, 307, 1]         8,320
├─Conv2d: 1-24                           [64, 12, 307, 1]          1,548
==========================================================================================
Total params: 547,852
Trainable params: 547,852
Non-trainable params: 0
Total mult-adds (G): 8.45
==========================================================================================
Input size (MB): 1.89
Forward/backward pass size (MB): 771.85
Params size (MB): 2.18
Estimated Total Size (MB): 775.92
==========================================================================================

Loss: HuberLoss

CL target length = 1
2023-09-02 11:18:00.561783 Epoch 1  	Train Loss = 23.22049 Val Loss = 123.53437
2023-09-02 11:18:20.615280 Epoch 2  	Train Loss = 18.44302 Val Loss = 123.46456
2023-09-02 11:18:40.799330 Epoch 3  	Train Loss = 17.85513 Val Loss = 123.37225
2023-09-02 11:19:01.027536 Epoch 4  	Train Loss = 17.55462 Val Loss = 123.30012
2023-09-02 11:19:21.314232 Epoch 5  	Train Loss = 17.45761 Val Loss = 123.30808
2023-09-02 11:19:41.668213 Epoch 6  	Train Loss = 17.38957 Val Loss = 123.35742
2023-09-02 11:20:02.075044 Epoch 7  	Train Loss = 17.29480 Val Loss = 123.34341
2023-09-02 11:20:22.544408 Epoch 8  	Train Loss = 17.19554 Val Loss = 123.29017
2023-09-02 11:20:43.034217 Epoch 9  	Train Loss = 17.21025 Val Loss = 123.31848
2023-09-02 11:21:03.570092 Epoch 10  	Train Loss = 17.21294 Val Loss = 123.30493
2023-09-02 11:21:24.146636 Epoch 11  	Train Loss = 17.14944 Val Loss = 123.27107
2023-09-02 11:21:44.823300 Epoch 12  	Train Loss = 17.04299 Val Loss = 123.38612
2023-09-02 11:22:05.769482 Epoch 13  	Train Loss = 17.09877 Val Loss = 123.34256
2023-09-02 11:22:26.882994 Epoch 14  	Train Loss = 16.85226 Val Loss = 123.26161
2023-09-02 11:22:48.172322 Epoch 15  	Train Loss = 16.97504 Val Loss = 123.27965
CL target length = 2
2023-09-02 11:23:09.642435 Epoch 16  	Train Loss = 19.68549 Val Loss = 113.69604
2023-09-02 11:23:31.012910 Epoch 17  	Train Loss = 17.48597 Val Loss = 113.73005
2023-09-02 11:23:52.401946 Epoch 18  	Train Loss = 17.31578 Val Loss = 113.64557
2023-09-02 11:24:13.749345 Epoch 19  	Train Loss = 17.13759 Val Loss = 113.62298
2023-09-02 11:24:35.144959 Epoch 20  	Train Loss = 17.12713 Val Loss = 113.64406
2023-09-02 11:24:56.563038 Epoch 21  	Train Loss = 17.05276 Val Loss = 113.67574
2023-09-02 11:25:18.004981 Epoch 22  	Train Loss = 17.02083 Val Loss = 113.62409
2023-09-02 11:25:39.431880 Epoch 23  	Train Loss = 16.89096 Val Loss = 113.62919
2023-09-02 11:26:00.788688 Epoch 24  	Train Loss = 16.84044 Val Loss = 113.67474
2023-09-02 11:26:21.956042 Epoch 25  	Train Loss = 16.79847 Val Loss = 113.58275
2023-09-02 11:26:43.005944 Epoch 26  	Train Loss = 16.72185 Val Loss = 113.69221
2023-09-02 11:27:04.007597 Epoch 27  	Train Loss = 16.71060 Val Loss = 113.57388
2023-09-02 11:27:24.889392 Epoch 28  	Train Loss = 16.74475 Val Loss = 113.67592
2023-09-02 11:27:45.720976 Epoch 29  	Train Loss = 16.68864 Val Loss = 113.58125
2023-09-02 11:28:06.484318 Epoch 30  	Train Loss = 16.67644 Val Loss = 113.67676
2023-09-02 11:28:27.265958 Epoch 31  	Train Loss = 16.62138 Val Loss = 113.59520
CL target length = 3
2023-09-02 11:28:48.072111 Epoch 32  	Train Loss = 18.61905 Val Loss = 104.12709
2023-09-02 11:29:08.884906 Epoch 33  	Train Loss = 17.00762 Val Loss = 103.99598
2023-09-02 11:29:29.654565 Epoch 34  	Train Loss = 16.90965 Val Loss = 103.97645
2023-09-02 11:29:50.531191 Epoch 35  	Train Loss = 16.85631 Val Loss = 103.95686
2023-09-02 11:30:11.426606 Epoch 36  	Train Loss = 16.89663 Val Loss = 104.07627
2023-09-02 11:30:32.336299 Epoch 37  	Train Loss = 16.83273 Val Loss = 103.94900
2023-09-02 11:30:53.233143 Epoch 38  	Train Loss = 16.79775 Val Loss = 103.99547
2023-09-02 11:31:14.174029 Epoch 39  	Train Loss = 16.74753 Val Loss = 104.04720
2023-09-02 11:31:35.178945 Epoch 40  	Train Loss = 16.78758 Val Loss = 103.92031
2023-09-02 11:31:56.171632 Epoch 41  	Train Loss = 16.71787 Val Loss = 104.25559
2023-09-02 11:32:17.133176 Epoch 42  	Train Loss = 16.80445 Val Loss = 103.93442
2023-09-02 11:32:38.126145 Epoch 43  	Train Loss = 16.70774 Val Loss = 103.98162
2023-09-02 11:32:59.108332 Epoch 44  	Train Loss = 16.68943 Val Loss = 103.94974
2023-09-02 11:33:20.061825 Epoch 45  	Train Loss = 16.74012 Val Loss = 103.97659
2023-09-02 11:33:41.111696 Epoch 46  	Train Loss = 16.60126 Val Loss = 103.97271
CL target length = 4
2023-09-02 11:34:02.086116 Epoch 47  	Train Loss = 17.83498 Val Loss = 95.02517
2023-09-02 11:34:23.154737 Epoch 48  	Train Loss = 16.97807 Val Loss = 94.57972
2023-09-02 11:34:44.385876 Epoch 49  	Train Loss = 16.97521 Val Loss = 94.39039
2023-09-02 11:35:05.600160 Epoch 50  	Train Loss = 16.92590 Val Loss = 94.43714
2023-09-02 11:35:26.914402 Epoch 51  	Train Loss = 16.90186 Val Loss = 94.34293
2023-09-02 11:35:48.285938 Epoch 52  	Train Loss = 16.84454 Val Loss = 94.34562
2023-09-02 11:36:09.699003 Epoch 53  	Train Loss = 16.80866 Val Loss = 94.32653
2023-09-02 11:36:31.279967 Epoch 54  	Train Loss = 16.83044 Val Loss = 94.37810
2023-09-02 11:36:52.892785 Epoch 55  	Train Loss = 16.83230 Val Loss = 94.35397
2023-09-02 11:37:14.566977 Epoch 56  	Train Loss = 16.80680 Val Loss = 94.39364
2023-09-02 11:37:36.240749 Epoch 57  	Train Loss = 16.78074 Val Loss = 94.35700
2023-09-02 11:37:57.963231 Epoch 58  	Train Loss = 16.76881 Val Loss = 94.53247
2023-09-02 11:38:19.702223 Epoch 59  	Train Loss = 16.75845 Val Loss = 94.44865
2023-09-02 11:38:41.443035 Epoch 60  	Train Loss = 16.67148 Val Loss = 94.40856
2023-09-02 11:39:03.279667 Epoch 61  	Train Loss = 16.69388 Val Loss = 94.35280
2023-09-02 11:39:25.047851 Epoch 62  	Train Loss = 16.66941 Val Loss = 94.36512
CL target length = 5
2023-09-02 11:39:46.801753 Epoch 63  	Train Loss = 17.98061 Val Loss = 84.82925
2023-09-02 11:40:08.561662 Epoch 64  	Train Loss = 17.00393 Val Loss = 84.78859
2023-09-02 11:40:30.270520 Epoch 65  	Train Loss = 16.93569 Val Loss = 84.79992
2023-09-02 11:40:51.853467 Epoch 66  	Train Loss = 16.91904 Val Loss = 84.76097
2023-09-02 11:41:13.259667 Epoch 67  	Train Loss = 16.87994 Val Loss = 84.74280
2023-09-02 11:41:34.559033 Epoch 68  	Train Loss = 16.84641 Val Loss = 84.87378
2023-09-02 11:41:55.705586 Epoch 69  	Train Loss = 16.87462 Val Loss = 84.86499
2023-09-02 11:42:16.830137 Epoch 70  	Train Loss = 16.82703 Val Loss = 84.79911
2023-09-02 11:42:37.973643 Epoch 71  	Train Loss = 16.82471 Val Loss = 84.78105
2023-09-02 11:42:59.053777 Epoch 72  	Train Loss = 16.85141 Val Loss = 84.89769
2023-09-02 11:43:20.115751 Epoch 73  	Train Loss = 16.81488 Val Loss = 84.91234
2023-09-02 11:43:41.122955 Epoch 74  	Train Loss = 16.81299 Val Loss = 84.87934
2023-09-02 11:44:02.154842 Epoch 75  	Train Loss = 16.78525 Val Loss = 84.83753
2023-09-02 11:44:23.260737 Epoch 76  	Train Loss = 16.80119 Val Loss = 84.78679
2023-09-02 11:44:44.348848 Epoch 77  	Train Loss = 16.71414 Val Loss = 84.73986
2023-09-02 11:45:05.495680 Epoch 78  	Train Loss = 16.76918 Val Loss = 84.75044
CL target length = 6
2023-09-02 11:45:26.619973 Epoch 79  	Train Loss = 17.86313 Val Loss = 75.29995
2023-09-02 11:45:47.715920 Epoch 80  	Train Loss = 16.95179 Val Loss = 75.26185
2023-09-02 11:46:08.879457 Epoch 81  	Train Loss = 16.93247 Val Loss = 75.23244
2023-09-02 11:46:30.119227 Epoch 82  	Train Loss = 16.92828 Val Loss = 75.40713
2023-09-02 11:46:51.295084 Epoch 83  	Train Loss = 16.95786 Val Loss = 75.21849
2023-09-02 11:47:12.472247 Epoch 84  	Train Loss = 16.90282 Val Loss = 75.17088
2023-09-02 11:47:33.553333 Epoch 85  	Train Loss = 16.88238 Val Loss = 75.40569
2023-09-02 11:47:54.582260 Epoch 86  	Train Loss = 16.89203 Val Loss = 75.17579
2023-09-02 11:48:15.560241 Epoch 87  	Train Loss = 16.83718 Val Loss = 75.26202
2023-09-02 11:48:36.600332 Epoch 88  	Train Loss = 16.82778 Val Loss = 75.28040
2023-09-02 11:48:57.781547 Epoch 89  	Train Loss = 16.85256 Val Loss = 75.32032
2023-09-02 11:49:19.025927 Epoch 90  	Train Loss = 16.82718 Val Loss = 75.16883
2023-09-02 11:49:40.412257 Epoch 91  	Train Loss = 16.77629 Val Loss = 75.26543
2023-09-02 11:50:01.811700 Epoch 92  	Train Loss = 16.84923 Val Loss = 75.11759
2023-09-02 11:50:23.275271 Epoch 93  	Train Loss = 16.80905 Val Loss = 75.34401
CL target length = 7
2023-09-02 11:50:44.791128 Epoch 94  	Train Loss = 17.58995 Val Loss = 66.18073
2023-09-02 11:51:07.028501 Epoch 95  	Train Loss = 17.05143 Val Loss = 65.86040
2023-09-02 11:51:28.428888 Epoch 96  	Train Loss = 16.99638 Val Loss = 65.67191
2023-09-02 11:51:49.977020 Epoch 97  	Train Loss = 16.98865 Val Loss = 65.70123
2023-09-02 11:52:11.553499 Epoch 98  	Train Loss = 16.99487 Val Loss = 65.80119
2023-09-02 11:52:33.111431 Epoch 99  	Train Loss = 16.91844 Val Loss = 65.67201
2023-09-02 11:52:54.753865 Epoch 100  	Train Loss = 16.96342 Val Loss = 65.69730
2023-09-02 11:53:16.369720 Epoch 101  	Train Loss = 16.90466 Val Loss = 65.72851
2023-09-02 11:53:38.060447 Epoch 102  	Train Loss = 16.93260 Val Loss = 65.68157
2023-09-02 11:53:59.756461 Epoch 103  	Train Loss = 16.85748 Val Loss = 65.72050
2023-09-02 11:54:21.507540 Epoch 104  	Train Loss = 16.86507 Val Loss = 65.88417
2023-09-02 11:54:43.238785 Epoch 105  	Train Loss = 16.85961 Val Loss = 65.66195
2023-09-02 11:55:04.748799 Epoch 106  	Train Loss = 16.85922 Val Loss = 65.66359
2023-09-02 11:55:26.163385 Epoch 107  	Train Loss = 16.89092 Val Loss = 65.81260
2023-09-02 11:55:47.548973 Epoch 108  	Train Loss = 16.80347 Val Loss = 65.72271
2023-09-02 11:56:08.887582 Epoch 109  	Train Loss = 16.78498 Val Loss = 65.66254
CL target length = 8
2023-09-02 11:56:30.097034 Epoch 110  	Train Loss = 17.65169 Val Loss = 56.19542
2023-09-02 11:56:51.251545 Epoch 111  	Train Loss = 16.97961 Val Loss = 56.15152
2023-09-02 11:57:12.359209 Epoch 112  	Train Loss = 16.92998 Val Loss = 56.18257
2023-09-02 11:57:33.442419 Epoch 113  	Train Loss = 16.96409 Val Loss = 56.16885
2023-09-02 11:57:54.591631 Epoch 114  	Train Loss = 16.94470 Val Loss = 56.23086
2023-09-02 11:58:15.687670 Epoch 115  	Train Loss = 16.94607 Val Loss = 56.19992
2023-09-02 11:58:36.741397 Epoch 116  	Train Loss = 16.92458 Val Loss = 56.19018
2023-09-02 11:58:57.751511 Epoch 117  	Train Loss = 16.94948 Val Loss = 56.11869
2023-09-02 11:59:18.836599 Epoch 118  	Train Loss = 16.88010 Val Loss = 56.26072
2023-09-02 11:59:39.969289 Epoch 119  	Train Loss = 16.89641 Val Loss = 56.13836
2023-09-02 12:00:01.098333 Epoch 120  	Train Loss = 16.90349 Val Loss = 56.28837
2023-09-02 12:00:22.201967 Epoch 121  	Train Loss = 16.88444 Val Loss = 56.16956
2023-09-02 12:00:43.349617 Epoch 122  	Train Loss = 16.82866 Val Loss = 56.16576
2023-09-02 12:01:04.454968 Epoch 123  	Train Loss = 16.83983 Val Loss = 56.23388
2023-09-02 12:01:25.641097 Epoch 124  	Train Loss = 16.79991 Val Loss = 56.24076
2023-09-02 12:01:46.754515 Epoch 125  	Train Loss = 16.82632 Val Loss = 56.31150
CL target length = 9
2023-09-02 12:02:07.906784 Epoch 126  	Train Loss = 17.67969 Val Loss = 46.71684
2023-09-02 12:02:28.948706 Epoch 127  	Train Loss = 16.97480 Val Loss = 46.61939
2023-09-02 12:02:49.879847 Epoch 128  	Train Loss = 16.99731 Val Loss = 46.61431
2023-09-02 12:03:10.830351 Epoch 129  	Train Loss = 17.00754 Val Loss = 46.71618
2023-09-02 12:03:31.792019 Epoch 130  	Train Loss = 16.99230 Val Loss = 46.82181
2023-09-02 12:03:52.962983 Epoch 131  	Train Loss = 16.99080 Val Loss = 46.62807
2023-09-02 12:04:14.191439 Epoch 132  	Train Loss = 16.94354 Val Loss = 46.65412
2023-09-02 12:04:35.489903 Epoch 133  	Train Loss = 16.96972 Val Loss = 46.67485
2023-09-02 12:04:56.783287 Epoch 134  	Train Loss = 16.92358 Val Loss = 46.67072
2023-09-02 12:05:18.116593 Epoch 135  	Train Loss = 16.96543 Val Loss = 46.71725
2023-09-02 12:05:39.491186 Epoch 136  	Train Loss = 16.88186 Val Loss = 46.55632
2023-09-02 12:06:00.817588 Epoch 137  	Train Loss = 16.86931 Val Loss = 46.60180
2023-09-02 12:06:22.176956 Epoch 138  	Train Loss = 16.85713 Val Loss = 46.75548
2023-09-02 12:06:43.409086 Epoch 139  	Train Loss = 16.87966 Val Loss = 46.51115
2023-09-02 12:07:04.588200 Epoch 140  	Train Loss = 16.92062 Val Loss = 46.81396
CL target length = 10
2023-09-02 12:07:25.735684 Epoch 141  	Train Loss = 17.51760 Val Loss = 37.33502
2023-09-02 12:07:46.971481 Epoch 142  	Train Loss = 17.08865 Val Loss = 37.07577
2023-09-02 12:08:08.198586 Epoch 143  	Train Loss = 17.06791 Val Loss = 37.13519
2023-09-02 12:08:29.446718 Epoch 144  	Train Loss = 16.97123 Val Loss = 37.09613
2023-09-02 12:08:50.778506 Epoch 145  	Train Loss = 16.97959 Val Loss = 37.13869
2023-09-02 12:09:12.020219 Epoch 146  	Train Loss = 17.01612 Val Loss = 37.08837
2023-09-02 12:09:33.311459 Epoch 147  	Train Loss = 16.98913 Val Loss = 37.21120
2023-09-02 12:09:54.716016 Epoch 148  	Train Loss = 17.01789 Val Loss = 37.42262
2023-09-02 12:10:16.164109 Epoch 149  	Train Loss = 17.05078 Val Loss = 37.34575
2023-09-02 12:10:37.665416 Epoch 150  	Train Loss = 16.96890 Val Loss = 37.51196
2023-09-02 12:10:59.176435 Epoch 151  	Train Loss = 16.96517 Val Loss = 37.15745
2023-09-02 12:11:20.605590 Epoch 152  	Train Loss = 16.93983 Val Loss = 37.47896
2023-09-02 12:11:42.069501 Epoch 153  	Train Loss = 16.92947 Val Loss = 37.11451
2023-09-02 12:12:03.604303 Epoch 154  	Train Loss = 16.91201 Val Loss = 37.14259
2023-09-02 12:12:25.038433 Epoch 155  	Train Loss = 16.93646 Val Loss = 37.28683
2023-09-02 12:12:46.471624 Epoch 156  	Train Loss = 16.92554 Val Loss = 37.11182
CL target length = 11
2023-09-02 12:13:07.863157 Epoch 157  	Train Loss = 17.67323 Val Loss = 27.81990
2023-09-02 12:13:29.365460 Epoch 158  	Train Loss = 17.08315 Val Loss = 27.94738
2023-09-02 12:13:50.816077 Epoch 159  	Train Loss = 17.01946 Val Loss = 27.65868
2023-09-02 12:14:12.346623 Epoch 160  	Train Loss = 17.02364 Val Loss = 27.88445
2023-09-02 12:14:34.084069 Epoch 161  	Train Loss = 17.04963 Val Loss = 27.60950
2023-09-02 12:14:55.897845 Epoch 162  	Train Loss = 17.03714 Val Loss = 27.67665
2023-09-02 12:15:17.809494 Epoch 163  	Train Loss = 16.99619 Val Loss = 27.80605
2023-09-02 12:15:39.927047 Epoch 164  	Train Loss = 17.02771 Val Loss = 27.66756
2023-09-02 12:16:01.863145 Epoch 165  	Train Loss = 17.02561 Val Loss = 27.68669
2023-09-02 12:16:23.886725 Epoch 166  	Train Loss = 17.00524 Val Loss = 27.76375
2023-09-02 12:16:45.790677 Epoch 167  	Train Loss = 16.98435 Val Loss = 27.69128
2023-09-02 12:17:07.830838 Epoch 168  	Train Loss = 16.97859 Val Loss = 27.64148
2023-09-02 12:17:29.936380 Epoch 169  	Train Loss = 16.96112 Val Loss = 27.92868
2023-09-02 12:17:51.776491 Epoch 170  	Train Loss = 17.00312 Val Loss = 27.77635
2023-09-02 12:18:13.457939 Epoch 171  	Train Loss = 16.95218 Val Loss = 27.68139
CL target length = 12
2023-09-02 12:18:35.035462 Epoch 172  	Train Loss = 17.42454 Val Loss = 19.25982
2023-09-02 12:18:56.478403 Epoch 173  	Train Loss = 17.19299 Val Loss = 18.45658
2023-09-02 12:19:17.890663 Epoch 174  	Train Loss = 17.12840 Val Loss = 18.17063
2023-09-02 12:19:39.215188 Epoch 175  	Train Loss = 17.08399 Val Loss = 18.59880
2023-09-02 12:20:00.576494 Epoch 176  	Train Loss = 16.79292 Val Loss = 17.99650
2023-09-02 12:20:21.807235 Epoch 177  	Train Loss = 16.78590 Val Loss = 17.97817
2023-09-02 12:20:43.052138 Epoch 178  	Train Loss = 16.77452 Val Loss = 17.96685
2023-09-02 12:21:04.185524 Epoch 179  	Train Loss = 16.73795 Val Loss = 17.99610
2023-09-02 12:21:25.348753 Epoch 180  	Train Loss = 16.72585 Val Loss = 17.98860
2023-09-02 12:21:46.549306 Epoch 181  	Train Loss = 16.72975 Val Loss = 17.96786
2023-09-02 12:22:07.705394 Epoch 182  	Train Loss = 16.71491 Val Loss = 17.97768
2023-09-02 12:22:28.826109 Epoch 183  	Train Loss = 16.72514 Val Loss = 17.96490
2023-09-02 12:22:49.938327 Epoch 184  	Train Loss = 16.71896 Val Loss = 17.98243
2023-09-02 12:23:10.999189 Epoch 185  	Train Loss = 16.73835 Val Loss = 17.98835
2023-09-02 12:23:32.058507 Epoch 186  	Train Loss = 16.72079 Val Loss = 17.95021
2023-09-02 12:23:53.050458 Epoch 187  	Train Loss = 16.71940 Val Loss = 17.93266
2023-09-02 12:24:13.991728 Epoch 188  	Train Loss = 16.68375 Val Loss = 17.94138
2023-09-02 12:24:34.888997 Epoch 189  	Train Loss = 16.71077 Val Loss = 17.97038
2023-09-02 12:24:55.729349 Epoch 190  	Train Loss = 16.69976 Val Loss = 17.96697
2023-09-02 12:25:16.453010 Epoch 191  	Train Loss = 16.71420 Val Loss = 17.97039
2023-09-02 12:25:37.253829 Epoch 192  	Train Loss = 16.69687 Val Loss = 17.97335
2023-09-02 12:25:58.137982 Epoch 193  	Train Loss = 16.72263 Val Loss = 17.97646
2023-09-02 12:26:19.186769 Epoch 194  	Train Loss = 16.67576 Val Loss = 17.95140
2023-09-02 12:26:40.404810 Epoch 195  	Train Loss = 16.71716 Val Loss = 17.96627
2023-09-02 12:27:01.706061 Epoch 196  	Train Loss = 16.68216 Val Loss = 17.98034
2023-09-02 12:27:22.997871 Epoch 197  	Train Loss = 16.66312 Val Loss = 17.95458
2023-09-02 12:27:44.353890 Epoch 198  	Train Loss = 16.70886 Val Loss = 17.93285
2023-09-02 12:28:05.781458 Epoch 199  	Train Loss = 16.65436 Val Loss = 17.95349
2023-09-02 12:28:27.278450 Epoch 200  	Train Loss = 16.66005 Val Loss = 17.95011
2023-09-02 12:28:48.955153 Epoch 201  	Train Loss = 16.66415 Val Loss = 17.95262
2023-09-02 12:29:10.711571 Epoch 202  	Train Loss = 16.64523 Val Loss = 17.99135
Early stopping at epoch: 202
Best at epoch 187:
Train Loss = 16.71940
Train RMSE = 28.12899, MAE = 17.06467, MAPE = 12.09842
Val Loss = 17.93266
Val RMSE = 31.24285, MAE = 18.76664, MAPE = 12.12707
--------- Test ---------
All Steps RMSE = 31.66676, MAE = 18.93508, MAPE = 12.48280
Step 1 RMSE = 27.14351, MAE = 16.83284, MAPE = 11.12381
Step 2 RMSE = 28.51990, MAE = 17.47625, MAPE = 11.59248
Step 3 RMSE = 29.73956, MAE = 18.00516, MAPE = 11.96072
Step 4 RMSE = 30.65607, MAE = 18.37865, MAPE = 12.17859
Step 5 RMSE = 31.38149, MAE = 18.69011, MAPE = 12.34198
Step 6 RMSE = 31.93435, MAE = 18.96051, MAPE = 12.47704
Step 7 RMSE = 32.44315, MAE = 19.22540, MAPE = 12.64616
Step 8 RMSE = 32.81499, MAE = 19.45137, MAPE = 12.77350
Step 9 RMSE = 33.11206, MAE = 19.66216, MAPE = 12.90777
Step 10 RMSE = 33.41778, MAE = 19.87139, MAPE = 13.05063
Step 11 RMSE = 33.75500, MAE = 20.14250, MAPE = 13.23937
Step 12 RMSE = 34.24089, MAE = 20.52444, MAPE = 13.50110
Inference time: 2.33 s
