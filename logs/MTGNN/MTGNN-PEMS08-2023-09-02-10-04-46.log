PEMS08
Trainset:	x-(10700, 12, 170, 2)	y-(10700, 12, 170, 1)
Valset:  	x-(3567, 12, 170, 2)  	y-(3567, 12, 170, 1)
Testset:	x-(3566, 12, 170, 2)	y-(3566, 12, 170, 1)

--------- MTGNN ---------
{
    "num_nodes": 170,
    "in_steps": 12,
    "out_steps": 12,
    "time_of_day": true,
    "train_size": 0.6,
    "val_size": 0.2,
    "lr": 0.001,
    "weight_decay": 0.0001,
    "milestones": [
        168
    ],
    "early_stop": 15,
    "clip_grad": 5,
    "batch_size": 64,
    "max_epochs": 200,
    "use_cl": true,
    "cl_step_size": 2500,
    "loss": "masked_mae",
    "pass_device": true,
    "model_args": {
        "num_nodes": 170,
        "in_dim": 2,
        "seq_length": 12,
        "out_dim": 12,
        "device": "cuda:0",
        "gcn_true": true,
        "buildA_true": true,
        "gcn_depth": 2,
        "predefined_A": null,
        "static_feat": null,
        "dropout": 0.3,
        "subgraph_size": 20,
        "node_dim": 40,
        "dilation_exponential": 1,
        "conv_channels": 32,
        "residual_channels": 32,
        "skip_channels": 64,
        "end_channels": 128,
        "layers": 3,
        "propalpha": 0.05,
        "tanhalpha": 3,
        "layer_norm_affline": true
    }
}
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
MTGNN                                    [64, 12, 170, 1]          3,168
├─graph_constructor: 1-1                 [170, 170]                --
│    └─Embedding: 2-1                    [170, 40]                 6,800
│    └─Embedding: 2-2                    [170, 40]                 6,800
│    └─Linear: 2-3                       [170, 40]                 1,640
│    └─Linear: 2-4                       [170, 40]                 1,640
├─Conv2d: 1-2                            [64, 32, 170, 19]         96
├─Conv2d: 1-3                            [64, 64, 170, 1]          2,496
├─ModuleList: 1-16                       --                        (recursive)
│    └─dilated_inception: 2-5            [64, 32, 170, 13]         --
│    │    └─ModuleList: 3-1              --                        4,640
├─ModuleList: 1-17                       --                        (recursive)
│    └─dilated_inception: 2-6            [64, 32, 170, 13]         --
│    │    └─ModuleList: 3-2              --                        4,640
├─ModuleList: 1-18                       --                        (recursive)
│    └─Conv2d: 2-7                       [64, 64, 170, 1]          26,688
├─ModuleList: 1-19                       --                        (recursive)
│    └─mixprop: 2-8                      [64, 32, 170, 13]         --
│    │    └─nconv: 3-3                   [64, 32, 170, 13]         --
│    │    └─nconv: 3-4                   [64, 32, 170, 13]         --
│    │    └─linear: 3-5                  [64, 32, 170, 13]         3,104
├─ModuleList: 1-20                       --                        (recursive)
│    └─mixprop: 2-9                      [64, 32, 170, 13]         --
│    │    └─nconv: 3-6                   [64, 32, 170, 13]         --
│    │    └─nconv: 3-7                   [64, 32, 170, 13]         --
│    │    └─linear: 3-8                  [64, 32, 170, 13]         3,104
├─ModuleList: 1-21                       --                        (recursive)
│    └─LayerNorm: 2-10                   [64, 32, 170, 13]         141,440
├─ModuleList: 1-16                       --                        (recursive)
│    └─dilated_inception: 2-11           [64, 32, 170, 7]          --
│    │    └─ModuleList: 3-9              --                        4,640
├─ModuleList: 1-17                       --                        (recursive)
│    └─dilated_inception: 2-12           [64, 32, 170, 7]          --
│    │    └─ModuleList: 3-10             --                        4,640
├─ModuleList: 1-18                       --                        (recursive)
│    └─Conv2d: 2-13                      [64, 64, 170, 1]          14,400
├─ModuleList: 1-19                       --                        (recursive)
│    └─mixprop: 2-14                     [64, 32, 170, 7]          --
│    │    └─nconv: 3-11                  [64, 32, 170, 7]          --
│    │    └─nconv: 3-12                  [64, 32, 170, 7]          --
│    │    └─linear: 3-13                 [64, 32, 170, 7]          3,104
├─ModuleList: 1-20                       --                        (recursive)
│    └─mixprop: 2-15                     [64, 32, 170, 7]          --
│    │    └─nconv: 3-14                  [64, 32, 170, 7]          --
│    │    └─nconv: 3-15                  [64, 32, 170, 7]          --
│    │    └─linear: 3-16                 [64, 32, 170, 7]          3,104
├─ModuleList: 1-21                       --                        (recursive)
│    └─LayerNorm: 2-16                   [64, 32, 170, 7]          76,160
├─ModuleList: 1-16                       --                        (recursive)
│    └─dilated_inception: 2-17           [64, 32, 170, 1]          --
│    │    └─ModuleList: 3-17             --                        4,640
├─ModuleList: 1-17                       --                        (recursive)
│    └─dilated_inception: 2-18           [64, 32, 170, 1]          --
│    │    └─ModuleList: 3-18             --                        4,640
├─ModuleList: 1-18                       --                        (recursive)
│    └─Conv2d: 2-19                      [64, 64, 170, 1]          2,112
├─ModuleList: 1-19                       --                        (recursive)
│    └─mixprop: 2-20                     [64, 32, 170, 1]          --
│    │    └─nconv: 3-19                  [64, 32, 170, 1]          --
│    │    └─nconv: 3-20                  [64, 32, 170, 1]          --
│    │    └─linear: 3-21                 [64, 32, 170, 1]          3,104
├─ModuleList: 1-20                       --                        (recursive)
│    └─mixprop: 2-21                     [64, 32, 170, 1]          --
│    │    └─nconv: 3-22                  [64, 32, 170, 1]          --
│    │    └─nconv: 3-23                  [64, 32, 170, 1]          --
│    │    └─linear: 3-24                 [64, 32, 170, 1]          3,104
├─ModuleList: 1-21                       --                        (recursive)
│    └─LayerNorm: 2-22                   [64, 32, 170, 1]          10,880
├─Conv2d: 1-22                           [64, 64, 170, 1]          2,112
├─Conv2d: 1-23                           [64, 128, 170, 1]         8,320
├─Conv2d: 1-24                           [64, 12, 170, 1]          1,548
==========================================================================================
Total params: 352,764
Trainable params: 352,764
Non-trainable params: 0
Total mult-adds (G): 4.68
==========================================================================================
Input size (MB): 1.04
Forward/backward pass size (MB): 427.41
Params size (MB): 1.40
Estimated Total Size (MB): 429.85
==========================================================================================

Loss: MaskedMAELoss

CL target length = 1
2023-09-02 10:05:00.803985 Epoch 1  	Train Loss = 19.54820 Val Loss = 113.03917
2023-09-02 10:05:13.944743 Epoch 2  	Train Loss = 15.43888 Val Loss = 113.08327
2023-09-02 10:05:27.201019 Epoch 3  	Train Loss = 15.08705 Val Loss = 113.06731
2023-09-02 10:05:40.361991 Epoch 4  	Train Loss = 14.82006 Val Loss = 113.04295
2023-09-02 10:05:53.775181 Epoch 5  	Train Loss = 14.53877 Val Loss = 113.07900
2023-09-02 10:06:06.941011 Epoch 6  	Train Loss = 14.61104 Val Loss = 113.07411
2023-09-02 10:06:20.133099 Epoch 7  	Train Loss = 14.67965 Val Loss = 113.04568
2023-09-02 10:06:33.366794 Epoch 8  	Train Loss = 14.45849 Val Loss = 113.02459
2023-09-02 10:06:46.602824 Epoch 9  	Train Loss = 14.36358 Val Loss = 112.99907
2023-09-02 10:06:59.802079 Epoch 10  	Train Loss = 14.28656 Val Loss = 113.02663
2023-09-02 10:07:13.062511 Epoch 11  	Train Loss = 14.24207 Val Loss = 113.02709
2023-09-02 10:07:26.279660 Epoch 12  	Train Loss = 14.35142 Val Loss = 113.07328
2023-09-02 10:07:39.610854 Epoch 13  	Train Loss = 14.05510 Val Loss = 112.98389
2023-09-02 10:07:52.946520 Epoch 14  	Train Loss = 13.98751 Val Loss = 112.99798
CL target length = 2
2023-09-02 10:08:06.282257 Epoch 15  	Train Loss = 16.11581 Val Loss = 104.39863
2023-09-02 10:08:19.614556 Epoch 16  	Train Loss = 14.74550 Val Loss = 104.03322
2023-09-02 10:08:32.921018 Epoch 17  	Train Loss = 14.60074 Val Loss = 104.09622
2023-09-02 10:08:46.195612 Epoch 18  	Train Loss = 14.45585 Val Loss = 104.02010
2023-09-02 10:08:59.491620 Epoch 19  	Train Loss = 14.35832 Val Loss = 104.01082
2023-09-02 10:09:12.859507 Epoch 20  	Train Loss = 14.22632 Val Loss = 104.01149
2023-09-02 10:09:26.240749 Epoch 21  	Train Loss = 14.21585 Val Loss = 104.00796
2023-09-02 10:09:39.604123 Epoch 22  	Train Loss = 14.21977 Val Loss = 104.02650
2023-09-02 10:09:53.023417 Epoch 23  	Train Loss = 14.09528 Val Loss = 103.98565
2023-09-02 10:10:06.417663 Epoch 24  	Train Loss = 14.22340 Val Loss = 103.96905
2023-09-02 10:10:19.783275 Epoch 25  	Train Loss = 14.02723 Val Loss = 104.03960
2023-09-02 10:10:33.220300 Epoch 26  	Train Loss = 13.99189 Val Loss = 103.98501
2023-09-02 10:10:46.646349 Epoch 27  	Train Loss = 14.09337 Val Loss = 104.01498
2023-09-02 10:11:00.084300 Epoch 28  	Train Loss = 13.91050 Val Loss = 103.98084
2023-09-02 10:11:13.496291 Epoch 29  	Train Loss = 13.88937 Val Loss = 103.93538
CL target length = 3
2023-09-02 10:11:26.858171 Epoch 30  	Train Loss = 15.46786 Val Loss = 95.14012
2023-09-02 10:11:40.244296 Epoch 31  	Train Loss = 14.39202 Val Loss = 95.06582
2023-09-02 10:11:53.621305 Epoch 32  	Train Loss = 14.27360 Val Loss = 95.06342
2023-09-02 10:12:06.932219 Epoch 33  	Train Loss = 14.24221 Val Loss = 95.08273
2023-09-02 10:12:20.365086 Epoch 34  	Train Loss = 14.25383 Val Loss = 95.08040
2023-09-02 10:12:33.834922 Epoch 35  	Train Loss = 14.17649 Val Loss = 95.01213
2023-09-02 10:12:47.409413 Epoch 36  	Train Loss = 14.08457 Val Loss = 95.01891
2023-09-02 10:13:00.811854 Epoch 37  	Train Loss = 14.05943 Val Loss = 95.13534
2023-09-02 10:13:14.379473 Epoch 38  	Train Loss = 14.05274 Val Loss = 95.04789
2023-09-02 10:13:27.927598 Epoch 39  	Train Loss = 14.08259 Val Loss = 95.22629
2023-09-02 10:13:41.426308 Epoch 40  	Train Loss = 14.11330 Val Loss = 95.00755
2023-09-02 10:13:55.034261 Epoch 41  	Train Loss = 13.99371 Val Loss = 95.00412
2023-09-02 10:14:08.457341 Epoch 42  	Train Loss = 13.92091 Val Loss = 95.08423
2023-09-02 10:14:21.923809 Epoch 43  	Train Loss = 13.95073 Val Loss = 94.95685
2023-09-02 10:14:35.460212 Epoch 44  	Train Loss = 13.91805 Val Loss = 95.07849
CL target length = 4
2023-09-02 10:14:48.828922 Epoch 45  	Train Loss = 15.12273 Val Loss = 86.07516
2023-09-02 10:15:02.231582 Epoch 46  	Train Loss = 14.25950 Val Loss = 86.11555
2023-09-02 10:15:15.631062 Epoch 47  	Train Loss = 14.31403 Val Loss = 86.04889
2023-09-02 10:15:29.186151 Epoch 48  	Train Loss = 14.15097 Val Loss = 86.11668
2023-09-02 10:15:42.651342 Epoch 49  	Train Loss = 14.13388 Val Loss = 86.12830
2023-09-02 10:15:56.089534 Epoch 50  	Train Loss = 14.08043 Val Loss = 86.04139
2023-09-02 10:16:09.559852 Epoch 51  	Train Loss = 14.09428 Val Loss = 86.07892
2023-09-02 10:16:22.946326 Epoch 52  	Train Loss = 14.03459 Val Loss = 86.17126
2023-09-02 10:16:36.380089 Epoch 53  	Train Loss = 14.10205 Val Loss = 86.11651
2023-09-02 10:16:49.775645 Epoch 54  	Train Loss = 14.01831 Val Loss = 85.99582
2023-09-02 10:17:03.195992 Epoch 55  	Train Loss = 13.98743 Val Loss = 86.02362
2023-09-02 10:17:16.633890 Epoch 56  	Train Loss = 13.96782 Val Loss = 86.15287
2023-09-02 10:17:30.030985 Epoch 57  	Train Loss = 13.92449 Val Loss = 86.01950
2023-09-02 10:17:43.393290 Epoch 58  	Train Loss = 13.96269 Val Loss = 86.13295
2023-09-02 10:17:56.806691 Epoch 59  	Train Loss = 13.94271 Val Loss = 86.19474
CL target length = 5
2023-09-02 10:18:10.275633 Epoch 60  	Train Loss = 15.04715 Val Loss = 77.33195
2023-09-02 10:18:23.700481 Epoch 61  	Train Loss = 14.23091 Val Loss = 77.15599
2023-09-02 10:18:37.152898 Epoch 62  	Train Loss = 14.18549 Val Loss = 77.17242
2023-09-02 10:18:50.612339 Epoch 63  	Train Loss = 14.22780 Val Loss = 77.09578
2023-09-02 10:19:04.955125 Epoch 64  	Train Loss = 14.09978 Val Loss = 77.18433
2023-09-02 10:19:19.674231 Epoch 65  	Train Loss = 14.11827 Val Loss = 77.23645
2023-09-02 10:19:34.395298 Epoch 66  	Train Loss = 14.11553 Val Loss = 77.07452
2023-09-02 10:19:49.120280 Epoch 67  	Train Loss = 14.12652 Val Loss = 77.14053
2023-09-02 10:20:03.845853 Epoch 68  	Train Loss = 14.07212 Val Loss = 77.19361
2023-09-02 10:20:18.563319 Epoch 69  	Train Loss = 14.06908 Val Loss = 77.16138
2023-09-02 10:20:33.290663 Epoch 70  	Train Loss = 14.04026 Val Loss = 77.05386
2023-09-02 10:20:48.015479 Epoch 71  	Train Loss = 14.01190 Val Loss = 77.08944
2023-09-02 10:21:02.748423 Epoch 72  	Train Loss = 14.03899 Val Loss = 77.13892
2023-09-02 10:21:17.479785 Epoch 73  	Train Loss = 14.03561 Val Loss = 77.17033
2023-09-02 10:21:29.630534 Epoch 74  	Train Loss = 14.00346 Val Loss = 77.20174
CL target length = 6
2023-09-02 10:21:40.891411 Epoch 75  	Train Loss = 15.02477 Val Loss = 68.40922
2023-09-02 10:21:52.155689 Epoch 76  	Train Loss = 14.26085 Val Loss = 68.23726
2023-09-02 10:22:03.416324 Epoch 77  	Train Loss = 14.24787 Val Loss = 68.32648
2023-09-02 10:22:14.677980 Epoch 78  	Train Loss = 14.21474 Val Loss = 68.23913
2023-09-02 10:22:25.940625 Epoch 79  	Train Loss = 14.17089 Val Loss = 68.27954
2023-09-02 10:22:37.205438 Epoch 80  	Train Loss = 14.12596 Val Loss = 68.26360
2023-09-02 10:22:48.471112 Epoch 81  	Train Loss = 14.16182 Val Loss = 68.32410
2023-09-02 10:22:59.726053 Epoch 82  	Train Loss = 14.12133 Val Loss = 68.25310
2023-09-02 10:23:10.981815 Epoch 83  	Train Loss = 14.15534 Val Loss = 68.23521
2023-09-02 10:23:22.244871 Epoch 84  	Train Loss = 14.09351 Val Loss = 68.23172
2023-09-02 10:23:33.522872 Epoch 85  	Train Loss = 14.07748 Val Loss = 68.24331
2023-09-02 10:23:44.827710 Epoch 86  	Train Loss = 14.09214 Val Loss = 68.33992
2023-09-02 10:23:56.177951 Epoch 87  	Train Loss = 14.05276 Val Loss = 68.30125
2023-09-02 10:24:07.535126 Epoch 88  	Train Loss = 14.03224 Val Loss = 68.32353
2023-09-02 10:24:18.910330 Epoch 89  	Train Loss = 14.07793 Val Loss = 68.33557
CL target length = 7
2023-09-02 10:24:30.290863 Epoch 90  	Train Loss = 14.92256 Val Loss = 59.49390
2023-09-02 10:24:41.678310 Epoch 91  	Train Loss = 14.25693 Val Loss = 59.37644
2023-09-02 10:24:53.095820 Epoch 92  	Train Loss = 14.29696 Val Loss = 59.54875
2023-09-02 10:25:04.503715 Epoch 93  	Train Loss = 14.22850 Val Loss = 59.51299
2023-09-02 10:25:15.915686 Epoch 94  	Train Loss = 14.22790 Val Loss = 59.48341
2023-09-02 10:25:27.340298 Epoch 95  	Train Loss = 14.19412 Val Loss = 59.40061
2023-09-02 10:25:38.757815 Epoch 96  	Train Loss = 14.19777 Val Loss = 59.36862
2023-09-02 10:25:50.182018 Epoch 97  	Train Loss = 14.20401 Val Loss = 59.42042
2023-09-02 10:26:01.608193 Epoch 98  	Train Loss = 14.15426 Val Loss = 59.37846
2023-09-02 10:26:13.048048 Epoch 99  	Train Loss = 14.11971 Val Loss = 59.71436
2023-09-02 10:26:24.480774 Epoch 100  	Train Loss = 14.14752 Val Loss = 59.48226
2023-09-02 10:26:35.919285 Epoch 101  	Train Loss = 14.15671 Val Loss = 59.41174
2023-09-02 10:26:47.357824 Epoch 102  	Train Loss = 14.12822 Val Loss = 59.48317
2023-09-02 10:26:58.793301 Epoch 103  	Train Loss = 14.12764 Val Loss = 59.41557
2023-09-02 10:27:10.227152 Epoch 104  	Train Loss = 14.09768 Val Loss = 59.48053
CL target length = 8
2023-09-02 10:27:21.659017 Epoch 105  	Train Loss = 14.97238 Val Loss = 50.68265
2023-09-02 10:27:33.103711 Epoch 106  	Train Loss = 14.29953 Val Loss = 50.71901
2023-09-02 10:27:44.540663 Epoch 107  	Train Loss = 14.26108 Val Loss = 50.60679
2023-09-02 10:27:55.972129 Epoch 108  	Train Loss = 14.28887 Val Loss = 50.66303
2023-09-02 10:28:07.404348 Epoch 109  	Train Loss = 14.25217 Val Loss = 50.64178
2023-09-02 10:28:18.826211 Epoch 110  	Train Loss = 14.23854 Val Loss = 50.89582
2023-09-02 10:28:30.240065 Epoch 111  	Train Loss = 14.22714 Val Loss = 50.59599
2023-09-02 10:28:41.659124 Epoch 112  	Train Loss = 14.26731 Val Loss = 50.54315
2023-09-02 10:28:53.062165 Epoch 113  	Train Loss = 14.18852 Val Loss = 50.78271
2023-09-02 10:29:04.462628 Epoch 114  	Train Loss = 14.21066 Val Loss = 50.70697
2023-09-02 10:29:15.851092 Epoch 115  	Train Loss = 14.17005 Val Loss = 50.70479
2023-09-02 10:29:27.231481 Epoch 116  	Train Loss = 14.17801 Val Loss = 50.65070
2023-09-02 10:29:38.608791 Epoch 117  	Train Loss = 14.16299 Val Loss = 50.73342
2023-09-02 10:29:49.985988 Epoch 118  	Train Loss = 14.16831 Val Loss = 50.81187
2023-09-02 10:30:01.360771 Epoch 119  	Train Loss = 14.15145 Val Loss = 50.62411
CL target length = 9
2023-09-02 10:30:12.730435 Epoch 120  	Train Loss = 14.94985 Val Loss = 42.05016
2023-09-02 10:30:24.092458 Epoch 121  	Train Loss = 14.33725 Val Loss = 41.93229
2023-09-02 10:30:35.452550 Epoch 122  	Train Loss = 14.31481 Val Loss = 41.86433
2023-09-02 10:30:46.808667 Epoch 123  	Train Loss = 14.28957 Val Loss = 41.89134
2023-09-02 10:30:58.163020 Epoch 124  	Train Loss = 14.26339 Val Loss = 41.87807
2023-09-02 10:31:09.518967 Epoch 125  	Train Loss = 14.26615 Val Loss = 41.84557
2023-09-02 10:31:20.864933 Epoch 126  	Train Loss = 14.27201 Val Loss = 41.97306
2023-09-02 10:31:32.210245 Epoch 127  	Train Loss = 14.24994 Val Loss = 41.96578
2023-09-02 10:31:43.556065 Epoch 128  	Train Loss = 14.24253 Val Loss = 42.06178
2023-09-02 10:31:54.894769 Epoch 129  	Train Loss = 14.23089 Val Loss = 41.94841
2023-09-02 10:32:08.247354 Epoch 130  	Train Loss = 14.20837 Val Loss = 41.87368
2023-09-02 10:32:22.985237 Epoch 131  	Train Loss = 14.22721 Val Loss = 42.07557
2023-09-02 10:32:37.703535 Epoch 132  	Train Loss = 14.21766 Val Loss = 41.99261
2023-09-02 10:32:52.421882 Epoch 133  	Train Loss = 14.19130 Val Loss = 41.95642
CL target length = 10
2023-09-02 10:33:07.143474 Epoch 134  	Train Loss = 14.66231 Val Loss = 33.88539
2023-09-02 10:33:21.868202 Epoch 135  	Train Loss = 14.49739 Val Loss = 33.08259
2023-09-02 10:33:36.594357 Epoch 136  	Train Loss = 14.33563 Val Loss = 33.14652
2023-09-02 10:33:51.312343 Epoch 137  	Train Loss = 14.32013 Val Loss = 33.11789
2023-09-02 10:34:06.030441 Epoch 138  	Train Loss = 14.32526 Val Loss = 33.27023
2023-09-02 10:34:20.744149 Epoch 139  	Train Loss = 14.29314 Val Loss = 33.58856
2023-09-02 10:34:35.458266 Epoch 140  	Train Loss = 14.30362 Val Loss = 33.23267
2023-09-02 10:34:50.177527 Epoch 141  	Train Loss = 14.31851 Val Loss = 33.29651
2023-09-02 10:35:04.901042 Epoch 142  	Train Loss = 14.30564 Val Loss = 33.15414
2023-09-02 10:35:19.630661 Epoch 143  	Train Loss = 14.27163 Val Loss = 33.23472
2023-09-02 10:35:34.365825 Epoch 144  	Train Loss = 14.24926 Val Loss = 33.22713
2023-09-02 10:35:49.098556 Epoch 145  	Train Loss = 14.28152 Val Loss = 33.19882
2023-09-02 10:36:03.831872 Epoch 146  	Train Loss = 14.30512 Val Loss = 33.44399
2023-09-02 10:36:18.563767 Epoch 147  	Train Loss = 14.23586 Val Loss = 33.62990
2023-09-02 10:36:33.296735 Epoch 148  	Train Loss = 14.28527 Val Loss = 33.27400
CL target length = 11
2023-09-02 10:36:48.023617 Epoch 149  	Train Loss = 14.75684 Val Loss = 24.83081
2023-09-02 10:37:02.752054 Epoch 150  	Train Loss = 14.42193 Val Loss = 24.50605
2023-09-02 10:37:17.479488 Epoch 151  	Train Loss = 14.36560 Val Loss = 24.46291
2023-09-02 10:37:32.200003 Epoch 152  	Train Loss = 14.40125 Val Loss = 24.45837
2023-09-02 10:37:46.924691 Epoch 153  	Train Loss = 14.33019 Val Loss = 24.51064
2023-09-02 10:38:01.644379 Epoch 154  	Train Loss = 14.35577 Val Loss = 24.36760
2023-09-02 10:38:16.359766 Epoch 155  	Train Loss = 14.31333 Val Loss = 24.70863
2023-09-02 10:38:31.069397 Epoch 156  	Train Loss = 14.29871 Val Loss = 24.52283
2023-09-02 10:38:45.789045 Epoch 157  	Train Loss = 14.29327 Val Loss = 24.46070
2023-09-02 10:39:00.520335 Epoch 158  	Train Loss = 14.27872 Val Loss = 24.58719
2023-09-02 10:39:15.242512 Epoch 159  	Train Loss = 14.25214 Val Loss = 24.77785
2023-09-02 10:39:29.963662 Epoch 160  	Train Loss = 14.26381 Val Loss = 24.67756
2023-09-02 10:39:44.676608 Epoch 161  	Train Loss = 14.25467 Val Loss = 24.61115
2023-09-02 10:39:59.400902 Epoch 162  	Train Loss = 14.25315 Val Loss = 24.32749
2023-09-02 10:40:14.132711 Epoch 163  	Train Loss = 14.25213 Val Loss = 24.46146
CL target length = 12
2023-09-02 10:40:28.855210 Epoch 164  	Train Loss = 14.81224 Val Loss = 15.88037
2023-09-02 10:40:43.570848 Epoch 165  	Train Loss = 14.38196 Val Loss = 15.66197
2023-09-02 10:40:58.293826 Epoch 166  	Train Loss = 14.35423 Val Loss = 15.99677
2023-09-02 10:41:13.016063 Epoch 167  	Train Loss = 14.33885 Val Loss = 15.80494
2023-09-02 10:41:27.747144 Epoch 168  	Train Loss = 14.30109 Val Loss = 15.79538
2023-09-02 10:41:42.485336 Epoch 169  	Train Loss = 14.09831 Val Loss = 15.56661
2023-09-02 10:41:57.223880 Epoch 170  	Train Loss = 14.05734 Val Loss = 15.53931
2023-09-02 10:42:11.957171 Epoch 171  	Train Loss = 14.04795 Val Loss = 15.58668
2023-09-02 10:42:26.680051 Epoch 172  	Train Loss = 14.03340 Val Loss = 15.58665
2023-09-02 10:42:41.405480 Epoch 173  	Train Loss = 14.02459 Val Loss = 15.58288
2023-09-02 10:42:56.122045 Epoch 174  	Train Loss = 14.03494 Val Loss = 15.62358
2023-09-02 10:43:10.847575 Epoch 175  	Train Loss = 14.03286 Val Loss = 15.59051
2023-09-02 10:43:25.568678 Epoch 176  	Train Loss = 14.01686 Val Loss = 15.58718
2023-09-02 10:43:40.294606 Epoch 177  	Train Loss = 14.01727 Val Loss = 15.58970
2023-09-02 10:43:54.067065 Epoch 178  	Train Loss = 14.01801 Val Loss = 15.54472
2023-09-02 10:44:07.357690 Epoch 179  	Train Loss = 14.01223 Val Loss = 15.57103
2023-09-02 10:44:20.615396 Epoch 180  	Train Loss = 14.00991 Val Loss = 15.64693
2023-09-02 10:44:33.943566 Epoch 181  	Train Loss = 14.00316 Val Loss = 15.60552
2023-09-02 10:44:47.633770 Epoch 182  	Train Loss = 13.99096 Val Loss = 15.59590
2023-09-02 10:45:01.012589 Epoch 183  	Train Loss = 14.00175 Val Loss = 15.58885
2023-09-02 10:45:14.377444 Epoch 184  	Train Loss = 14.00227 Val Loss = 15.59319
2023-09-02 10:45:27.944939 Epoch 185  	Train Loss = 13.99150 Val Loss = 15.54799
Early stopping at epoch: 185
Best at epoch 170:
Train Loss = 14.05734
Train RMSE = 22.98016, MAE = 13.72548, MAPE = 8.91799
Val Loss = 15.53931
Val RMSE = 25.89305, MAE = 15.54783, MAPE = 13.83171
--------- Test ---------
All Steps RMSE = 24.59075, MAE = 15.38391, MAPE = 9.80112
Step 1 RMSE = 20.02125, MAE = 12.98075, MAPE = 8.38417
Step 2 RMSE = 21.29007, MAE = 13.60644, MAPE = 8.86455
Step 3 RMSE = 22.29177, MAE = 14.15754, MAPE = 9.18216
Step 4 RMSE = 23.22504, MAE = 14.62418, MAPE = 9.43214
Step 5 RMSE = 24.02231, MAE = 15.04396, MAPE = 9.58156
Step 6 RMSE = 24.65878, MAE = 15.38259, MAPE = 9.83422
Step 7 RMSE = 25.22228, MAE = 15.73061, MAPE = 9.91757
Step 8 RMSE = 25.75158, MAE = 16.05810, MAPE = 10.11246
Step 9 RMSE = 26.20500, MAE = 16.33086, MAPE = 10.30609
Step 10 RMSE = 26.61781, MAE = 16.58112, MAPE = 10.49082
Step 11 RMSE = 27.02410, MAE = 16.88136, MAPE = 10.69979
Step 12 RMSE = 27.49700, MAE = 17.22946, MAPE = 10.80799
Inference time: 1.20 s
