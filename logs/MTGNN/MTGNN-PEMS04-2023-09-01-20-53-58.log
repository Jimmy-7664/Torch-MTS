PEMS04
Trainset:	x-(10181, 12, 307, 1)	y-(10181, 12, 307, 1)
Valset:  	x-(3394, 12, 307, 1)  	y-(3394, 12, 307, 1)
Testset:	x-(3394, 12, 307, 1)	y-(3394, 12, 307, 1)

--------- MTGNN ---------
{
    "num_nodes": 307,
    "in_steps": 12,
    "out_steps": 12,
    "train_size": 0.6,
    "val_size": 0.2,
    "lr": 0.001,
    "weight_decay": 0.0001,
    "milestones": [
        175
    ],
    "early_stop": 15,
    "clip_grad": 5,
    "batch_size": 64,
    "max_epochs": 500,
    "use_cl": true,
    "cl_step_size": 2500,
    "pass_device": true,
    "model_args": {
        "num_nodes": 307,
        "in_dim": 1,
        "seq_length": 12,
        "out_dim": 12,
        "device": "cuda:0",
        "gcn_true": true,
        "buildA_true": true,
        "gcn_depth": 2,
        "predefined_A": null,
        "static_feat": null,
        "dropout": 0.3,
        "subgraph_size": 20,
        "node_dim": 40,
        "dilation_exponential": 1,
        "conv_channels": 32,
        "residual_channels": 32,
        "skip_channels": 64,
        "end_channels": 128,
        "layers": 3,
        "propalpha": 0.05,
        "tanhalpha": 3,
        "layer_norm_affline": true
    }
}
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
MTGNN                                    [64, 12, 307, 1]          3,168
├─graph_constructor: 1-1                 [307, 307]                --
│    └─Embedding: 2-1                    [307, 40]                 12,280
│    └─Embedding: 2-2                    [307, 40]                 12,280
│    └─Linear: 2-3                       [307, 40]                 1,640
│    └─Linear: 2-4                       [307, 40]                 1,640
├─Conv2d: 1-2                            [64, 32, 307, 19]         64
├─Conv2d: 1-3                            [64, 64, 307, 1]          1,280
├─ModuleList: 1-16                       --                        (recursive)
│    └─dilated_inception: 2-5            [64, 32, 307, 13]         --
│    │    └─ModuleList: 3-1              --                        4,640
├─ModuleList: 1-17                       --                        (recursive)
│    └─dilated_inception: 2-6            [64, 32, 307, 13]         --
│    │    └─ModuleList: 3-2              --                        4,640
├─ModuleList: 1-18                       --                        (recursive)
│    └─Conv2d: 2-7                       [64, 64, 307, 1]          26,688
├─ModuleList: 1-19                       --                        (recursive)
│    └─mixprop: 2-8                      [64, 32, 307, 13]         --
│    │    └─nconv: 3-3                   [64, 32, 307, 13]         --
│    │    └─nconv: 3-4                   [64, 32, 307, 13]         --
│    │    └─linear: 3-5                  [64, 32, 307, 13]         3,104
├─ModuleList: 1-20                       --                        (recursive)
│    └─mixprop: 2-9                      [64, 32, 307, 13]         --
│    │    └─nconv: 3-6                   [64, 32, 307, 13]         --
│    │    └─nconv: 3-7                   [64, 32, 307, 13]         --
│    │    └─linear: 3-8                  [64, 32, 307, 13]         3,104
├─ModuleList: 1-21                       --                        (recursive)
│    └─LayerNorm: 2-10                   [64, 32, 307, 13]         255,424
├─ModuleList: 1-16                       --                        (recursive)
│    └─dilated_inception: 2-11           [64, 32, 307, 7]          --
│    │    └─ModuleList: 3-9              --                        4,640
├─ModuleList: 1-17                       --                        (recursive)
│    └─dilated_inception: 2-12           [64, 32, 307, 7]          --
│    │    └─ModuleList: 3-10             --                        4,640
├─ModuleList: 1-18                       --                        (recursive)
│    └─Conv2d: 2-13                      [64, 64, 307, 1]          14,400
├─ModuleList: 1-19                       --                        (recursive)
│    └─mixprop: 2-14                     [64, 32, 307, 7]          --
│    │    └─nconv: 3-11                  [64, 32, 307, 7]          --
│    │    └─nconv: 3-12                  [64, 32, 307, 7]          --
│    │    └─linear: 3-13                 [64, 32, 307, 7]          3,104
├─ModuleList: 1-20                       --                        (recursive)
│    └─mixprop: 2-15                     [64, 32, 307, 7]          --
│    │    └─nconv: 3-14                  [64, 32, 307, 7]          --
│    │    └─nconv: 3-15                  [64, 32, 307, 7]          --
│    │    └─linear: 3-16                 [64, 32, 307, 7]          3,104
├─ModuleList: 1-21                       --                        (recursive)
│    └─LayerNorm: 2-16                   [64, 32, 307, 7]          137,536
├─ModuleList: 1-16                       --                        (recursive)
│    └─dilated_inception: 2-17           [64, 32, 307, 1]          --
│    │    └─ModuleList: 3-17             --                        4,640
├─ModuleList: 1-17                       --                        (recursive)
│    └─dilated_inception: 2-18           [64, 32, 307, 1]          --
│    │    └─ModuleList: 3-18             --                        4,640
├─ModuleList: 1-18                       --                        (recursive)
│    └─Conv2d: 2-19                      [64, 64, 307, 1]          2,112
├─ModuleList: 1-19                       --                        (recursive)
│    └─mixprop: 2-20                     [64, 32, 307, 1]          --
│    │    └─nconv: 3-19                  [64, 32, 307, 1]          --
│    │    └─nconv: 3-20                  [64, 32, 307, 1]          --
│    │    └─linear: 3-21                 [64, 32, 307, 1]          3,104
├─ModuleList: 1-20                       --                        (recursive)
│    └─mixprop: 2-21                     [64, 32, 307, 1]          --
│    │    └─nconv: 3-22                  [64, 32, 307, 1]          --
│    │    └─nconv: 3-23                  [64, 32, 307, 1]          --
│    │    └─linear: 3-24                 [64, 32, 307, 1]          3,104
├─ModuleList: 1-21                       --                        (recursive)
│    └─LayerNorm: 2-22                   [64, 32, 307, 1]          19,648
├─Conv2d: 1-22                           [64, 64, 307, 1]          2,112
├─Conv2d: 1-23                           [64, 128, 307, 1]         8,320
├─Conv2d: 1-24                           [64, 12, 307, 1]          1,548
==========================================================================================
Total params: 546,604
Trainable params: 546,604
Non-trainable params: 0
Total mult-adds (G): 8.41
==========================================================================================
Input size (MB): 0.94
Forward/backward pass size (MB): 771.85
Params size (MB): 2.17
Estimated Total Size (MB): 774.97
==========================================================================================

Loss: HuberLoss

CL target length = 1
2023-09-01 20:54:20.668825 Epoch 1  	Train Loss = 22.60640 Val Loss = 123.48250
2023-09-01 20:54:40.453397 Epoch 2  	Train Loss = 18.33380 Val Loss = 123.43871
2023-09-01 20:55:00.869399 Epoch 3  	Train Loss = 18.07608 Val Loss = 123.34189
2023-09-01 20:55:21.328057 Epoch 4  	Train Loss = 17.87633 Val Loss = 123.31539
2023-09-01 20:55:41.846825 Epoch 5  	Train Loss = 17.53475 Val Loss = 123.29701
2023-09-01 20:56:02.280494 Epoch 6  	Train Loss = 17.46901 Val Loss = 123.35063
2023-09-01 20:56:22.788253 Epoch 7  	Train Loss = 17.44855 Val Loss = 123.34614
2023-09-01 20:56:43.278173 Epoch 8  	Train Loss = 17.45777 Val Loss = 123.38146
2023-09-01 20:57:03.808160 Epoch 9  	Train Loss = 17.18773 Val Loss = 123.33109
2023-09-01 20:57:24.432547 Epoch 10  	Train Loss = 17.23475 Val Loss = 123.29490
2023-09-01 20:57:45.016932 Epoch 11  	Train Loss = 17.17308 Val Loss = 123.28715
2023-09-01 20:58:05.609098 Epoch 12  	Train Loss = 17.20490 Val Loss = 123.28495
2023-09-01 20:58:26.202120 Epoch 13  	Train Loss = 17.16311 Val Loss = 123.31366
2023-09-01 20:58:46.779528 Epoch 14  	Train Loss = 16.93872 Val Loss = 123.27588
2023-09-01 20:59:07.008900 Epoch 15  	Train Loss = 16.90298 Val Loss = 123.33558
CL target length = 2
2023-09-01 20:59:27.389788 Epoch 16  	Train Loss = 19.74995 Val Loss = 113.77538
2023-09-01 20:59:47.989509 Epoch 17  	Train Loss = 17.55481 Val Loss = 113.66838
2023-09-01 21:00:08.559395 Epoch 18  	Train Loss = 17.45783 Val Loss = 113.81423
2023-09-01 21:00:29.145165 Epoch 19  	Train Loss = 17.33996 Val Loss = 113.73204
2023-09-01 21:00:49.519266 Epoch 20  	Train Loss = 17.16006 Val Loss = 113.71034
2023-09-01 21:01:10.167501 Epoch 21  	Train Loss = 17.11775 Val Loss = 113.68198
2023-09-01 21:01:30.654608 Epoch 22  	Train Loss = 16.97034 Val Loss = 113.63876
2023-09-01 21:01:51.151799 Epoch 23  	Train Loss = 17.02404 Val Loss = 113.62702
2023-09-01 21:02:11.644458 Epoch 24  	Train Loss = 16.94012 Val Loss = 113.68048
2023-09-01 21:02:32.182925 Epoch 25  	Train Loss = 17.00496 Val Loss = 113.63420
2023-09-01 21:02:52.782002 Epoch 26  	Train Loss = 16.83289 Val Loss = 113.62471
2023-09-01 21:03:13.366558 Epoch 27  	Train Loss = 16.84707 Val Loss = 113.62299
2023-09-01 21:03:33.819161 Epoch 28  	Train Loss = 16.75377 Val Loss = 113.60498
2023-09-01 21:03:54.445790 Epoch 29  	Train Loss = 16.73113 Val Loss = 113.60377
2023-09-01 21:04:15.106319 Epoch 30  	Train Loss = 16.78588 Val Loss = 113.64132
2023-09-01 21:04:35.701396 Epoch 31  	Train Loss = 16.71211 Val Loss = 113.63709
CL target length = 3
2023-09-01 21:04:56.307913 Epoch 32  	Train Loss = 18.72089 Val Loss = 104.02662
2023-09-01 21:05:16.815664 Epoch 33  	Train Loss = 17.10803 Val Loss = 104.05755
2023-09-01 21:05:37.373806 Epoch 34  	Train Loss = 17.00858 Val Loss = 104.00015
2023-09-01 21:05:58.050828 Epoch 35  	Train Loss = 16.95967 Val Loss = 104.09766
2023-09-01 21:06:18.646419 Epoch 36  	Train Loss = 16.97904 Val Loss = 104.09146
2023-09-01 21:06:39.263336 Epoch 37  	Train Loss = 16.98739 Val Loss = 103.98009
2023-09-01 21:06:59.881135 Epoch 38  	Train Loss = 16.89971 Val Loss = 103.98293
2023-09-01 21:07:20.483304 Epoch 39  	Train Loss = 16.91998 Val Loss = 104.04832
2023-09-01 21:07:41.128328 Epoch 40  	Train Loss = 16.84419 Val Loss = 104.01609
2023-09-01 21:08:01.774521 Epoch 41  	Train Loss = 16.77358 Val Loss = 103.99833
2023-09-01 21:08:22.483626 Epoch 42  	Train Loss = 16.78132 Val Loss = 104.00748
2023-09-01 21:08:43.224474 Epoch 43  	Train Loss = 16.77875 Val Loss = 103.95687
2023-09-01 21:09:03.966869 Epoch 44  	Train Loss = 16.79601 Val Loss = 103.96577
2023-09-01 21:09:24.648891 Epoch 45  	Train Loss = 16.75030 Val Loss = 103.94168
2023-09-01 21:09:45.327178 Epoch 46  	Train Loss = 16.70866 Val Loss = 103.99719
CL target length = 4
2023-09-01 21:10:06.032362 Epoch 47  	Train Loss = 17.95278 Val Loss = 95.17514
2023-09-01 21:10:26.747361 Epoch 48  	Train Loss = 17.12637 Val Loss = 94.44946
2023-09-01 21:10:47.465443 Epoch 49  	Train Loss = 17.01150 Val Loss = 94.38013
2023-09-01 21:11:08.208687 Epoch 50  	Train Loss = 16.98969 Val Loss = 94.53064
2023-09-01 21:11:29.012651 Epoch 51  	Train Loss = 16.97498 Val Loss = 94.41322
2023-09-01 21:11:49.700323 Epoch 52  	Train Loss = 16.90941 Val Loss = 94.37426
2023-09-01 21:12:10.429725 Epoch 53  	Train Loss = 16.89846 Val Loss = 94.40755
2023-09-01 21:12:31.080139 Epoch 54  	Train Loss = 16.91680 Val Loss = 94.41182
2023-09-01 21:12:51.567613 Epoch 55  	Train Loss = 16.82577 Val Loss = 94.33797
2023-09-01 21:13:11.893272 Epoch 56  	Train Loss = 16.86823 Val Loss = 94.40714
2023-09-01 21:13:32.586457 Epoch 57  	Train Loss = 16.84906 Val Loss = 94.42307
2023-09-01 21:13:53.272296 Epoch 58  	Train Loss = 16.86165 Val Loss = 94.42432
2023-09-01 21:14:13.928983 Epoch 59  	Train Loss = 16.81090 Val Loss = 94.62999
2023-09-01 21:14:34.537332 Epoch 60  	Train Loss = 16.80010 Val Loss = 94.36903
2023-09-01 21:14:55.230749 Epoch 61  	Train Loss = 16.74953 Val Loss = 94.39052
2023-09-01 21:15:15.871231 Epoch 62  	Train Loss = 16.77293 Val Loss = 94.31983
CL target length = 5
2023-09-01 21:15:36.568301 Epoch 63  	Train Loss = 17.93460 Val Loss = 84.91329
2023-09-01 21:15:57.290446 Epoch 64  	Train Loss = 17.08981 Val Loss = 84.86648
2023-09-01 21:16:17.944713 Epoch 65  	Train Loss = 17.01561 Val Loss = 84.80995
2023-09-01 21:16:38.581642 Epoch 66  	Train Loss = 16.96002 Val Loss = 84.81194
2023-09-01 21:16:58.889901 Epoch 67  	Train Loss = 16.94691 Val Loss = 84.83082
2023-09-01 21:17:19.531523 Epoch 68  	Train Loss = 16.89002 Val Loss = 84.85825
2023-09-01 21:17:40.152234 Epoch 69  	Train Loss = 16.92375 Val Loss = 84.79476
2023-09-01 21:18:00.865984 Epoch 70  	Train Loss = 16.86915 Val Loss = 84.75038
2023-09-01 21:18:21.251574 Epoch 71  	Train Loss = 16.87029 Val Loss = 84.89491
2023-09-01 21:18:41.920880 Epoch 72  	Train Loss = 16.89411 Val Loss = 84.76878
2023-09-01 21:19:02.582577 Epoch 73  	Train Loss = 16.89340 Val Loss = 84.93274
2023-09-01 21:19:23.168812 Epoch 74  	Train Loss = 16.84132 Val Loss = 84.90876
2023-09-01 21:19:43.711102 Epoch 75  	Train Loss = 16.86496 Val Loss = 84.89779
2023-09-01 21:20:04.232237 Epoch 76  	Train Loss = 16.80151 Val Loss = 84.79639
2023-09-01 21:20:24.777162 Epoch 77  	Train Loss = 16.84571 Val Loss = 84.82368
2023-09-01 21:20:45.385150 Epoch 78  	Train Loss = 16.80122 Val Loss = 84.75580
CL target length = 6
2023-09-01 21:21:06.054672 Epoch 79  	Train Loss = 17.89195 Val Loss = 75.36828
2023-09-01 21:21:26.682513 Epoch 80  	Train Loss = 17.04555 Val Loss = 75.23943
2023-09-01 21:21:47.324897 Epoch 81  	Train Loss = 17.07500 Val Loss = 75.63548
2023-09-01 21:22:07.983765 Epoch 82  	Train Loss = 17.07293 Val Loss = 75.31772
2023-09-01 21:22:28.599605 Epoch 83  	Train Loss = 16.99490 Val Loss = 75.25494
2023-09-01 21:22:49.255391 Epoch 84  	Train Loss = 16.93029 Val Loss = 75.58942
2023-09-01 21:23:09.969172 Epoch 85  	Train Loss = 16.97588 Val Loss = 75.20712
2023-09-01 21:23:30.725295 Epoch 86  	Train Loss = 16.94436 Val Loss = 75.23156
2023-09-01 21:23:51.461233 Epoch 87  	Train Loss = 16.92332 Val Loss = 75.32822
2023-09-01 21:24:11.877927 Epoch 88  	Train Loss = 16.89416 Val Loss = 75.20946
2023-09-01 21:24:32.441574 Epoch 89  	Train Loss = 16.88139 Val Loss = 75.26551
2023-09-01 21:24:53.048728 Epoch 90  	Train Loss = 16.85329 Val Loss = 75.18799
2023-09-01 21:25:13.635238 Epoch 91  	Train Loss = 16.87745 Val Loss = 75.23926
2023-09-01 21:25:34.327851 Epoch 92  	Train Loss = 16.82735 Val Loss = 75.40038
2023-09-01 21:25:55.001029 Epoch 93  	Train Loss = 16.86540 Val Loss = 75.26983
CL target length = 7
2023-09-01 21:26:15.353127 Epoch 94  	Train Loss = 17.70541 Val Loss = 65.91038
2023-09-01 21:26:36.061457 Epoch 95  	Train Loss = 17.12901 Val Loss = 65.80983
2023-09-01 21:26:56.714106 Epoch 96  	Train Loss = 17.07278 Val Loss = 65.87142
2023-09-01 21:27:17.375914 Epoch 97  	Train Loss = 17.08856 Val Loss = 65.84484
2023-09-01 21:27:38.017555 Epoch 98  	Train Loss = 17.03868 Val Loss = 65.78035
2023-09-01 21:27:58.643765 Epoch 99  	Train Loss = 17.02163 Val Loss = 65.84041
2023-09-01 21:28:19.302615 Epoch 100  	Train Loss = 17.00621 Val Loss = 65.68935
2023-09-01 21:28:39.902925 Epoch 101  	Train Loss = 17.03093 Val Loss = 65.79806
2023-09-01 21:29:00.550862 Epoch 102  	Train Loss = 17.00012 Val Loss = 65.77862
2023-09-01 21:29:20.945406 Epoch 103  	Train Loss = 16.99949 Val Loss = 65.82897
2023-09-01 21:29:41.605031 Epoch 104  	Train Loss = 16.98412 Val Loss = 65.69349
2023-09-01 21:30:02.292307 Epoch 105  	Train Loss = 16.92167 Val Loss = 65.67040
2023-09-01 21:30:22.980257 Epoch 106  	Train Loss = 16.87975 Val Loss = 65.91044
2023-09-01 21:30:43.577620 Epoch 107  	Train Loss = 16.91574 Val Loss = 65.71304
2023-09-01 21:31:04.199412 Epoch 108  	Train Loss = 16.88077 Val Loss = 65.74560
2023-09-01 21:31:24.812886 Epoch 109  	Train Loss = 16.93999 Val Loss = 65.81373
CL target length = 8
2023-09-01 21:31:45.416241 Epoch 110  	Train Loss = 17.73296 Val Loss = 56.26026
2023-09-01 21:32:06.117971 Epoch 111  	Train Loss = 17.10461 Val Loss = 56.21151
2023-09-01 21:32:26.477300 Epoch 112  	Train Loss = 17.11142 Val Loss = 56.33249
2023-09-01 21:32:47.154317 Epoch 113  	Train Loss = 17.11700 Val Loss = 56.66378
2023-09-01 21:33:07.767303 Epoch 114  	Train Loss = 17.09809 Val Loss = 56.24829
2023-09-01 21:33:28.378673 Epoch 115  	Train Loss = 17.01621 Val Loss = 56.32104
2023-09-01 21:33:49.016962 Epoch 116  	Train Loss = 17.03603 Val Loss = 56.29046
2023-09-01 21:34:09.609090 Epoch 117  	Train Loss = 16.98532 Val Loss = 56.22354
2023-09-01 21:34:30.273080 Epoch 118  	Train Loss = 17.03836 Val Loss = 56.35537
2023-09-01 21:34:50.885011 Epoch 119  	Train Loss = 17.00516 Val Loss = 56.27174
2023-09-01 21:35:11.510800 Epoch 120  	Train Loss = 16.96327 Val Loss = 56.18456
2023-09-01 21:35:32.182636 Epoch 121  	Train Loss = 17.03253 Val Loss = 56.58575
2023-09-01 21:35:52.853008 Epoch 122  	Train Loss = 16.99830 Val Loss = 56.20027
2023-09-01 21:36:13.539886 Epoch 123  	Train Loss = 16.94098 Val Loss = 56.43660
2023-09-01 21:36:34.166360 Epoch 124  	Train Loss = 16.94398 Val Loss = 56.16987
2023-09-01 21:36:54.859334 Epoch 125  	Train Loss = 16.97853 Val Loss = 56.30116
CL target length = 9
2023-09-01 21:37:15.536119 Epoch 126  	Train Loss = 17.81281 Val Loss = 46.81222
2023-09-01 21:37:36.127225 Epoch 127  	Train Loss = 17.13630 Val Loss = 46.71653
2023-09-01 21:37:56.759532 Epoch 128  	Train Loss = 17.05206 Val Loss = 46.85362
2023-09-01 21:38:17.464894 Epoch 129  	Train Loss = 17.11980 Val Loss = 47.09721
2023-09-01 21:38:38.137125 Epoch 130  	Train Loss = 17.10629 Val Loss = 46.83153
2023-09-01 21:38:58.828084 Epoch 131  	Train Loss = 17.04603 Val Loss = 46.86059
2023-09-01 21:39:19.750295 Epoch 132  	Train Loss = 17.09316 Val Loss = 46.86925
2023-09-01 21:39:40.436666 Epoch 133  	Train Loss = 17.02534 Val Loss = 46.64545
2023-09-01 21:40:01.076697 Epoch 134  	Train Loss = 17.01030 Val Loss = 46.71948
2023-09-01 21:40:21.712351 Epoch 135  	Train Loss = 17.04916 Val Loss = 46.74483
2023-09-01 21:40:42.338049 Epoch 136  	Train Loss = 17.03203 Val Loss = 46.67697
2023-09-01 21:41:02.983739 Epoch 137  	Train Loss = 17.02221 Val Loss = 46.89745
2023-09-01 21:41:23.640254 Epoch 138  	Train Loss = 17.03977 Val Loss = 46.99820
2023-09-01 21:41:44.397546 Epoch 139  	Train Loss = 17.00461 Val Loss = 46.70586
2023-09-01 21:42:05.179589 Epoch 140  	Train Loss = 16.97171 Val Loss = 46.78379
CL target length = 10
2023-09-01 21:42:25.803597 Epoch 141  	Train Loss = 17.71611 Val Loss = 37.40244
2023-09-01 21:42:46.524419 Epoch 142  	Train Loss = 17.16110 Val Loss = 37.75023
2023-09-01 21:43:07.357680 Epoch 143  	Train Loss = 17.11139 Val Loss = 37.29596
2023-09-01 21:43:28.202557 Epoch 144  	Train Loss = 17.12163 Val Loss = 37.58270
2023-09-01 21:43:48.835750 Epoch 145  	Train Loss = 17.09709 Val Loss = 37.32359
2023-09-01 21:44:09.441082 Epoch 146  	Train Loss = 17.08863 Val Loss = 37.23741
2023-09-01 21:44:30.030421 Epoch 147  	Train Loss = 17.13935 Val Loss = 37.57657
2023-09-01 21:44:50.465300 Epoch 148  	Train Loss = 17.06416 Val Loss = 37.29762
2023-09-01 21:45:11.177144 Epoch 149  	Train Loss = 17.03150 Val Loss = 37.18577
2023-09-01 21:45:31.820712 Epoch 150  	Train Loss = 17.06246 Val Loss = 37.27860
2023-09-01 21:45:52.464298 Epoch 151  	Train Loss = 17.04725 Val Loss = 37.14881
2023-09-01 21:46:13.081955 Epoch 152  	Train Loss = 17.02776 Val Loss = 37.21229
2023-09-01 21:46:33.749838 Epoch 153  	Train Loss = 17.02862 Val Loss = 37.32532
2023-09-01 21:46:54.412535 Epoch 154  	Train Loss = 17.04250 Val Loss = 37.21748
2023-09-01 21:47:14.756645 Epoch 155  	Train Loss = 17.03533 Val Loss = 37.29730
2023-09-01 21:47:35.360800 Epoch 156  	Train Loss = 16.99058 Val Loss = 37.89058
CL target length = 11
2023-09-01 21:47:56.045649 Epoch 157  	Train Loss = 17.75689 Val Loss = 28.13958
2023-09-01 21:48:16.655460 Epoch 158  	Train Loss = 17.17099 Val Loss = 27.80320
2023-09-01 21:48:37.327214 Epoch 159  	Train Loss = 17.14531 Val Loss = 27.88483
2023-09-01 21:48:57.746177 Epoch 160  	Train Loss = 17.10188 Val Loss = 27.78920
2023-09-01 21:49:18.218658 Epoch 161  	Train Loss = 17.16194 Val Loss = 27.88029
2023-09-01 21:49:38.663439 Epoch 162  	Train Loss = 17.10415 Val Loss = 27.76791
2023-09-01 21:49:59.220597 Epoch 163  	Train Loss = 17.11884 Val Loss = 27.78006
2023-09-01 21:50:19.871168 Epoch 164  	Train Loss = 17.05852 Val Loss = 28.08449
2023-09-01 21:50:39.951990 Epoch 165  	Train Loss = 17.09654 Val Loss = 27.75590
2023-09-01 21:51:00.598345 Epoch 166  	Train Loss = 17.07813 Val Loss = 27.75368
2023-09-01 21:51:21.245771 Epoch 167  	Train Loss = 17.07857 Val Loss = 28.36010
2023-09-01 21:51:41.913320 Epoch 168  	Train Loss = 17.08535 Val Loss = 28.00799
2023-09-01 21:52:02.576358 Epoch 169  	Train Loss = 17.03765 Val Loss = 27.76503
2023-09-01 21:52:23.115087 Epoch 170  	Train Loss = 17.05906 Val Loss = 27.75621
2023-09-01 21:52:43.428204 Epoch 171  	Train Loss = 17.08836 Val Loss = 28.24184
CL target length = 12
2023-09-01 21:53:03.996325 Epoch 172  	Train Loss = 17.57200 Val Loss = 20.29555
2023-09-01 21:53:24.646440 Epoch 173  	Train Loss = 17.27097 Val Loss = 18.50777
2023-09-01 21:53:45.280237 Epoch 174  	Train Loss = 17.12655 Val Loss = 18.79733
2023-09-01 21:54:05.885622 Epoch 175  	Train Loss = 17.18370 Val Loss = 18.31124
2023-09-01 21:54:26.504911 Epoch 176  	Train Loss = 16.91273 Val Loss = 18.27838
2023-09-01 21:54:47.117891 Epoch 177  	Train Loss = 16.87929 Val Loss = 18.17121
2023-09-01 21:55:07.734932 Epoch 178  	Train Loss = 16.87160 Val Loss = 18.19762
2023-09-01 21:55:28.374680 Epoch 179  	Train Loss = 16.85460 Val Loss = 18.16524
2023-09-01 21:55:48.978766 Epoch 180  	Train Loss = 16.84948 Val Loss = 18.13112
2023-09-01 21:56:09.591454 Epoch 181  	Train Loss = 16.85591 Val Loss = 18.13353
2023-09-01 21:56:30.170019 Epoch 182  	Train Loss = 16.83160 Val Loss = 18.16696
2023-09-01 21:56:50.776112 Epoch 183  	Train Loss = 16.84388 Val Loss = 18.19407
2023-09-01 21:57:11.391435 Epoch 184  	Train Loss = 16.83717 Val Loss = 18.14637
2023-09-01 21:57:32.009348 Epoch 185  	Train Loss = 16.83269 Val Loss = 18.19578
2023-09-01 21:57:52.623810 Epoch 186  	Train Loss = 16.82550 Val Loss = 18.13393
2023-09-01 21:58:13.235994 Epoch 187  	Train Loss = 16.81427 Val Loss = 18.13321
2023-09-01 21:58:33.823235 Epoch 188  	Train Loss = 16.76754 Val Loss = 18.13064
2023-09-01 21:58:54.487939 Epoch 189  	Train Loss = 16.78108 Val Loss = 18.16186
2023-09-01 21:59:15.143203 Epoch 190  	Train Loss = 16.83043 Val Loss = 18.17143
2023-09-01 21:59:35.239176 Epoch 191  	Train Loss = 16.78646 Val Loss = 18.14189
2023-09-01 21:59:55.862420 Epoch 192  	Train Loss = 16.81029 Val Loss = 18.13610
2023-09-01 22:00:16.494352 Epoch 193  	Train Loss = 16.78451 Val Loss = 18.18958
2023-09-01 22:00:37.079833 Epoch 194  	Train Loss = 16.76705 Val Loss = 18.16123
2023-09-01 22:00:57.720222 Epoch 195  	Train Loss = 16.74550 Val Loss = 18.14925
2023-09-01 22:01:18.298179 Epoch 196  	Train Loss = 16.78963 Val Loss = 18.14727
2023-09-01 22:01:38.970997 Epoch 197  	Train Loss = 16.78835 Val Loss = 18.10862
2023-09-01 22:01:59.563752 Epoch 198  	Train Loss = 16.78710 Val Loss = 18.17276
2023-09-01 22:02:20.160201 Epoch 199  	Train Loss = 16.78991 Val Loss = 18.18497
2023-09-01 22:02:40.777207 Epoch 200  	Train Loss = 16.77351 Val Loss = 18.12107
2023-09-01 22:03:01.366197 Epoch 201  	Train Loss = 16.75166 Val Loss = 18.15691
2023-09-01 22:03:21.965329 Epoch 202  	Train Loss = 16.76628 Val Loss = 18.13719
2023-09-01 22:03:42.554282 Epoch 203  	Train Loss = 16.78056 Val Loss = 18.14863
2023-09-01 22:04:03.177356 Epoch 204  	Train Loss = 16.79150 Val Loss = 18.15427
2023-09-01 22:04:23.796116 Epoch 205  	Train Loss = 16.73855 Val Loss = 18.11735
2023-09-01 22:04:44.462558 Epoch 206  	Train Loss = 16.74102 Val Loss = 18.20897
2023-09-01 22:05:05.140085 Epoch 207  	Train Loss = 16.76692 Val Loss = 18.17365
2023-09-01 22:05:25.789160 Epoch 208  	Train Loss = 16.77956 Val Loss = 18.16578
2023-09-01 22:05:46.417439 Epoch 209  	Train Loss = 16.75763 Val Loss = 18.14457
2023-09-01 22:06:07.120717 Epoch 210  	Train Loss = 16.70466 Val Loss = 18.17010
2023-09-01 22:06:27.753592 Epoch 211  	Train Loss = 16.70318 Val Loss = 18.16130
2023-09-01 22:06:48.388566 Epoch 212  	Train Loss = 16.75654 Val Loss = 18.15000
Early stopping at epoch: 212
Best at epoch 197:
Train Loss = 16.78835
Train RMSE = 28.10579, MAE = 17.14327, MAPE = 12.40404
Val Loss = 18.10862
Val RMSE = 31.10847, MAE = 18.90006, MAPE = 12.43075
--------- Test ---------
All Steps RMSE = 31.59485, MAE = 19.18742, MAPE = 12.98796
Step 1 RMSE = 27.41545, MAE = 17.04251, MAPE = 11.58017
Step 2 RMSE = 28.59501, MAE = 17.66074, MAPE = 12.07947
Step 3 RMSE = 29.57754, MAE = 18.18152, MAPE = 12.42287
Step 4 RMSE = 30.31868, MAE = 18.54819, MAPE = 12.63367
Step 5 RMSE = 30.99581, MAE = 18.88622, MAPE = 12.82271
Step 6 RMSE = 31.60053, MAE = 19.16973, MAPE = 13.04202
Step 7 RMSE = 32.19673, MAE = 19.46939, MAPE = 13.20729
Step 8 RMSE = 32.71798, MAE = 19.74456, MAPE = 13.32271
Step 9 RMSE = 33.14622, MAE = 19.98365, MAPE = 13.44424
Step 10 RMSE = 33.47792, MAE = 20.19072, MAPE = 13.55086
Step 11 RMSE = 33.85570, MAE = 20.46953, MAPE = 13.73216
Step 12 RMSE = 34.40001, MAE = 20.90201, MAPE = 14.01713
Inference time: 2.16 s
