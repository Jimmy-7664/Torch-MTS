PEMS08
Trainset:	x-(10700, 12, 170, 1)	y-(10700, 12, 170, 1)
Valset:  	x-(3567, 12, 170, 1)  	y-(3567, 12, 170, 1)
Testset:	x-(3566, 12, 170, 1)	y-(3566, 12, 170, 1)

--------- STWA ---------
{
    "in_steps": 12,
    "out_steps": 12,
    "lr": 0.001,
    "milestones": [],
    "clip_grad": false,
    "batch_size": 16,
    "max_epochs": 200,
    "early_stop": 15,
    "pass_device": true,
    "model_args": {
        "num_nodes": 170,
        "input_dim": 1,
        "output_dim": 1,
        "lag": 12,
        "horizon": 12,
        "device": "cuda:0",
        "channels": 16,
        "memory_size": 16,
        "dynamic": true
    }
}
====================================================================================================
Layer (type:depth-idx)                             Output Shape              Param #
====================================================================================================
STWA                                               [16, 12, 170, 1]          --
├─Sequential: 1-1                                  [16, 170, 16]             --
│    └─Linear: 2-1                                 [16, 170, 32]             416
│    └─Tanh: 2-2                                   [16, 170, 32]             --
│    └─Linear: 2-3                                 [16, 170, 32]             1,056
│    └─Tanh: 2-4                                   [16, 170, 32]             --
│    └─Linear: 2-5                                 [16, 170, 16]             528
├─Sequential: 1-2                                  [16, 170, 16]             --
│    └─Linear: 2-6                                 [16, 170, 32]             416
│    └─Tanh: 2-7                                   [16, 170, 32]             --
│    └─Linear: 2-8                                 [16, 170, 32]             1,056
│    └─Tanh: 2-9                                   [16, 170, 32]             --
│    └─Linear: 2-10                                [16, 170, 16]             528
├─Linear: 1-3                                      [16, 12, 170, 16]         32
├─ModuleList: 1-8                                  --                        (recursive)
│    └─Layer: 2-11                                 [16, 12, 170, 16]         70,720
│    │    └─ModuleList: 3-1                        --                        6,100
│    │    └─ModuleList: 3-2                        --                        6,100
│    │    └─TemporalAttention: 3-3                 [16, 2, 170, 16]          544
│    │    └─SpatialAttention: 3-4                  [16, 2, 170, 16]          544
│    │    └─Sequential: 3-5                        [16, 2, 170, 16]          544
│    │    └─TemporalAttention: 3-6                 [16, 2, 170, 16]          (recursive)
│    │    └─SpatialAttention: 3-7                  [16, 2, 170, 16]          (recursive)
│    │    └─Sequential: 3-8                        [16, 2, 170, 16]          (recursive)
│    │    └─TemporalAttention: 3-9                 [16, 2, 170, 16]          (recursive)
│    │    └─SpatialAttention: 3-10                 [16, 2, 170, 16]          (recursive)
│    │    └─Sequential: 3-11                       [16, 2, 170, 16]          (recursive)
│    │    └─TemporalAttention: 3-12                [16, 2, 170, 16]          (recursive)
│    │    └─SpatialAttention: 3-13                 [16, 2, 170, 16]          (recursive)
│    │    └─Sequential: 3-14                       [16, 2, 170, 16]          (recursive)
│    │    └─TemporalAttention: 3-15                [16, 2, 170, 16]          (recursive)
│    │    └─SpatialAttention: 3-16                 [16, 2, 170, 16]          (recursive)
│    │    └─Sequential: 3-17                       [16, 2, 170, 16]          (recursive)
│    │    └─TemporalAttention: 3-18                [16, 2, 170, 16]          (recursive)
│    │    └─SpatialAttention: 3-19                 [16, 2, 170, 16]          (recursive)
│    │    └─Sequential: 3-20                       [16, 2, 170, 16]          (recursive)
│    │    └─TemporalAttention: 3-21                [16, 2, 170, 16]          (recursive)
│    │    └─SpatialAttention: 3-22                 [16, 2, 170, 16]          (recursive)
│    │    └─Sequential: 3-23                       [16, 2, 170, 16]          (recursive)
│    │    └─TemporalAttention: 3-24                [16, 2, 170, 16]          (recursive)
│    │    └─SpatialAttention: 3-25                 [16, 2, 170, 16]          (recursive)
│    │    └─Sequential: 3-26                       [16, 2, 170, 16]          (recursive)
│    │    └─TemporalAttention: 3-27                [16, 2, 170, 16]          (recursive)
│    │    └─SpatialAttention: 3-28                 [16, 2, 170, 16]          (recursive)
│    │    └─Sequential: 3-29                       [16, 2, 170, 16]          (recursive)
│    │    └─TemporalAttention: 3-30                [16, 2, 170, 16]          (recursive)
│    │    └─SpatialAttention: 3-31                 [16, 2, 170, 16]          (recursive)
│    │    └─Sequential: 3-32                       [16, 2, 170, 16]          (recursive)
│    │    └─TemporalAttention: 3-33                [16, 2, 170, 16]          (recursive)
│    │    └─SpatialAttention: 3-34                 [16, 2, 170, 16]          (recursive)
│    │    └─Sequential: 3-35                       [16, 2, 170, 16]          (recursive)
│    │    └─TemporalAttention: 3-36                [16, 2, 170, 16]          (recursive)
│    │    └─SpatialAttention: 3-37                 [16, 2, 170, 16]          (recursive)
│    │    └─Sequential: 3-38                       [16, 2, 170, 16]          (recursive)
├─ModuleList: 1-9                                  --                        (recursive)
│    └─Linear: 2-12                                [16, 170, 256]            49,408
├─ModuleList: 1-8                                  --                        (recursive)
│    └─Layer: 2-13                                 [16, 3, 170, 16]          21,760
│    │    └─ModuleList: 3-39                       --                        6,100
│    │    └─ModuleList: 3-40                       --                        6,100
│    │    └─TemporalAttention: 3-41                [16, 2, 170, 16]          544
│    │    └─SpatialAttention: 3-42                 [16, 2, 170, 16]          544
│    │    └─Sequential: 3-43                       [16, 2, 170, 16]          544
│    │    └─TemporalAttention: 3-44                [16, 2, 170, 16]          (recursive)
│    │    └─SpatialAttention: 3-45                 [16, 2, 170, 16]          (recursive)
│    │    └─Sequential: 3-46                       [16, 2, 170, 16]          (recursive)
│    │    └─TemporalAttention: 3-47                [16, 2, 170, 16]          (recursive)
│    │    └─SpatialAttention: 3-48                 [16, 2, 170, 16]          (recursive)
│    │    └─Sequential: 3-49                       [16, 2, 170, 16]          (recursive)
├─ModuleList: 1-9                                  --                        (recursive)
│    └─Linear: 2-14                                [16, 170, 256]            12,544
├─ModuleList: 1-8                                  --                        (recursive)
│    └─Layer: 2-15                                 [16, 1, 170, 16]          10,880
│    │    └─ModuleList: 3-50                       --                        6,100
│    │    └─ModuleList: 3-51                       --                        6,100
│    │    └─TemporalAttention: 3-52                [16, 2, 170, 16]          544
│    │    └─SpatialAttention: 3-53                 [16, 2, 170, 16]          544
│    │    └─Sequential: 3-54                       [16, 2, 170, 16]          544
├─ModuleList: 1-9                                  --                        (recursive)
│    └─Linear: 2-16                                [16, 170, 256]            4,352
├─Sequential: 1-10                                 [16, 170, 12]             --
│    └─Linear: 2-17                                [16, 170, 512]            131,584
│    └─ReLU: 2-18                                  [16, 170, 512]            --
│    └─Linear: 2-19                                [16, 170, 12]             6,156
====================================================================================================
Total params: 352,932
Trainable params: 352,932
Non-trainable params: 0
Total mult-adds (M): 4.33
====================================================================================================
Input size (MB): 0.13
Forward/backward pass size (MB): 192.97
Params size (MB): 1.00
Estimated Total Size (MB): 194.10
====================================================================================================

Loss: HuberLoss

2023-12-08 20:47:06.232643 Epoch 1  	Train Loss = 28.94830 Val Loss = 21.55622
2023-12-08 20:48:41.581805 Epoch 2  	Train Loss = 19.67065 Val Loss = 19.19377
2023-12-08 20:50:16.979461 Epoch 3  	Train Loss = 18.43038 Val Loss = 19.25645
2023-12-08 20:51:51.047186 Epoch 4  	Train Loss = 17.67130 Val Loss = 17.98972
2023-12-08 20:53:26.031712 Epoch 5  	Train Loss = 17.09762 Val Loss = 17.89110
2023-12-08 20:55:02.464376 Epoch 6  	Train Loss = 16.67912 Val Loss = 18.00297
2023-12-08 20:56:37.392167 Epoch 7  	Train Loss = 16.34569 Val Loss = 16.83612
2023-12-08 20:58:12.487076 Epoch 8  	Train Loss = 16.10747 Val Loss = 17.02781
2023-12-08 20:59:47.460422 Epoch 9  	Train Loss = 15.93691 Val Loss = 17.07588
2023-12-08 21:01:22.913703 Epoch 10  	Train Loss = 15.70231 Val Loss = 16.80151
2023-12-08 21:02:57.699854 Epoch 11  	Train Loss = 15.55020 Val Loss = 16.58419
2023-12-08 21:04:30.763101 Epoch 12  	Train Loss = 15.50364 Val Loss = 16.40329
2023-12-08 21:06:05.856109 Epoch 13  	Train Loss = 15.31563 Val Loss = 16.87627
2023-12-08 21:07:39.869574 Epoch 14  	Train Loss = 15.10943 Val Loss = 16.57010
2023-12-08 21:09:14.231484 Epoch 15  	Train Loss = 15.08592 Val Loss = 16.30723
2023-12-08 21:10:49.411641 Epoch 16  	Train Loss = 15.00320 Val Loss = 16.01859
2023-12-08 21:12:24.472161 Epoch 17  	Train Loss = 14.88411 Val Loss = 16.38550
2023-12-08 21:13:59.482592 Epoch 18  	Train Loss = 14.83070 Val Loss = 16.12829
2023-12-08 21:15:34.286775 Epoch 19  	Train Loss = 14.70897 Val Loss = 16.51138
2023-12-08 21:17:08.416628 Epoch 20  	Train Loss = 14.65205 Val Loss = 16.29028
2023-12-08 21:18:42.665138 Epoch 21  	Train Loss = 14.56195 Val Loss = 16.53000
2023-12-08 21:20:16.913764 Epoch 22  	Train Loss = 14.50005 Val Loss = 16.44360
2023-12-08 21:21:49.214192 Epoch 23  	Train Loss = 14.47071 Val Loss = 16.09529
2023-12-08 21:23:23.534460 Epoch 24  	Train Loss = 14.39435 Val Loss = 16.80257
2023-12-08 21:24:57.613654 Epoch 25  	Train Loss = 14.32525 Val Loss = 16.78392
2023-12-08 21:26:32.821192 Epoch 26  	Train Loss = 14.28960 Val Loss = 16.09663
2023-12-08 21:28:07.177342 Epoch 27  	Train Loss = 14.22924 Val Loss = 16.25665
2023-12-08 21:29:40.521912 Epoch 28  	Train Loss = 14.24450 Val Loss = 16.07895
2023-12-08 21:31:15.216132 Epoch 29  	Train Loss = 14.15269 Val Loss = 16.52520
2023-12-08 21:32:49.840041 Epoch 30  	Train Loss = 14.13297 Val Loss = 16.19949
2023-12-08 21:34:25.053571 Epoch 31  	Train Loss = 14.06007 Val Loss = 16.23327
Early stopping at epoch: 31
Best at epoch 16:
Train Loss = 15.00320
Train RMSE = 24.75628, MAE = 15.15528, MAPE = 10.87314
Val Loss = 16.01859
Val RMSE = 26.22700, MAE = 16.49740, MAPE = 13.18605
--------- Test ---------
All Steps RMSE = 25.07547, MAE = 16.13255, MAPE = 11.82878
Step 1 RMSE = 21.91877, MAE = 14.37180, MAPE = 10.91440
Step 2 RMSE = 22.71799, MAE = 14.66768, MAPE = 10.13723
Step 3 RMSE = 23.44518, MAE = 15.14799, MAPE = 11.06236
Step 4 RMSE = 24.02950, MAE = 15.47196, MAPE = 11.10169
Step 5 RMSE = 24.64001, MAE = 15.89171, MAPE = 11.87078
Step 6 RMSE = 24.96829, MAE = 15.99226, MAPE = 10.95647
Step 7 RMSE = 25.33953, MAE = 16.21341, MAPE = 10.73028
Step 8 RMSE = 25.72513, MAE = 16.49685, MAPE = 11.88288
Step 9 RMSE = 26.12910, MAE = 16.82871, MAPE = 13.00341
Step 10 RMSE = 26.55600, MAE = 17.09640, MAPE = 12.93890
Step 11 RMSE = 27.08291, MAE = 17.50708, MAPE = 13.74769
Step 12 RMSE = 27.67429, MAE = 17.90478, MAPE = 13.59942
Inference time: 5.60 s
