PEMSBAY
Trainset:	x-(36465, 12, 325, 1)	y-(36465, 12, 325, 1)
Valset:  	x-(5209, 12, 325, 1)  	y-(5209, 12, 325, 1)
Testset:	x-(10419, 12, 325, 1)	y-(10419, 12, 325, 1)

--------- STWA ---------
{
    "in_steps": 12,
    "out_steps": 12,
    "lr": 0.001,
    "milestones": [],
    "clip_grad": false,
    "batch_size": 16,
    "max_epochs": 200,
    "early_stop": 15,
    "pass_device": true,
    "model_args": {
        "num_nodes": 325,
        "input_dim": 1,
        "output_dim": 1,
        "lag": 12,
        "horizon": 12,
        "device": "cuda:0",
        "channels": 16,
        "memory_size": 16,
        "dynamic": true
    }
}
====================================================================================================
Layer (type:depth-idx)                             Output Shape              Param #
====================================================================================================
STWA                                               [16, 12, 325, 1]          --
├─Sequential: 1-1                                  [16, 325, 16]             --
│    └─Linear: 2-1                                 [16, 325, 32]             416
│    └─Tanh: 2-2                                   [16, 325, 32]             --
│    └─Linear: 2-3                                 [16, 325, 32]             1,056
│    └─Tanh: 2-4                                   [16, 325, 32]             --
│    └─Linear: 2-5                                 [16, 325, 16]             528
├─Sequential: 1-2                                  [16, 325, 16]             --
│    └─Linear: 2-6                                 [16, 325, 32]             416
│    └─Tanh: 2-7                                   [16, 325, 32]             --
│    └─Linear: 2-8                                 [16, 325, 32]             1,056
│    └─Tanh: 2-9                                   [16, 325, 32]             --
│    └─Linear: 2-10                                [16, 325, 16]             528
├─Linear: 1-3                                      [16, 12, 325, 16]         32
├─ModuleList: 1-8                                  --                        (recursive)
│    └─Layer: 2-11                                 [16, 12, 325, 16]         135,200
│    │    └─ModuleList: 3-1                        --                        6,100
│    │    └─ModuleList: 3-2                        --                        6,100
│    │    └─TemporalAttention: 3-3                 [16, 2, 325, 16]          544
│    │    └─SpatialAttention: 3-4                  [16, 2, 325, 16]          544
│    │    └─Sequential: 3-5                        [16, 2, 325, 16]          544
│    │    └─TemporalAttention: 3-6                 [16, 2, 325, 16]          (recursive)
│    │    └─SpatialAttention: 3-7                  [16, 2, 325, 16]          (recursive)
│    │    └─Sequential: 3-8                        [16, 2, 325, 16]          (recursive)
│    │    └─TemporalAttention: 3-9                 [16, 2, 325, 16]          (recursive)
│    │    └─SpatialAttention: 3-10                 [16, 2, 325, 16]          (recursive)
│    │    └─Sequential: 3-11                       [16, 2, 325, 16]          (recursive)
│    │    └─TemporalAttention: 3-12                [16, 2, 325, 16]          (recursive)
│    │    └─SpatialAttention: 3-13                 [16, 2, 325, 16]          (recursive)
│    │    └─Sequential: 3-14                       [16, 2, 325, 16]          (recursive)
│    │    └─TemporalAttention: 3-15                [16, 2, 325, 16]          (recursive)
│    │    └─SpatialAttention: 3-16                 [16, 2, 325, 16]          (recursive)
│    │    └─Sequential: 3-17                       [16, 2, 325, 16]          (recursive)
│    │    └─TemporalAttention: 3-18                [16, 2, 325, 16]          (recursive)
│    │    └─SpatialAttention: 3-19                 [16, 2, 325, 16]          (recursive)
│    │    └─Sequential: 3-20                       [16, 2, 325, 16]          (recursive)
│    │    └─TemporalAttention: 3-21                [16, 2, 325, 16]          (recursive)
│    │    └─SpatialAttention: 3-22                 [16, 2, 325, 16]          (recursive)
│    │    └─Sequential: 3-23                       [16, 2, 325, 16]          (recursive)
│    │    └─TemporalAttention: 3-24                [16, 2, 325, 16]          (recursive)
│    │    └─SpatialAttention: 3-25                 [16, 2, 325, 16]          (recursive)
│    │    └─Sequential: 3-26                       [16, 2, 325, 16]          (recursive)
│    │    └─TemporalAttention: 3-27                [16, 2, 325, 16]          (recursive)
│    │    └─SpatialAttention: 3-28                 [16, 2, 325, 16]          (recursive)
│    │    └─Sequential: 3-29                       [16, 2, 325, 16]          (recursive)
│    │    └─TemporalAttention: 3-30                [16, 2, 325, 16]          (recursive)
│    │    └─SpatialAttention: 3-31                 [16, 2, 325, 16]          (recursive)
│    │    └─Sequential: 3-32                       [16, 2, 325, 16]          (recursive)
│    │    └─TemporalAttention: 3-33                [16, 2, 325, 16]          (recursive)
│    │    └─SpatialAttention: 3-34                 [16, 2, 325, 16]          (recursive)
│    │    └─Sequential: 3-35                       [16, 2, 325, 16]          (recursive)
│    │    └─TemporalAttention: 3-36                [16, 2, 325, 16]          (recursive)
│    │    └─SpatialAttention: 3-37                 [16, 2, 325, 16]          (recursive)
│    │    └─Sequential: 3-38                       [16, 2, 325, 16]          (recursive)
├─ModuleList: 1-9                                  --                        (recursive)
│    └─Linear: 2-12                                [16, 325, 256]            49,408
├─ModuleList: 1-8                                  --                        (recursive)
│    └─Layer: 2-13                                 [16, 3, 325, 16]          41,600
│    │    └─ModuleList: 3-39                       --                        6,100
│    │    └─ModuleList: 3-40                       --                        6,100
│    │    └─TemporalAttention: 3-41                [16, 2, 325, 16]          544
│    │    └─SpatialAttention: 3-42                 [16, 2, 325, 16]          544
│    │    └─Sequential: 3-43                       [16, 2, 325, 16]          544
│    │    └─TemporalAttention: 3-44                [16, 2, 325, 16]          (recursive)
│    │    └─SpatialAttention: 3-45                 [16, 2, 325, 16]          (recursive)
│    │    └─Sequential: 3-46                       [16, 2, 325, 16]          (recursive)
│    │    └─TemporalAttention: 3-47                [16, 2, 325, 16]          (recursive)
│    │    └─SpatialAttention: 3-48                 [16, 2, 325, 16]          (recursive)
│    │    └─Sequential: 3-49                       [16, 2, 325, 16]          (recursive)
├─ModuleList: 1-9                                  --                        (recursive)
│    └─Linear: 2-14                                [16, 325, 256]            12,544
├─ModuleList: 1-8                                  --                        (recursive)
│    └─Layer: 2-15                                 [16, 1, 325, 16]          20,800
│    │    └─ModuleList: 3-50                       --                        6,100
│    │    └─ModuleList: 3-51                       --                        6,100
│    │    └─TemporalAttention: 3-52                [16, 2, 325, 16]          544
│    │    └─SpatialAttention: 3-53                 [16, 2, 325, 16]          544
│    │    └─Sequential: 3-54                       [16, 2, 325, 16]          544
├─ModuleList: 1-9                                  --                        (recursive)
│    └─Linear: 2-16                                [16, 325, 256]            4,352
├─Sequential: 1-10                                 [16, 325, 12]             --
│    └─Linear: 2-17                                [16, 325, 512]            131,584
│    └─ReLU: 2-18                                  [16, 325, 512]            --
│    └─Linear: 2-19                                [16, 325, 12]             6,156
====================================================================================================
Total params: 447,172
Trainable params: 447,172
Non-trainable params: 0
Total mult-adds (M): 4.33
====================================================================================================
Input size (MB): 0.25
Forward/backward pass size (MB): 265.08
Params size (MB): 1.00
Estimated Total Size (MB): 266.32
====================================================================================================

Loss: MaskedMAELoss

2023-12-05 17:03:07.797202 Epoch 1  	Train Loss = 2.05776 Val Loss = 1.97181
2023-12-05 17:08:46.714765 Epoch 2  	Train Loss = 1.69153 Val Loss = 1.80073
2023-12-05 17:14:28.811686 Epoch 3  	Train Loss = 1.61458 Val Loss = 1.75221
2023-12-05 17:20:05.315762 Epoch 4  	Train Loss = 1.57369 Val Loss = 1.86020
2023-12-05 17:25:43.764387 Epoch 5  	Train Loss = 1.54642 Val Loss = 1.69491
2023-12-05 17:31:24.944498 Epoch 6  	Train Loss = 1.52096 Val Loss = 1.72444
2023-12-05 17:37:01.924801 Epoch 7  	Train Loss = 1.50443 Val Loss = 1.71101
2023-12-05 17:42:40.239872 Epoch 8  	Train Loss = 1.48647 Val Loss = 1.67977
2023-12-05 17:48:20.337728 Epoch 9  	Train Loss = 1.47020 Val Loss = 1.66851
2023-12-05 17:54:00.082648 Epoch 10  	Train Loss = 1.45778 Val Loss = 1.67529
2023-12-05 17:59:38.203046 Epoch 11  	Train Loss = 1.44631 Val Loss = 1.67199
2023-12-05 18:05:16.281170 Epoch 12  	Train Loss = 1.43746 Val Loss = 1.66770
2023-12-05 18:11:00.089600 Epoch 13  	Train Loss = 1.42782 Val Loss = 1.68698
2023-12-05 18:16:36.483260 Epoch 14  	Train Loss = 1.41993 Val Loss = 1.65897
2023-12-05 18:22:11.045042 Epoch 15  	Train Loss = 1.41277 Val Loss = 1.65755
2023-12-05 18:27:47.668622 Epoch 16  	Train Loss = 1.40531 Val Loss = 1.65494
2023-12-05 18:33:24.412636 Epoch 17  	Train Loss = 1.39941 Val Loss = 1.69251
2023-12-05 18:39:02.341125 Epoch 18  	Train Loss = 1.39377 Val Loss = 1.65109
2023-12-05 18:44:39.546415 Epoch 19  	Train Loss = 1.38856 Val Loss = 1.71883
2023-12-05 18:50:15.828209 Epoch 20  	Train Loss = 1.38698 Val Loss = 1.68931
2023-12-05 18:55:52.189439 Epoch 21  	Train Loss = 1.37828 Val Loss = 1.65235
2023-12-05 19:01:29.985757 Epoch 22  	Train Loss = 1.37363 Val Loss = 1.65213
2023-12-05 19:07:05.938199 Epoch 23  	Train Loss = 1.36950 Val Loss = 1.64008
2023-12-05 19:12:40.890991 Epoch 24  	Train Loss = 1.36460 Val Loss = 1.67644
2023-12-05 19:18:15.638981 Epoch 25  	Train Loss = 1.36159 Val Loss = 1.63760
2023-12-05 19:23:51.347770 Epoch 26  	Train Loss = 1.35756 Val Loss = 1.64805
2023-12-05 19:29:25.713638 Epoch 27  	Train Loss = 1.35454 Val Loss = 1.64981
2023-12-05 19:35:04.469960 Epoch 28  	Train Loss = 1.35045 Val Loss = 1.66150
2023-12-05 19:40:41.393687 Epoch 29  	Train Loss = 1.34580 Val Loss = 1.63467
2023-12-05 19:46:20.283394 Epoch 30  	Train Loss = 1.34341 Val Loss = 1.64395
2023-12-05 19:51:57.058659 Epoch 31  	Train Loss = 1.34042 Val Loss = 1.64125
2023-12-05 19:57:37.875738 Epoch 32  	Train Loss = 1.33841 Val Loss = 1.69403
2023-12-05 20:03:15.598481 Epoch 33  	Train Loss = 1.33713 Val Loss = 1.64025
2023-12-05 20:08:54.206497 Epoch 34  	Train Loss = 1.33278 Val Loss = 1.65932
2023-12-05 20:14:32.402639 Epoch 35  	Train Loss = 1.32945 Val Loss = 1.66347
2023-12-05 20:20:10.181013 Epoch 36  	Train Loss = 1.32763 Val Loss = 1.65055
2023-12-05 20:25:49.187822 Epoch 37  	Train Loss = 1.32536 Val Loss = 1.67340
2023-12-05 20:31:28.957994 Epoch 38  	Train Loss = 1.32515 Val Loss = 1.63695
2023-12-05 20:37:06.184467 Epoch 39  	Train Loss = 1.31838 Val Loss = 1.67524
2023-12-05 20:42:44.644788 Epoch 40  	Train Loss = 1.31686 Val Loss = 1.64653
2023-12-05 20:48:22.654535 Epoch 41  	Train Loss = 1.31589 Val Loss = 1.64631
2023-12-05 20:54:02.060992 Epoch 42  	Train Loss = 1.31401 Val Loss = 1.65039
2023-12-05 20:59:40.676670 Epoch 43  	Train Loss = 1.30996 Val Loss = 1.65326
2023-12-05 21:05:19.819231 Epoch 44  	Train Loss = 1.30787 Val Loss = 1.64999
Early stopping at epoch: 44
Best at epoch 29:
Train Loss = 1.34580
Train RMSE = 2.80590, MAE = 1.29961, MAPE = 2.71185
Val Loss = 1.63467
Val RMSE = 3.77885, MAE = 1.64910, MAPE = 3.74048
--------- Test ---------
All Steps RMSE = 3.84960, MAE = 1.68823, MAPE = 3.79849
Step 1 RMSE = 1.67472, MAE = 0.93403, MAPE = 1.85220
Step 2 RMSE = 2.38742, MAE = 1.20522, MAPE = 2.47665
Step 3 RMSE = 2.97078, MAE = 1.40757, MAPE = 2.98892
Step 4 RMSE = 3.41965, MAE = 1.56140, MAPE = 3.41576
Step 5 RMSE = 3.75091, MAE = 1.67612, MAPE = 3.73279
Step 6 RMSE = 3.96797, MAE = 1.75662, MAPE = 3.96459
Step 7 RMSE = 4.14939, MAE = 1.82499, MAPE = 4.16786
Step 8 RMSE = 4.30450, MAE = 1.88822, MAPE = 4.33994
Step 9 RMSE = 4.42531, MAE = 1.94033, MAPE = 4.49210
Step 10 RMSE = 4.52081, MAE = 1.98228, MAPE = 4.60952
Step 11 RMSE = 4.60485, MAE = 2.02134, MAPE = 4.72008
Step 12 RMSE = 4.69289, MAE = 2.06067, MAPE = 4.82140
Inference time: 18.47 s
