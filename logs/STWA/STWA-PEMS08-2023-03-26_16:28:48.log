PEMS08
Original data shape (17856, 170, 3)
Trainset:	x-(10690, 12, 170, 1)	y-(10690, 12, 170, 1)
Valset:  	x-(3548, 12, 170, 1)  	y-(3548, 12, 170, 1)
Testset:	x-(3549, 12, 170, 1)	y-(3549, 12, 170, 1)

--------- STWA ---------
{
    "num_nodes": 170,
    "in_steps": 12,
    "out_steps": 12,
    "train_size": 0.6,
    "val_size": 0.2,
    "lr": 0.001,
    "milestones": [
        60
    ],
    "clip_grad": false,
    "batch_size": 64,
    "max_epochs": 200,
    "use_cl": false,
    "load_npz": false,
    "pass_device": true,
    "model_args": {
        "num_nodes": 170,
        "input_dim": 1,
        "output_dim": 1,
        "lag": 12,
        "horizon": 12,
        "device": "cuda:0",
        "channels": 16,
        "memory_size": 16,
        "dynamic": true
    }
}
====================================================================================================
Layer (type:depth-idx)                             Output Shape              Param #
====================================================================================================
STWA                                               [64, 12, 170, 1]          --
├─Sequential: 1-1                                  [64, 170, 16]             --
│    └─Linear: 2-1                                 [64, 170, 32]             416
│    └─Tanh: 2-2                                   [64, 170, 32]             --
│    └─Linear: 2-3                                 [64, 170, 32]             1,056
│    └─Tanh: 2-4                                   [64, 170, 32]             --
│    └─Linear: 2-5                                 [64, 170, 16]             528
├─Sequential: 1-2                                  [64, 170, 16]             --
│    └─Linear: 2-6                                 [64, 170, 32]             416
│    └─Tanh: 2-7                                   [64, 170, 32]             --
│    └─Linear: 2-8                                 [64, 170, 32]             1,056
│    └─Tanh: 2-9                                   [64, 170, 32]             --
│    └─Linear: 2-10                                [64, 170, 16]             528
├─Linear: 1-3                                      [64, 12, 170, 16]         32
├─ModuleList: 1-8                                  --                        (recursive)
│    └─Layer: 2-11                                 [64, 12, 170, 16]         70,720
│    │    └─ModuleList: 3-1                        --                        6,100
│    │    └─ModuleList: 3-2                        --                        6,100
│    │    └─TemporalAttention: 3-3                 [64, 2, 170, 16]          544
│    │    └─SpatialAttention: 3-4                  [64, 2, 170, 16]          544
│    │    └─Sequential: 3-5                        [64, 2, 170, 16]          544
│    │    └─TemporalAttention: 3-6                 [64, 2, 170, 16]          (recursive)
│    │    └─SpatialAttention: 3-7                  [64, 2, 170, 16]          (recursive)
│    │    └─Sequential: 3-8                        [64, 2, 170, 16]          (recursive)
│    │    └─TemporalAttention: 3-9                 [64, 2, 170, 16]          (recursive)
│    │    └─SpatialAttention: 3-10                 [64, 2, 170, 16]          (recursive)
│    │    └─Sequential: 3-11                       [64, 2, 170, 16]          (recursive)
│    │    └─TemporalAttention: 3-12                [64, 2, 170, 16]          (recursive)
│    │    └─SpatialAttention: 3-13                 [64, 2, 170, 16]          (recursive)
│    │    └─Sequential: 3-14                       [64, 2, 170, 16]          (recursive)
│    │    └─TemporalAttention: 3-15                [64, 2, 170, 16]          (recursive)
│    │    └─SpatialAttention: 3-16                 [64, 2, 170, 16]          (recursive)
│    │    └─Sequential: 3-17                       [64, 2, 170, 16]          (recursive)
│    │    └─TemporalAttention: 3-18                [64, 2, 170, 16]          (recursive)
│    │    └─SpatialAttention: 3-19                 [64, 2, 170, 16]          (recursive)
│    │    └─Sequential: 3-20                       [64, 2, 170, 16]          (recursive)
│    │    └─TemporalAttention: 3-21                [64, 2, 170, 16]          (recursive)
│    │    └─SpatialAttention: 3-22                 [64, 2, 170, 16]          (recursive)
│    │    └─Sequential: 3-23                       [64, 2, 170, 16]          (recursive)
│    │    └─TemporalAttention: 3-24                [64, 2, 170, 16]          (recursive)
│    │    └─SpatialAttention: 3-25                 [64, 2, 170, 16]          (recursive)
│    │    └─Sequential: 3-26                       [64, 2, 170, 16]          (recursive)
│    │    └─TemporalAttention: 3-27                [64, 2, 170, 16]          (recursive)
│    │    └─SpatialAttention: 3-28                 [64, 2, 170, 16]          (recursive)
│    │    └─Sequential: 3-29                       [64, 2, 170, 16]          (recursive)
│    │    └─TemporalAttention: 3-30                [64, 2, 170, 16]          (recursive)
│    │    └─SpatialAttention: 3-31                 [64, 2, 170, 16]          (recursive)
│    │    └─Sequential: 3-32                       [64, 2, 170, 16]          (recursive)
│    │    └─TemporalAttention: 3-33                [64, 2, 170, 16]          (recursive)
│    │    └─SpatialAttention: 3-34                 [64, 2, 170, 16]          (recursive)
│    │    └─Sequential: 3-35                       [64, 2, 170, 16]          (recursive)
│    │    └─TemporalAttention: 3-36                [64, 2, 170, 16]          (recursive)
│    │    └─SpatialAttention: 3-37                 [64, 2, 170, 16]          (recursive)
│    │    └─Sequential: 3-38                       [64, 2, 170, 16]          (recursive)
├─ModuleList: 1-9                                  --                        (recursive)
│    └─Linear: 2-12                                [64, 170, 256]            49,408
├─ModuleList: 1-8                                  --                        (recursive)
│    └─Layer: 2-13                                 [64, 3, 170, 16]          21,760
│    │    └─ModuleList: 3-39                       --                        6,100
│    │    └─ModuleList: 3-40                       --                        6,100
│    │    └─TemporalAttention: 3-41                [64, 2, 170, 16]          544
│    │    └─SpatialAttention: 3-42                 [64, 2, 170, 16]          544
│    │    └─Sequential: 3-43                       [64, 2, 170, 16]          544
│    │    └─TemporalAttention: 3-44                [64, 2, 170, 16]          (recursive)
│    │    └─SpatialAttention: 3-45                 [64, 2, 170, 16]          (recursive)
│    │    └─Sequential: 3-46                       [64, 2, 170, 16]          (recursive)
│    │    └─TemporalAttention: 3-47                [64, 2, 170, 16]          (recursive)
│    │    └─SpatialAttention: 3-48                 [64, 2, 170, 16]          (recursive)
│    │    └─Sequential: 3-49                       [64, 2, 170, 16]          (recursive)
├─ModuleList: 1-9                                  --                        (recursive)
│    └─Linear: 2-14                                [64, 170, 256]            12,544
├─ModuleList: 1-8                                  --                        (recursive)
│    └─Layer: 2-15                                 [64, 1, 170, 16]          10,880
│    │    └─ModuleList: 3-50                       --                        6,100
│    │    └─ModuleList: 3-51                       --                        6,100
│    │    └─TemporalAttention: 3-52                [64, 2, 170, 16]          544
│    │    └─SpatialAttention: 3-53                 [64, 2, 170, 16]          544
│    │    └─Sequential: 3-54                       [64, 2, 170, 16]          544
├─ModuleList: 1-9                                  --                        (recursive)
│    └─Linear: 2-16                                [64, 170, 256]            4,352
├─Sequential: 1-10                                 [64, 170, 12]             --
│    └─Linear: 2-17                                [64, 170, 512]            131,584
│    └─ReLU: 2-18                                  [64, 170, 512]            --
│    └─Linear: 2-19                                [64, 170, 12]             6,156
====================================================================================================
Total params: 352,932
Trainable params: 352,932
Non-trainable params: 0
Total mult-adds (M): 17.33
====================================================================================================
Input size (MB): 0.52
Forward/backward pass size (MB): 554.62
Params size (MB): 1.00
Estimated Total Size (MB): 556.14
====================================================================================================

Loss: HuberLoss

2023-03-26 16:29:29.821006 Epoch 1  	Train Loss = 47.11752 Val Loss = 26.99786
2023-03-26 16:30:09.914921 Epoch 2  	Train Loss = 23.52601 Val Loss = 23.24442
2023-03-26 16:30:50.116220 Epoch 3  	Train Loss = 21.52918 Val Loss = 21.44723
2023-03-26 16:31:30.242522 Epoch 4  	Train Loss = 20.03696 Val Loss = 20.56915
2023-03-26 16:32:10.379255 Epoch 5  	Train Loss = 19.43091 Val Loss = 20.69141
2023-03-26 16:32:50.509098 Epoch 6  	Train Loss = 18.80960 Val Loss = 19.43027
2023-03-26 16:33:30.647565 Epoch 7  	Train Loss = 18.31671 Val Loss = 21.10362
2023-03-26 16:34:10.810947 Epoch 8  	Train Loss = 18.03861 Val Loss = 19.76981
2023-03-26 16:34:51.017410 Epoch 9  	Train Loss = 17.66881 Val Loss = 18.46481
2023-03-26 16:35:31.276827 Epoch 10  	Train Loss = 17.32294 Val Loss = 19.91258
2023-03-26 16:36:11.555952 Epoch 11  	Train Loss = 17.34892 Val Loss = 18.20705
2023-03-26 16:36:52.095856 Epoch 12  	Train Loss = 17.05177 Val Loss = 17.91231
2023-03-26 16:37:32.844151 Epoch 13  	Train Loss = 16.85625 Val Loss = 18.23516
2023-03-26 16:38:13.176368 Epoch 14  	Train Loss = 16.69322 Val Loss = 18.33834
2023-03-26 16:38:53.437826 Epoch 15  	Train Loss = 16.69119 Val Loss = 17.82949
2023-03-26 16:39:33.637983 Epoch 16  	Train Loss = 16.44730 Val Loss = 19.92251
2023-03-26 16:40:13.839868 Epoch 17  	Train Loss = 16.48717 Val Loss = 17.10089
2023-03-26 16:40:54.109243 Epoch 18  	Train Loss = 16.26711 Val Loss = 18.84002
2023-03-26 16:41:34.367713 Epoch 19  	Train Loss = 16.18165 Val Loss = 17.08927
2023-03-26 16:42:14.776171 Epoch 20  	Train Loss = 16.02265 Val Loss = 16.94042
2023-03-26 16:42:55.192686 Epoch 21  	Train Loss = 15.98055 Val Loss = 16.75121
2023-03-26 16:43:35.811374 Epoch 22  	Train Loss = 15.82844 Val Loss = 19.77575
2023-03-26 16:44:16.593160 Epoch 23  	Train Loss = 15.97257 Val Loss = 17.04819
2023-03-26 16:44:56.904443 Epoch 24  	Train Loss = 15.70979 Val Loss = 16.76077
2023-03-26 16:45:37.051986 Epoch 25  	Train Loss = 15.52978 Val Loss = 16.78424
2023-03-26 16:46:17.462705 Epoch 26  	Train Loss = 15.55515 Val Loss = 18.83664
2023-03-26 16:46:57.638661 Epoch 27  	Train Loss = 15.59213 Val Loss = 16.94649
2023-03-26 16:47:37.874093 Epoch 28  	Train Loss = 15.45136 Val Loss = 16.89919
2023-03-26 16:48:18.488291 Epoch 29  	Train Loss = 15.36512 Val Loss = 17.82575
2023-03-26 16:48:58.617063 Epoch 30  	Train Loss = 15.51815 Val Loss = 16.61780
2023-03-26 16:49:38.751966 Epoch 31  	Train Loss = 15.19325 Val Loss = 16.52495
2023-03-26 16:50:18.892893 Epoch 32  	Train Loss = 15.16758 Val Loss = 16.68145
2023-03-26 16:50:59.091553 Epoch 33  	Train Loss = 15.15154 Val Loss = 17.56215
2023-03-26 16:51:39.225775 Epoch 34  	Train Loss = 15.18777 Val Loss = 16.36065
2023-03-26 16:52:19.356241 Epoch 35  	Train Loss = 15.12373 Val Loss = 16.14271
2023-03-26 16:52:59.639135 Epoch 36  	Train Loss = 14.97453 Val Loss = 16.20939
2023-03-26 16:53:39.871010 Epoch 37  	Train Loss = 15.02269 Val Loss = 16.36645
2023-03-26 16:54:19.982048 Epoch 38  	Train Loss = 15.04400 Val Loss = 16.90864
2023-03-26 16:55:00.147500 Epoch 39  	Train Loss = 14.88995 Val Loss = 17.10271
2023-03-26 16:55:40.308030 Epoch 40  	Train Loss = 14.96083 Val Loss = 16.63118
2023-03-26 16:56:20.498912 Epoch 41  	Train Loss = 14.90945 Val Loss = 17.13652
2023-03-26 16:57:00.628531 Epoch 42  	Train Loss = 14.81541 Val Loss = 16.54922
2023-03-26 16:57:40.774938 Epoch 43  	Train Loss = 14.80541 Val Loss = 17.47789
2023-03-26 16:58:20.928334 Epoch 44  	Train Loss = 14.75915 Val Loss = 16.04657
2023-03-26 16:59:01.092843 Epoch 45  	Train Loss = 14.68884 Val Loss = 16.18503
2023-03-26 16:59:41.263903 Epoch 46  	Train Loss = 14.71443 Val Loss = 16.36082
2023-03-26 17:00:21.428618 Epoch 47  	Train Loss = 14.72735 Val Loss = 16.17205
2023-03-26 17:01:01.570971 Epoch 48  	Train Loss = 14.68901 Val Loss = 16.56274
2023-03-26 17:01:41.728365 Epoch 49  	Train Loss = 14.53839 Val Loss = 16.08684
2023-03-26 17:02:21.894343 Epoch 50  	Train Loss = 14.50127 Val Loss = 16.55708
2023-03-26 17:03:02.027646 Epoch 51  	Train Loss = 14.55895 Val Loss = 16.42124
2023-03-26 17:03:42.162060 Epoch 52  	Train Loss = 14.47182 Val Loss = 17.08917
2023-03-26 17:04:22.289816 Epoch 53  	Train Loss = 14.50898 Val Loss = 16.21682
2023-03-26 17:05:02.562461 Epoch 54  	Train Loss = 14.47164 Val Loss = 18.63273
Early stopping at epoch: 54
Best at epoch 44:
Train Loss = 14.75915
Train RMSE = 26.44374, MAE = 16.92030, MAPE = 14.70367
Val Loss = 16.04657
Val RMSE = 29.31670, MAE = 19.04043, MAPE = 17.02540
--------- Test ---------
All Steps RMSE = 28.54307, MAE = 18.79408, MAPE = 15.84919
Step 1 RMSE = 23.63684, MAE = 15.93118, MAPE = 14.76724
Step 2 RMSE = 24.63284, MAE = 16.32564, MAPE = 12.96070
Step 3 RMSE = 25.47187, MAE = 16.77981, MAPE = 12.48863
Step 4 RMSE = 26.38719, MAE = 17.54507, MAPE = 15.02555
Step 5 RMSE = 27.22942, MAE = 18.00878, MAPE = 14.81298
Step 6 RMSE = 27.70852, MAE = 18.40691, MAPE = 16.76748
Step 7 RMSE = 28.57400, MAE = 18.88774, MAPE = 16.42431
Step 8 RMSE = 29.44711, MAE = 19.34701, MAPE = 15.77558
Step 9 RMSE = 30.61846, MAE = 20.20850, MAPE = 17.08805
Step 10 RMSE = 31.44001, MAE = 20.76381, MAPE = 17.72142
Step 11 RMSE = 32.12285, MAE = 21.24094, MAPE = 18.13679
Step 12 RMSE = 33.39550, MAE = 22.08357, MAPE = 18.22170
Inference time: 2.32 s
