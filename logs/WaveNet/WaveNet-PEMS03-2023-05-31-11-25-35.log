PEMS03
Trainset:	x-(15711, 12, 358, 1)	y-(15711, 12, 358, 1)
Valset:  	x-(5237, 12, 358, 1)  	y-(5237, 12, 358, 1)
Testset:	x-(5237, 12, 358, 1)	y-(5237, 12, 358, 1)

--------- WaveNet ---------
{
    "num_nodes": 358,
    "in_steps": 12,
    "out_steps": 12,
    "lr": 0.01,
    "weight_decay": 0,
    "milestones": [
        10,
        30
    ],
    "clip_grad": 0,
    "batch_size": 64,
    "max_epochs": 200,
    "use_cl": false,
    "model_args": {
        "in_channels": 1,
        "out_channels": 12,
        "hidden_channels": 16,
        "kernel_size": 2,
        "num_blocks": 4,
        "num_layers": 2
    }
}
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
WaveNet                                  [64, 12, 358, 1]          --
├─Conv2d: 1-1                            [64, 16, 358, 13]         32
├─ModuleList: 1-2                        --                        --
│    └─ConvBlock: 2-1                    [64, 16, 358, 10]         --
│    │    └─ModuleList: 3-5              --                        (recursive)
│    │    └─ModuleList: 3-6              --                        (recursive)
│    │    └─ModuleList: 3-7              --                        (recursive)
│    │    └─ModuleList: 3-8              --                        (recursive)
│    │    └─ModuleList: 3-5              --                        (recursive)
│    │    └─ModuleList: 3-6              --                        (recursive)
│    │    └─ModuleList: 3-7              --                        (recursive)
│    │    └─ModuleList: 3-8              --                        (recursive)
│    └─ConvBlock: 2-2                    [64, 16, 358, 7]          --
│    │    └─ModuleList: 3-13             --                        (recursive)
│    │    └─ModuleList: 3-14             --                        (recursive)
│    │    └─ModuleList: 3-15             --                        (recursive)
│    │    └─ModuleList: 3-16             --                        (recursive)
│    │    └─ModuleList: 3-13             --                        (recursive)
│    │    └─ModuleList: 3-14             --                        (recursive)
│    │    └─ModuleList: 3-15             --                        (recursive)
│    │    └─ModuleList: 3-16             --                        (recursive)
│    └─ConvBlock: 2-3                    [64, 16, 358, 4]          --
│    │    └─ModuleList: 3-21             --                        (recursive)
│    │    └─ModuleList: 3-22             --                        (recursive)
│    │    └─ModuleList: 3-23             --                        (recursive)
│    │    └─ModuleList: 3-24             --                        (recursive)
│    │    └─ModuleList: 3-21             --                        (recursive)
│    │    └─ModuleList: 3-22             --                        (recursive)
│    │    └─ModuleList: 3-23             --                        (recursive)
│    │    └─ModuleList: 3-24             --                        (recursive)
│    └─ConvBlock: 2-4                    [64, 16, 358, 1]          --
│    │    └─ModuleList: 3-29             --                        (recursive)
│    │    └─ModuleList: 3-30             --                        (recursive)
│    │    └─ModuleList: 3-31             --                        (recursive)
│    │    └─ModuleList: 3-32             --                        (recursive)
│    │    └─ModuleList: 3-29             --                        (recursive)
│    │    └─ModuleList: 3-30             --                        (recursive)
│    │    └─ModuleList: 3-31             --                        (recursive)
│    │    └─ModuleList: 3-32             --                        (recursive)
├─Sequential: 1-3                        [64, 12, 358, 1]          --
│    └─ReLU: 2-5                         [64, 16, 358, 1]          --
│    └─Conv2d: 2-6                       [64, 16, 358, 1]          272
│    └─ReLU: 2-7                         [64, 16, 358, 1]          --
│    └─Conv2d: 2-8                       [64, 12, 358, 1]          204
==========================================================================================
Total params: 13,308
Trainable params: 13,308
Non-trainable params: 0
Total mult-adds (G): 1.93
==========================================================================================
Input size (MB): 1.10
Forward/backward pass size (MB): 653.27
Params size (MB): 0.05
Estimated Total Size (MB): 654.42
==========================================================================================

Loss: HuberLoss

2023-05-31 11:25:47.040447 Epoch 1  	Train Loss = 27.87914 Val Loss = 23.55153
2023-05-31 11:25:54.323571 Epoch 2  	Train Loss = 22.59686 Val Loss = 21.52622
2023-05-31 11:26:01.992250 Epoch 3  	Train Loss = 21.61213 Val Loss = 21.38462
2023-05-31 11:26:09.396526 Epoch 4  	Train Loss = 21.41146 Val Loss = 21.00605
2023-05-31 11:26:17.036872 Epoch 5  	Train Loss = 21.13598 Val Loss = 21.08163
2023-05-31 11:26:24.719660 Epoch 6  	Train Loss = 21.15284 Val Loss = 20.57621
2023-05-31 11:26:32.298992 Epoch 7  	Train Loss = 20.92666 Val Loss = 20.91774
2023-05-31 11:26:39.904665 Epoch 8  	Train Loss = 20.84481 Val Loss = 20.61179
2023-05-31 11:26:47.575446 Epoch 9  	Train Loss = 20.89949 Val Loss = 20.53318
2023-05-31 11:26:55.265938 Epoch 10  	Train Loss = 20.83134 Val Loss = 20.54888
2023-05-31 11:27:02.997425 Epoch 11  	Train Loss = 20.34948 Val Loss = 20.22765
2023-05-31 11:27:10.624716 Epoch 12  	Train Loss = 20.31273 Val Loss = 20.20869
2023-05-31 11:27:18.211035 Epoch 13  	Train Loss = 20.30855 Val Loss = 20.20490
2023-05-31 11:27:25.808834 Epoch 14  	Train Loss = 20.29942 Val Loss = 20.22471
2023-05-31 11:27:33.384212 Epoch 15  	Train Loss = 20.31842 Val Loss = 20.23120
2023-05-31 11:27:40.939012 Epoch 16  	Train Loss = 20.28644 Val Loss = 20.20643
2023-05-31 11:27:48.350609 Epoch 17  	Train Loss = 20.29925 Val Loss = 20.20115
2023-05-31 11:27:55.888174 Epoch 18  	Train Loss = 20.28184 Val Loss = 20.26618
2023-05-31 11:28:03.456428 Epoch 19  	Train Loss = 20.26952 Val Loss = 20.18888
2023-05-31 11:28:10.961939 Epoch 20  	Train Loss = 20.29636 Val Loss = 20.27178
2023-05-31 11:28:18.575060 Epoch 21  	Train Loss = 20.27380 Val Loss = 20.22657
2023-05-31 11:28:26.344245 Epoch 22  	Train Loss = 20.26545 Val Loss = 20.14314
2023-05-31 11:28:34.018415 Epoch 23  	Train Loss = 20.27144 Val Loss = 20.15114
2023-05-31 11:28:41.680138 Epoch 24  	Train Loss = 20.26027 Val Loss = 20.16663
2023-05-31 11:28:49.243964 Epoch 25  	Train Loss = 20.24216 Val Loss = 20.21042
2023-05-31 11:28:56.908836 Epoch 26  	Train Loss = 20.25203 Val Loss = 20.15753
2023-05-31 11:29:04.502491 Epoch 27  	Train Loss = 20.24533 Val Loss = 20.18713
2023-05-31 11:29:12.117914 Epoch 28  	Train Loss = 20.24190 Val Loss = 20.23141
2023-05-31 11:29:19.784500 Epoch 29  	Train Loss = 20.23995 Val Loss = 20.16895
2023-05-31 11:29:27.393527 Epoch 30  	Train Loss = 20.23632 Val Loss = 20.17265
2023-05-31 11:29:34.985550 Epoch 31  	Train Loss = 20.15415 Val Loss = 20.09996
2023-05-31 11:29:42.653509 Epoch 32  	Train Loss = 20.15120 Val Loss = 20.09055
2023-05-31 11:29:50.285809 Epoch 33  	Train Loss = 20.14768 Val Loss = 20.09278
2023-05-31 11:29:57.935054 Epoch 34  	Train Loss = 20.14492 Val Loss = 20.09756
2023-05-31 11:30:05.614425 Epoch 35  	Train Loss = 20.14116 Val Loss = 20.09479
2023-05-31 11:30:13.199087 Epoch 36  	Train Loss = 20.14818 Val Loss = 20.10283
2023-05-31 11:30:20.855687 Epoch 37  	Train Loss = 20.14887 Val Loss = 20.09260
2023-05-31 11:30:28.617551 Epoch 38  	Train Loss = 20.14037 Val Loss = 20.09005
2023-05-31 11:30:36.346695 Epoch 39  	Train Loss = 20.14187 Val Loss = 20.09380
2023-05-31 11:30:43.693483 Epoch 40  	Train Loss = 20.14288 Val Loss = 20.09096
2023-05-31 11:30:51.156683 Epoch 41  	Train Loss = 20.14211 Val Loss = 20.08593
2023-05-31 11:30:58.748968 Epoch 42  	Train Loss = 20.13789 Val Loss = 20.08688
2023-05-31 11:31:06.558957 Epoch 43  	Train Loss = 20.13844 Val Loss = 20.08632
2023-05-31 11:31:14.294222 Epoch 44  	Train Loss = 20.13841 Val Loss = 20.07879
2023-05-31 11:31:21.879799 Epoch 45  	Train Loss = 20.13916 Val Loss = 20.08479
2023-05-31 11:31:29.538657 Epoch 46  	Train Loss = 20.13683 Val Loss = 20.09489
2023-05-31 11:31:37.188841 Epoch 47  	Train Loss = 20.13963 Val Loss = 20.09327
2023-05-31 11:31:44.782743 Epoch 48  	Train Loss = 20.14139 Val Loss = 20.08176
2023-05-31 11:31:52.386449 Epoch 49  	Train Loss = 20.13610 Val Loss = 20.09738
2023-05-31 11:32:00.253489 Epoch 50  	Train Loss = 20.13311 Val Loss = 20.10098
2023-05-31 11:32:07.976607 Epoch 51  	Train Loss = 20.13483 Val Loss = 20.08229
2023-05-31 11:32:15.572414 Epoch 52  	Train Loss = 20.13824 Val Loss = 20.08026
2023-05-31 11:32:23.193155 Epoch 53  	Train Loss = 20.13834 Val Loss = 20.09000
2023-05-31 11:32:30.871166 Epoch 54  	Train Loss = 20.13067 Val Loss = 20.07585
2023-05-31 11:32:38.571979 Epoch 55  	Train Loss = 20.13534 Val Loss = 20.08649
2023-05-31 11:32:46.196548 Epoch 56  	Train Loss = 20.13218 Val Loss = 20.08821
2023-05-31 11:32:53.900111 Epoch 57  	Train Loss = 20.13647 Val Loss = 20.08230
2023-05-31 11:33:01.527803 Epoch 58  	Train Loss = 20.12866 Val Loss = 20.08472
2023-05-31 11:33:09.200843 Epoch 59  	Train Loss = 20.12932 Val Loss = 20.07952
2023-05-31 11:33:16.881460 Epoch 60  	Train Loss = 20.13385 Val Loss = 20.07739
2023-05-31 11:33:24.566219 Epoch 61  	Train Loss = 20.12881 Val Loss = 20.08367
2023-05-31 11:33:32.256456 Epoch 62  	Train Loss = 20.13120 Val Loss = 20.08534
2023-05-31 11:33:39.958258 Epoch 63  	Train Loss = 20.13004 Val Loss = 20.08043
2023-05-31 11:33:47.641704 Epoch 64  	Train Loss = 20.13128 Val Loss = 20.08112
Early stopping at epoch: 64
Best at epoch 54:
Train Loss = 20.13067
Train RMSE = 32.16954, MAE = 20.68826, MAPE = 19.02429
Val Loss = 20.07585
Val RMSE = 32.10994, MAE = 20.65661, MAPE = 18.92752
--------- Test ---------
All Steps RMSE = 32.96412, MAE = 19.96500, MAPE = 19.15571
Step 1 RMSE = 22.01721, MAE = 13.39993, MAPE = 13.09849
Step 2 RMSE = 24.47752, MAE = 14.85615, MAPE = 14.37051
Step 3 RMSE = 27.03309, MAE = 16.17673, MAPE = 15.53401
Step 4 RMSE = 28.74632, MAE = 17.26962, MAPE = 16.41623
Step 5 RMSE = 30.45171, MAE = 18.30524, MAPE = 17.35021
Step 6 RMSE = 31.96307, MAE = 19.40543, MAPE = 18.53476
Step 7 RMSE = 33.50107, MAE = 20.55640, MAPE = 19.56735
Step 8 RMSE = 35.03990, MAE = 21.67383, MAPE = 20.64361
Step 9 RMSE = 36.50077, MAE = 22.73669, MAPE = 21.69608
Step 10 RMSE = 38.10490, MAE = 23.80482, MAPE = 22.83919
Step 11 RMSE = 39.66331, MAE = 24.99522, MAPE = 24.13205
Step 12 RMSE = 41.73759, MAE = 26.40004, MAPE = 25.68613
Inference time: 0.40 s
