METRLA
Trainset:	x-(23974, 12, 207, 1)	y-(23974, 12, 207, 1)
Valset:  	x-(3425, 12, 207, 1)  	y-(3425, 12, 207, 1)
Testset:	x-(6850, 12, 207, 1)	y-(6850, 12, 207, 1)

--------- WaveNet ---------
{
    "num_nodes": 207,
    "in_steps": 12,
    "out_steps": 12,
    "lr": 0.01,
    "weight_decay": 0,
    "milestones": [
        10,
        30
    ],
    "clip_grad": 0,
    "batch_size": 64,
    "max_epochs": 200,
    "use_cl": false,
    "model_args": {
        "in_channels": 1,
        "out_channels": 12,
        "hidden_channels": 16,
        "kernel_size": 2,
        "num_blocks": 4,
        "num_layers": 2
    }
}
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
WaveNet                                  [64, 12, 207, 1]          --
├─Conv2d: 1-1                            [64, 16, 207, 13]         32
├─ModuleList: 1-2                        --                        --
│    └─ConvBlock: 2-1                    [64, 16, 207, 10]         --
│    │    └─ModuleList: 3-5              --                        (recursive)
│    │    └─ModuleList: 3-6              --                        (recursive)
│    │    └─ModuleList: 3-7              --                        (recursive)
│    │    └─ModuleList: 3-8              --                        (recursive)
│    │    └─ModuleList: 3-5              --                        (recursive)
│    │    └─ModuleList: 3-6              --                        (recursive)
│    │    └─ModuleList: 3-7              --                        (recursive)
│    │    └─ModuleList: 3-8              --                        (recursive)
│    └─ConvBlock: 2-2                    [64, 16, 207, 7]          --
│    │    └─ModuleList: 3-13             --                        (recursive)
│    │    └─ModuleList: 3-14             --                        (recursive)
│    │    └─ModuleList: 3-15             --                        (recursive)
│    │    └─ModuleList: 3-16             --                        (recursive)
│    │    └─ModuleList: 3-13             --                        (recursive)
│    │    └─ModuleList: 3-14             --                        (recursive)
│    │    └─ModuleList: 3-15             --                        (recursive)
│    │    └─ModuleList: 3-16             --                        (recursive)
│    └─ConvBlock: 2-3                    [64, 16, 207, 4]          --
│    │    └─ModuleList: 3-21             --                        (recursive)
│    │    └─ModuleList: 3-22             --                        (recursive)
│    │    └─ModuleList: 3-23             --                        (recursive)
│    │    └─ModuleList: 3-24             --                        (recursive)
│    │    └─ModuleList: 3-21             --                        (recursive)
│    │    └─ModuleList: 3-22             --                        (recursive)
│    │    └─ModuleList: 3-23             --                        (recursive)
│    │    └─ModuleList: 3-24             --                        (recursive)
│    └─ConvBlock: 2-4                    [64, 16, 207, 1]          --
│    │    └─ModuleList: 3-29             --                        (recursive)
│    │    └─ModuleList: 3-30             --                        (recursive)
│    │    └─ModuleList: 3-31             --                        (recursive)
│    │    └─ModuleList: 3-32             --                        (recursive)
│    │    └─ModuleList: 3-29             --                        (recursive)
│    │    └─ModuleList: 3-30             --                        (recursive)
│    │    └─ModuleList: 3-31             --                        (recursive)
│    │    └─ModuleList: 3-32             --                        (recursive)
├─Sequential: 1-3                        [64, 12, 207, 1]          --
│    └─ReLU: 2-5                         [64, 16, 207, 1]          --
│    └─Conv2d: 2-6                       [64, 16, 207, 1]          272
│    └─ReLU: 2-7                         [64, 16, 207, 1]          --
│    └─Conv2d: 2-8                       [64, 12, 207, 1]          204
==========================================================================================
Total params: 13,308
Trainable params: 13,308
Non-trainable params: 0
Total mult-adds (G): 1.11
==========================================================================================
Input size (MB): 0.64
Forward/backward pass size (MB): 377.73
Params size (MB): 0.05
Estimated Total Size (MB): 378.42
==========================================================================================

Loss: MaskedMAELoss

2023-05-31 10:22:16.404499 Epoch 1  	Train Loss = 4.13541 Val Loss = 3.60012
2023-05-31 10:22:29.708647 Epoch 2  	Train Loss = 3.68930 Val Loss = 3.45179
2023-05-31 10:22:41.373961 Epoch 3  	Train Loss = 3.79482 Val Loss = 3.46696
2023-05-31 10:22:53.242511 Epoch 4  	Train Loss = 3.71435 Val Loss = 3.43183
2023-05-31 10:23:04.771012 Epoch 5  	Train Loss = 3.68533 Val Loss = 3.41175
2023-05-31 10:23:16.427359 Epoch 6  	Train Loss = 3.66710 Val Loss = 3.41811
2023-05-31 10:23:28.521799 Epoch 7  	Train Loss = 3.68709 Val Loss = 3.40535
2023-05-31 10:23:40.176204 Epoch 8  	Train Loss = 3.62882 Val Loss = 3.40842
2023-05-31 10:23:50.688825 Epoch 9  	Train Loss = 3.62323 Val Loss = 3.41258
2023-05-31 10:24:02.230471 Epoch 10  	Train Loss = 3.62601 Val Loss = 3.40121
2023-05-31 10:24:13.981312 Epoch 11  	Train Loss = 3.59740 Val Loss = 3.39074
2023-05-31 10:24:25.545380 Epoch 12  	Train Loss = 3.59592 Val Loss = 3.38805
2023-05-31 10:24:36.933971 Epoch 13  	Train Loss = 3.59430 Val Loss = 3.39452
2023-05-31 10:24:49.180784 Epoch 14  	Train Loss = 3.59436 Val Loss = 3.38682
2023-05-31 10:25:00.851569 Epoch 15  	Train Loss = 3.59456 Val Loss = 3.38825
2023-05-31 10:25:12.599501 Epoch 16  	Train Loss = 3.59267 Val Loss = 3.38786
2023-05-31 10:25:24.060939 Epoch 17  	Train Loss = 3.59254 Val Loss = 3.38651
2023-05-31 10:25:35.694926 Epoch 18  	Train Loss = 3.59109 Val Loss = 3.38799
2023-05-31 10:25:47.251862 Epoch 19  	Train Loss = 3.58986 Val Loss = 3.38599
2023-05-31 10:25:58.776383 Epoch 20  	Train Loss = 3.58988 Val Loss = 3.38721
2023-05-31 10:26:10.062856 Epoch 21  	Train Loss = 3.59003 Val Loss = 3.38603
2023-05-31 10:26:21.624182 Epoch 22  	Train Loss = 3.58869 Val Loss = 3.39034
2023-05-31 10:26:35.345697 Epoch 23  	Train Loss = 3.58758 Val Loss = 3.38537
2023-05-31 10:26:47.387564 Epoch 24  	Train Loss = 3.58721 Val Loss = 3.39004
2023-05-31 10:26:58.558214 Epoch 25  	Train Loss = 3.58732 Val Loss = 3.38384
2023-05-31 10:27:10.206416 Epoch 26  	Train Loss = 3.58614 Val Loss = 3.38216
2023-05-31 10:27:22.564738 Epoch 27  	Train Loss = 3.58605 Val Loss = 3.38244
2023-05-31 10:27:34.204823 Epoch 28  	Train Loss = 3.58575 Val Loss = 3.39058
2023-05-31 10:27:45.869345 Epoch 29  	Train Loss = 3.58601 Val Loss = 3.38716
2023-05-31 10:27:57.760993 Epoch 30  	Train Loss = 3.58443 Val Loss = 3.38427
2023-05-31 10:28:09.453823 Epoch 31  	Train Loss = 3.57966 Val Loss = 3.38090
2023-05-31 10:28:21.226553 Epoch 32  	Train Loss = 3.57923 Val Loss = 3.37993
2023-05-31 10:28:32.682419 Epoch 33  	Train Loss = 3.57879 Val Loss = 3.37997
2023-05-31 10:28:44.327233 Epoch 34  	Train Loss = 3.57841 Val Loss = 3.37981
2023-05-31 10:28:56.195948 Epoch 35  	Train Loss = 3.57863 Val Loss = 3.37967
2023-05-31 10:29:07.766693 Epoch 36  	Train Loss = 3.57772 Val Loss = 3.37967
2023-05-31 10:29:19.407886 Epoch 37  	Train Loss = 3.57838 Val Loss = 3.38073
2023-05-31 10:29:30.962871 Epoch 38  	Train Loss = 3.57749 Val Loss = 3.37925
2023-05-31 10:29:42.958791 Epoch 39  	Train Loss = 3.57791 Val Loss = 3.38073
2023-05-31 10:29:54.724586 Epoch 40  	Train Loss = 3.57754 Val Loss = 3.38128
2023-05-31 10:30:06.468597 Epoch 41  	Train Loss = 3.57733 Val Loss = 3.38013
2023-05-31 10:30:17.909306 Epoch 42  	Train Loss = 3.57740 Val Loss = 3.37996
2023-05-31 10:30:29.787283 Epoch 43  	Train Loss = 3.57790 Val Loss = 3.37946
2023-05-31 10:30:41.572943 Epoch 44  	Train Loss = 3.57745 Val Loss = 3.37970
2023-05-31 10:30:54.892158 Epoch 45  	Train Loss = 3.57776 Val Loss = 3.38091
2023-05-31 10:31:06.429351 Epoch 46  	Train Loss = 3.57721 Val Loss = 3.37979
2023-05-31 10:31:17.960171 Epoch 47  	Train Loss = 3.57739 Val Loss = 3.37885
2023-05-31 10:31:29.529397 Epoch 48  	Train Loss = 3.57773 Val Loss = 3.37960
2023-05-31 10:31:41.285170 Epoch 49  	Train Loss = 3.57827 Val Loss = 3.37994
2023-05-31 10:31:52.403440 Epoch 50  	Train Loss = 3.57794 Val Loss = 3.38027
2023-05-31 10:32:03.128911 Epoch 51  	Train Loss = 3.57682 Val Loss = 3.37989
2023-05-31 10:32:14.592739 Epoch 52  	Train Loss = 3.57779 Val Loss = 3.38006
2023-05-31 10:32:25.561501 Epoch 53  	Train Loss = 3.57748 Val Loss = 3.38061
2023-05-31 10:32:37.041134 Epoch 54  	Train Loss = 3.57705 Val Loss = 3.37916
2023-05-31 10:32:48.410186 Epoch 55  	Train Loss = 3.57767 Val Loss = 3.38024
2023-05-31 10:33:00.113982 Epoch 56  	Train Loss = 3.57656 Val Loss = 3.37939
2023-05-31 10:33:11.639014 Epoch 57  	Train Loss = 3.57670 Val Loss = 3.37974
Early stopping at epoch: 57
Best at epoch 47:
Train Loss = 3.57739
Train RMSE = 7.33852, MAE = 3.57643, MAPE = 9.85762
Val Loss = 3.37885
Val RMSE = 7.22480, MAE = 3.42136, MAPE = 9.74776
--------- Test ---------
All Steps RMSE = 7.71078, MAE = 3.79362, MAPE = 10.77444
Step 1 RMSE = 4.30778, MAE = 2.42025, MAPE = 5.93226
Step 2 RMSE = 5.35307, MAE = 2.78914, MAPE = 7.15838
Step 3 RMSE = 6.07949, MAE = 3.07184, MAPE = 8.13694
Step 4 RMSE = 6.67127, MAE = 3.32009, MAPE = 9.02060
Step 5 RMSE = 7.17488, MAE = 3.54869, MAPE = 9.83880
Step 6 RMSE = 7.62949, MAE = 3.76706, MAPE = 10.62467
Step 7 RMSE = 8.03817, MAE = 3.97253, MAPE = 11.37598
Step 8 RMSE = 8.41193, MAE = 4.16716, MAPE = 12.09345
Step 9 RMSE = 8.74975, MAE = 4.35304, MAPE = 12.78899
Step 10 RMSE = 9.06688, MAE = 4.53228, MAPE = 13.45102
Step 11 RMSE = 9.36808, MAE = 4.70512, MAPE = 14.10697
Step 12 RMSE = 9.65464, MAE = 4.87642, MAPE = 14.76573
Inference time: 0.50 s
