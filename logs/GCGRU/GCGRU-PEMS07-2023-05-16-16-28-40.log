PEMS07
Trainset:	x-(16921, 12, 883, 1)	y-(16921, 12, 883, 1)
Valset:  	x-(5640, 12, 883, 1)  	y-(5640, 12, 883, 1)
Testset:	x-(5640, 12, 883, 1)	y-(5640, 12, 883, 1)

--------- GCGRU ---------
{
    "num_nodes": 883,
    "in_steps": 12,
    "out_steps": 12,
    "lr": 0.001,
    "weight_decay": 0,
    "milestones": [
        12,
        50
    ],
    "clip_grad": 0,
    "batch_size": 64,
    "max_epochs": 200,
    "use_cl": false,
    "pass_device": true,
    "model_args": {
        "num_nodes": 883,
        "input_dim": 1,
        "output_dim": 1,
        "horizon": 12,
        "rnn_units": 64,
        "num_layers": 1,
        "cheb_k": 3,
        "adj_path": "../data/PEMS07/adj_PEMS07.pkl",
        "adj_type": "doubletransition",
        "device": "cuda:0"
    }
}
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
GCGRU                                    [64, 12, 883, 1]          --
├─Encoder: 1-1                           [64, 883, 64]             --
│    └─ModuleList: 2-1                   --                        --
│    │    └─GRUCell: 3-1                 [64, 883, 64]             75,072
│    │    └─GRUCell: 3-2                 [64, 883, 64]             (recursive)
│    │    └─GRUCell: 3-3                 [64, 883, 64]             (recursive)
│    │    └─GRUCell: 3-4                 [64, 883, 64]             (recursive)
│    │    └─GRUCell: 3-5                 [64, 883, 64]             (recursive)
│    │    └─GRUCell: 3-6                 [64, 883, 64]             (recursive)
│    │    └─GRUCell: 3-7                 [64, 883, 64]             (recursive)
│    │    └─GRUCell: 3-8                 [64, 883, 64]             (recursive)
│    │    └─GRUCell: 3-9                 [64, 883, 64]             (recursive)
│    │    └─GRUCell: 3-10                [64, 883, 64]             (recursive)
│    │    └─GRUCell: 3-11                [64, 883, 64]             (recursive)
│    │    └─GRUCell: 3-12                [64, 883, 64]             (recursive)
├─Decoder: 1-2                           [64, 883, 64]             --
│    └─ModuleList: 2-24                  --                        (recursive)
│    │    └─GRUCell: 3-13                [64, 883, 64]             75,072
├─Sequential: 1-3                        [64, 883, 1]              --
│    └─Linear: 2-3                       [64, 883, 1]              65
├─Decoder: 1-4                           [64, 883, 64]             (recursive)
│    └─ModuleList: 2-24                  --                        (recursive)
│    │    └─GRUCell: 3-14                [64, 883, 64]             (recursive)
├─Sequential: 1-5                        [64, 883, 1]              (recursive)
│    └─Linear: 2-5                       [64, 883, 1]              (recursive)
├─Decoder: 1-6                           [64, 883, 64]             (recursive)
│    └─ModuleList: 2-24                  --                        (recursive)
│    │    └─GRUCell: 3-15                [64, 883, 64]             (recursive)
├─Sequential: 1-7                        [64, 883, 1]              (recursive)
│    └─Linear: 2-7                       [64, 883, 1]              (recursive)
├─Decoder: 1-8                           [64, 883, 64]             (recursive)
│    └─ModuleList: 2-24                  --                        (recursive)
│    │    └─GRUCell: 3-16                [64, 883, 64]             (recursive)
├─Sequential: 1-9                        [64, 883, 1]              (recursive)
│    └─Linear: 2-9                       [64, 883, 1]              (recursive)
├─Decoder: 1-10                          [64, 883, 64]             (recursive)
│    └─ModuleList: 2-24                  --                        (recursive)
│    │    └─GRUCell: 3-17                [64, 883, 64]             (recursive)
├─Sequential: 1-11                       [64, 883, 1]              (recursive)
│    └─Linear: 2-11                      [64, 883, 1]              (recursive)
├─Decoder: 1-12                          [64, 883, 64]             (recursive)
│    └─ModuleList: 2-24                  --                        (recursive)
│    │    └─GRUCell: 3-18                [64, 883, 64]             (recursive)
├─Sequential: 1-13                       [64, 883, 1]              (recursive)
│    └─Linear: 2-13                      [64, 883, 1]              (recursive)
├─Decoder: 1-14                          [64, 883, 64]             (recursive)
│    └─ModuleList: 2-24                  --                        (recursive)
│    │    └─GRUCell: 3-19                [64, 883, 64]             (recursive)
├─Sequential: 1-15                       [64, 883, 1]              (recursive)
│    └─Linear: 2-15                      [64, 883, 1]              (recursive)
├─Decoder: 1-16                          [64, 883, 64]             (recursive)
│    └─ModuleList: 2-24                  --                        (recursive)
│    │    └─GRUCell: 3-20                [64, 883, 64]             (recursive)
├─Sequential: 1-17                       [64, 883, 1]              (recursive)
│    └─Linear: 2-17                      [64, 883, 1]              (recursive)
├─Decoder: 1-18                          [64, 883, 64]             (recursive)
│    └─ModuleList: 2-24                  --                        (recursive)
│    │    └─GRUCell: 3-21                [64, 883, 64]             (recursive)
├─Sequential: 1-19                       [64, 883, 1]              (recursive)
│    └─Linear: 2-19                      [64, 883, 1]              (recursive)
├─Decoder: 1-20                          [64, 883, 64]             (recursive)
│    └─ModuleList: 2-24                  --                        (recursive)
│    │    └─GRUCell: 3-22                [64, 883, 64]             (recursive)
├─Sequential: 1-21                       [64, 883, 1]              (recursive)
│    └─Linear: 2-21                      [64, 883, 1]              (recursive)
├─Decoder: 1-22                          [64, 883, 64]             (recursive)
│    └─ModuleList: 2-24                  --                        (recursive)
│    │    └─GRUCell: 3-23                [64, 883, 64]             (recursive)
├─Sequential: 1-23                       [64, 883, 1]              (recursive)
│    └─Linear: 2-23                      [64, 883, 1]              (recursive)
├─Decoder: 1-24                          [64, 883, 64]             (recursive)
│    └─ModuleList: 2-24                  --                        (recursive)
│    │    └─GRUCell: 3-24                [64, 883, 64]             (recursive)
├─Sequential: 1-25                       [64, 883, 1]              (recursive)
│    └─Linear: 2-25                      [64, 883, 1]              (recursive)
==========================================================================================
Total params: 150,209
Trainable params: 150,209
Non-trainable params: 0
Total mult-adds (M): 0.05
==========================================================================================
Input size (MB): 2.71
Forward/backward pass size (MB): 2088.68
Params size (MB): 0.60
Estimated Total Size (MB): 2092.00
==========================================================================================

Loss: HuberLoss

2023-05-16 16:31:50.899341 Epoch 1  	Train Loss = 38.75301 Val Loss = 30.08040
2023-05-16 16:35:11.199182 Epoch 2  	Train Loss = 29.95783 Val Loss = 29.90269
2023-05-16 16:38:36.122055 Epoch 3  	Train Loss = 29.40825 Val Loss = 29.29194
2023-05-16 16:41:55.018334 Epoch 4  	Train Loss = 29.09470 Val Loss = 27.80288
2023-05-16 16:45:13.241516 Epoch 5  	Train Loss = 28.94253 Val Loss = 27.68812
2023-05-16 16:48:31.335147 Epoch 6  	Train Loss = 28.62221 Val Loss = 27.56096
2023-05-16 16:51:55.308961 Epoch 7  	Train Loss = 28.51142 Val Loss = 27.64440
2023-05-16 16:55:12.896415 Epoch 8  	Train Loss = 28.29990 Val Loss = 27.38953
2023-05-16 16:58:29.362646 Epoch 9  	Train Loss = 28.31354 Val Loss = 27.65375
2023-05-16 17:01:45.227086 Epoch 10  	Train Loss = 28.12588 Val Loss = 27.08990
2023-05-16 17:05:07.300541 Epoch 11  	Train Loss = 27.98368 Val Loss = 27.62729
2023-05-16 17:08:26.359719 Epoch 12  	Train Loss = 27.83868 Val Loss = 27.22932
2023-05-16 17:11:41.838495 Epoch 13  	Train Loss = 27.36648 Val Loss = 26.57206
2023-05-16 17:14:56.989355 Epoch 14  	Train Loss = 27.31581 Val Loss = 26.62550
2023-05-16 17:18:15.021808 Epoch 15  	Train Loss = 27.27626 Val Loss = 26.59278
2023-05-16 17:21:40.451550 Epoch 16  	Train Loss = 27.25741 Val Loss = 26.54898
2023-05-16 17:24:56.212234 Epoch 17  	Train Loss = 27.22263 Val Loss = 26.54085
2023-05-16 17:28:09.888513 Epoch 18  	Train Loss = 27.18825 Val Loss = 26.47250
2023-05-16 17:31:23.574155 Epoch 19  	Train Loss = 27.15982 Val Loss = 26.42192
2023-05-16 17:34:39.730450 Epoch 20  	Train Loss = 27.13071 Val Loss = 26.36534
2023-05-16 17:37:51.579468 Epoch 21  	Train Loss = 27.10201 Val Loss = 26.37986
2023-05-16 17:40:58.569917 Epoch 22  	Train Loss = 27.06985 Val Loss = 26.52790
2023-05-16 17:44:03.984898 Epoch 23  	Train Loss = 27.04480 Val Loss = 26.36949
2023-05-16 17:47:13.178302 Epoch 24  	Train Loss = 27.00945 Val Loss = 26.28460
2023-05-16 17:50:26.647645 Epoch 25  	Train Loss = 27.00586 Val Loss = 26.28392
2023-05-16 17:53:34.009122 Epoch 26  	Train Loss = 26.96544 Val Loss = 26.29644
2023-05-16 17:56:35.736631 Epoch 27  	Train Loss = 26.91239 Val Loss = 26.28180
2023-05-16 17:59:35.123863 Epoch 28  	Train Loss = 26.89855 Val Loss = 26.16908
2023-05-16 18:02:31.023339 Epoch 29  	Train Loss = 26.85929 Val Loss = 26.13021
2023-05-16 18:05:29.908039 Epoch 30  	Train Loss = 26.83031 Val Loss = 26.12663
2023-05-16 18:08:32.916185 Epoch 31  	Train Loss = 26.83862 Val Loss = 26.13731
2023-05-16 18:11:39.989408 Epoch 32  	Train Loss = 26.82060 Val Loss = 26.08495
2023-05-16 18:14:39.472958 Epoch 33  	Train Loss = 26.75095 Val Loss = 26.15894
2023-05-16 18:17:38.974030 Epoch 34  	Train Loss = 26.73205 Val Loss = 26.05252
2023-05-16 18:20:43.653740 Epoch 35  	Train Loss = 26.69044 Val Loss = 26.03715
2023-05-16 18:23:49.171995 Epoch 36  	Train Loss = 26.69223 Val Loss = 25.98244
2023-05-16 18:26:54.100024 Epoch 37  	Train Loss = 26.63536 Val Loss = 25.93862
2023-05-16 18:29:50.344076 Epoch 38  	Train Loss = 26.66188 Val Loss = 25.96240
2023-05-16 18:32:49.146551 Epoch 39  	Train Loss = 26.61016 Val Loss = 25.95166
2023-05-16 18:35:52.202904 Epoch 40  	Train Loss = 26.58673 Val Loss = 25.96721
2023-05-16 18:38:56.154716 Epoch 41  	Train Loss = 26.57554 Val Loss = 25.87129
2023-05-16 18:41:58.581732 Epoch 42  	Train Loss = 26.55576 Val Loss = 25.84478
2023-05-16 18:44:54.899787 Epoch 43  	Train Loss = 26.50088 Val Loss = 25.93049
2023-05-16 18:47:56.164772 Epoch 44  	Train Loss = 26.49843 Val Loss = 25.83636
2023-05-16 18:51:00.492334 Epoch 45  	Train Loss = 26.46762 Val Loss = 25.79509
2023-05-16 18:54:06.056804 Epoch 46  	Train Loss = 26.43083 Val Loss = 25.87217
2023-05-16 18:57:06.563391 Epoch 47  	Train Loss = 26.41450 Val Loss = 25.87496
2023-05-16 19:00:03.848767 Epoch 48  	Train Loss = 26.40242 Val Loss = 25.81204
2023-05-16 19:03:07.163516 Epoch 49  	Train Loss = 26.39167 Val Loss = 25.82170
2023-05-16 19:06:11.970393 Epoch 50  	Train Loss = 26.33673 Val Loss = 25.74337
2023-05-16 19:09:19.082934 Epoch 51  	Train Loss = 26.21670 Val Loss = 25.64956
2023-05-16 19:12:18.048840 Epoch 52  	Train Loss = 26.20675 Val Loss = 25.64664
2023-05-16 19:15:16.385364 Epoch 53  	Train Loss = 26.20863 Val Loss = 25.64869
2023-05-16 19:18:12.987482 Epoch 54  	Train Loss = 26.20278 Val Loss = 25.65807
2023-05-16 19:21:10.352940 Epoch 55  	Train Loss = 26.19568 Val Loss = 25.63017
2023-05-16 19:24:16.463344 Epoch 56  	Train Loss = 26.20051 Val Loss = 25.65018
2023-05-16 19:27:17.627687 Epoch 57  	Train Loss = 26.19114 Val Loss = 25.66919
2023-05-16 19:30:16.965703 Epoch 58  	Train Loss = 26.18782 Val Loss = 25.70216
2023-05-16 19:33:16.917666 Epoch 59  	Train Loss = 26.19288 Val Loss = 25.62819
2023-05-16 19:36:19.320219 Epoch 60  	Train Loss = 26.19220 Val Loss = 25.64097
2023-05-16 19:39:27.434652 Epoch 61  	Train Loss = 26.17883 Val Loss = 25.61453
2023-05-16 19:42:28.932225 Epoch 62  	Train Loss = 26.18351 Val Loss = 25.62022
2023-05-16 19:45:28.890807 Epoch 63  	Train Loss = 26.17283 Val Loss = 25.67081
2023-05-16 19:48:28.629631 Epoch 64  	Train Loss = 26.16662 Val Loss = 25.65461
2023-05-16 19:51:32.196400 Epoch 65  	Train Loss = 26.16085 Val Loss = 25.65527
2023-05-16 19:54:38.645934 Epoch 66  	Train Loss = 26.16726 Val Loss = 25.60900
2023-05-16 19:57:39.647610 Epoch 67  	Train Loss = 26.15777 Val Loss = 25.61241
2023-05-16 20:00:38.616106 Epoch 68  	Train Loss = 26.15021 Val Loss = 25.61611
2023-05-16 20:03:38.159505 Epoch 69  	Train Loss = 26.14850 Val Loss = 25.59748
2023-05-16 20:06:43.510072 Epoch 70  	Train Loss = 26.15441 Val Loss = 25.60824
2023-05-16 20:09:47.848810 Epoch 71  	Train Loss = 26.15709 Val Loss = 25.60275
2023-05-16 20:12:48.025049 Epoch 72  	Train Loss = 26.15642 Val Loss = 25.59578
2023-05-16 20:15:46.571274 Epoch 73  	Train Loss = 26.13760 Val Loss = 25.59055
2023-05-16 20:18:47.779767 Epoch 74  	Train Loss = 26.13631 Val Loss = 25.61735
2023-05-16 20:21:56.878027 Epoch 75  	Train Loss = 26.14105 Val Loss = 25.63367
2023-05-16 20:25:00.505485 Epoch 76  	Train Loss = 26.12977 Val Loss = 25.64422
2023-05-16 20:28:00.997219 Epoch 77  	Train Loss = 26.12508 Val Loss = 25.58367
2023-05-16 20:31:00.110219 Epoch 78  	Train Loss = 26.11222 Val Loss = 25.59706
2023-05-16 20:34:03.375474 Epoch 79  	Train Loss = 26.11738 Val Loss = 25.58615
2023-05-16 20:37:12.683047 Epoch 80  	Train Loss = 26.12270 Val Loss = 25.60387
2023-05-16 20:40:15.520600 Epoch 81  	Train Loss = 26.12256 Val Loss = 25.57372
2023-05-16 20:43:16.460038 Epoch 82  	Train Loss = 26.10442 Val Loss = 25.56982
2023-05-16 20:46:16.462428 Epoch 83  	Train Loss = 26.10885 Val Loss = 25.59420
2023-05-16 20:49:22.566989 Epoch 84  	Train Loss = 26.11202 Val Loss = 25.56663
2023-05-16 20:52:30.954736 Epoch 85  	Train Loss = 26.10367 Val Loss = 25.57735
2023-05-16 20:55:32.533102 Epoch 86  	Train Loss = 26.09192 Val Loss = 25.58237
2023-05-16 20:58:31.571982 Epoch 87  	Train Loss = 26.10111 Val Loss = 25.55483
2023-05-16 21:01:29.483391 Epoch 88  	Train Loss = 26.09640 Val Loss = 25.55015
2023-05-16 21:04:24.779876 Epoch 89  	Train Loss = 26.08453 Val Loss = 25.57043
2023-05-16 21:07:24.096377 Epoch 90  	Train Loss = 26.09016 Val Loss = 25.55426
2023-05-16 21:10:26.938425 Epoch 91  	Train Loss = 26.08333 Val Loss = 25.56311
2023-05-16 21:13:32.199380 Epoch 92  	Train Loss = 26.08001 Val Loss = 25.55342
2023-05-16 21:16:29.185291 Epoch 93  	Train Loss = 26.07839 Val Loss = 25.55207
2023-05-16 21:19:27.812645 Epoch 94  	Train Loss = 26.07172 Val Loss = 25.57105
2023-05-16 21:22:31.638148 Epoch 95  	Train Loss = 26.07499 Val Loss = 25.54824
2023-05-16 21:25:37.889340 Epoch 96  	Train Loss = 26.07391 Val Loss = 25.56123
2023-05-16 21:28:43.383855 Epoch 97  	Train Loss = 26.07200 Val Loss = 25.53748
2023-05-16 21:31:41.794905 Epoch 98  	Train Loss = 26.05382 Val Loss = 25.53710
2023-05-16 21:34:43.170191 Epoch 99  	Train Loss = 26.07045 Val Loss = 25.52833
2023-05-16 21:37:47.142498 Epoch 100  	Train Loss = 26.05854 Val Loss = 25.53845
2023-05-16 21:40:52.518301 Epoch 101  	Train Loss = 26.05573 Val Loss = 25.53630
2023-05-16 21:43:54.876897 Epoch 102  	Train Loss = 26.05965 Val Loss = 25.54886
2023-05-16 21:46:53.180098 Epoch 103  	Train Loss = 26.04463 Val Loss = 25.53485
2023-05-16 21:49:56.291280 Epoch 104  	Train Loss = 26.05031 Val Loss = 25.55363
2023-05-16 21:53:01.540048 Epoch 105  	Train Loss = 26.04947 Val Loss = 25.53431
2023-05-16 21:56:08.563264 Epoch 106  	Train Loss = 26.04578 Val Loss = 25.52539
2023-05-16 21:59:08.714903 Epoch 107  	Train Loss = 26.03356 Val Loss = 25.51354
2023-05-16 22:02:08.186887 Epoch 108  	Train Loss = 26.04127 Val Loss = 25.55065
2023-05-16 22:05:12.416583 Epoch 109  	Train Loss = 26.03868 Val Loss = 25.53256
2023-05-16 22:08:17.974733 Epoch 110  	Train Loss = 26.02502 Val Loss = 25.50850
2023-05-16 22:11:24.422631 Epoch 111  	Train Loss = 26.02994 Val Loss = 25.51234
2023-05-16 22:14:22.594735 Epoch 112  	Train Loss = 26.02915 Val Loss = 25.50270
2023-05-16 22:17:21.118081 Epoch 113  	Train Loss = 26.02610 Val Loss = 25.51112
2023-05-16 22:20:16.757655 Epoch 114  	Train Loss = 26.02011 Val Loss = 25.49839
2023-05-16 22:23:15.910677 Epoch 115  	Train Loss = 26.02038 Val Loss = 25.51975
2023-05-16 22:26:21.467401 Epoch 116  	Train Loss = 26.02086 Val Loss = 25.50247
2023-05-16 22:29:21.963531 Epoch 117  	Train Loss = 26.01884 Val Loss = 25.49598
2023-05-16 22:32:21.487984 Epoch 118  	Train Loss = 26.01267 Val Loss = 25.49247
2023-05-16 22:35:20.868322 Epoch 119  	Train Loss = 26.00594 Val Loss = 25.49649
2023-05-16 22:38:23.733369 Epoch 120  	Train Loss = 26.00463 Val Loss = 25.50585
2023-05-16 22:41:30.553949 Epoch 121  	Train Loss = 26.00437 Val Loss = 25.50031
2023-05-16 22:44:32.456839 Epoch 122  	Train Loss = 26.00203 Val Loss = 25.50115
2023-05-16 22:47:33.152492 Epoch 123  	Train Loss = 25.99729 Val Loss = 25.50150
2023-05-16 22:50:33.298406 Epoch 124  	Train Loss = 25.99468 Val Loss = 25.48001
2023-05-16 22:53:38.746374 Epoch 125  	Train Loss = 25.98461 Val Loss = 25.49998
2023-05-16 22:56:44.244297 Epoch 126  	Train Loss = 25.99044 Val Loss = 25.50565
2023-05-16 22:59:45.884039 Epoch 127  	Train Loss = 25.99030 Val Loss = 25.49934
2023-05-16 23:02:46.090659 Epoch 128  	Train Loss = 25.98782 Val Loss = 25.52658
2023-05-16 23:05:46.651702 Epoch 129  	Train Loss = 25.98157 Val Loss = 25.47487
2023-05-16 23:08:54.096235 Epoch 130  	Train Loss = 25.96831 Val Loss = 25.48546
2023-05-16 23:11:57.397772 Epoch 131  	Train Loss = 25.97506 Val Loss = 25.50033
2023-05-16 23:14:57.229269 Epoch 132  	Train Loss = 25.97377 Val Loss = 25.49413
2023-05-16 23:17:56.220365 Epoch 133  	Train Loss = 25.96688 Val Loss = 25.47792
2023-05-16 23:20:58.502260 Epoch 134  	Train Loss = 25.96862 Val Loss = 25.46791
2023-05-16 23:24:07.062863 Epoch 135  	Train Loss = 25.95344 Val Loss = 25.46221
2023-05-16 23:27:08.982996 Epoch 136  	Train Loss = 25.95449 Val Loss = 25.47569
2023-05-16 23:30:07.875703 Epoch 137  	Train Loss = 25.96512 Val Loss = 25.47414
2023-05-16 23:33:07.598581 Epoch 138  	Train Loss = 25.95227 Val Loss = 25.45964
2023-05-16 23:36:12.453260 Epoch 139  	Train Loss = 25.95590 Val Loss = 25.45346
2023-05-16 23:39:20.711841 Epoch 140  	Train Loss = 25.95859 Val Loss = 25.44613
2023-05-16 23:42:23.536228 Epoch 141  	Train Loss = 25.95123 Val Loss = 25.45418
2023-05-16 23:45:23.359167 Epoch 142  	Train Loss = 25.95914 Val Loss = 25.45157
2023-05-16 23:48:24.257475 Epoch 143  	Train Loss = 25.94382 Val Loss = 25.45576
2023-05-16 23:51:30.971177 Epoch 144  	Train Loss = 25.94985 Val Loss = 25.49012
2023-05-16 23:54:36.525371 Epoch 145  	Train Loss = 25.94886 Val Loss = 25.45969
2023-05-16 23:57:36.765852 Epoch 146  	Train Loss = 25.93977 Val Loss = 25.46360
2023-05-17 00:00:33.441071 Epoch 147  	Train Loss = 25.94137 Val Loss = 25.45182
2023-05-17 00:03:28.560694 Epoch 148  	Train Loss = 25.93470 Val Loss = 25.45367
2023-05-17 00:06:21.046668 Epoch 149  	Train Loss = 25.93346 Val Loss = 25.43476
2023-05-17 00:09:18.636626 Epoch 150  	Train Loss = 25.92753 Val Loss = 25.45848
2023-05-17 00:12:19.651949 Epoch 151  	Train Loss = 25.92740 Val Loss = 25.49094
2023-05-17 00:15:21.858423 Epoch 152  	Train Loss = 25.92915 Val Loss = 25.45085
2023-05-17 00:18:16.003233 Epoch 153  	Train Loss = 25.91760 Val Loss = 25.43469
2023-05-17 00:21:12.689548 Epoch 154  	Train Loss = 25.92512 Val Loss = 25.44956
2023-05-17 00:24:14.955743 Epoch 155  	Train Loss = 25.91916 Val Loss = 25.45101
2023-05-17 00:27:18.982826 Epoch 156  	Train Loss = 25.91166 Val Loss = 25.42378
2023-05-17 00:30:21.225534 Epoch 157  	Train Loss = 25.91512 Val Loss = 25.44413
2023-05-17 00:33:15.965708 Epoch 158  	Train Loss = 25.90655 Val Loss = 25.41319
2023-05-17 00:36:14.452267 Epoch 159  	Train Loss = 25.90862 Val Loss = 25.43528
2023-05-17 00:39:17.048835 Epoch 160  	Train Loss = 25.90503 Val Loss = 25.45918
2023-05-17 00:42:21.411479 Epoch 161  	Train Loss = 25.90411 Val Loss = 25.42448
2023-05-17 00:45:21.266516 Epoch 162  	Train Loss = 25.89160 Val Loss = 25.42129
2023-05-17 00:48:15.380277 Epoch 163  	Train Loss = 25.90465 Val Loss = 25.44626
2023-05-17 00:51:13.860548 Epoch 164  	Train Loss = 25.89280 Val Loss = 25.42005
2023-05-17 00:54:15.560734 Epoch 165  	Train Loss = 25.89903 Val Loss = 25.43499
2023-05-17 00:57:19.769033 Epoch 166  	Train Loss = 25.88382 Val Loss = 25.42134
2023-05-17 01:00:18.258890 Epoch 167  	Train Loss = 25.88475 Val Loss = 25.40897
2023-05-17 01:03:13.624300 Epoch 168  	Train Loss = 25.88372 Val Loss = 25.39919
2023-05-17 01:06:14.052175 Epoch 169  	Train Loss = 25.88403 Val Loss = 25.43764
2023-05-17 01:09:16.686287 Epoch 170  	Train Loss = 25.88067 Val Loss = 25.41123
2023-05-17 01:12:22.050868 Epoch 171  	Train Loss = 25.88389 Val Loss = 25.39024
2023-05-17 01:15:19.238327 Epoch 172  	Train Loss = 25.88027 Val Loss = 25.40098
2023-05-17 01:18:13.969593 Epoch 173  	Train Loss = 25.87080 Val Loss = 25.41492
2023-05-17 01:21:07.265055 Epoch 174  	Train Loss = 25.87486 Val Loss = 25.40277
2023-05-17 01:24:02.683481 Epoch 175  	Train Loss = 25.87053 Val Loss = 25.39081
2023-05-17 01:27:06.593499 Epoch 176  	Train Loss = 25.87243 Val Loss = 25.44116
2023-05-17 01:30:05.186727 Epoch 177  	Train Loss = 25.86818 Val Loss = 25.39880
2023-05-17 01:33:00.769618 Epoch 178  	Train Loss = 25.85964 Val Loss = 25.43963
2023-05-17 01:35:56.656913 Epoch 179  	Train Loss = 25.85722 Val Loss = 25.38362
2023-05-17 01:38:56.203173 Epoch 180  	Train Loss = 25.85165 Val Loss = 25.40456
2023-05-17 01:42:02.832379 Epoch 181  	Train Loss = 25.84968 Val Loss = 25.41513
2023-05-17 01:45:02.470682 Epoch 182  	Train Loss = 25.85746 Val Loss = 25.37799
2023-05-17 01:47:59.204765 Epoch 183  	Train Loss = 25.85720 Val Loss = 25.38639
2023-05-17 01:50:56.439768 Epoch 184  	Train Loss = 25.84816 Val Loss = 25.39581
2023-05-17 01:53:57.767808 Epoch 185  	Train Loss = 25.84998 Val Loss = 25.38514
2023-05-17 01:57:03.924910 Epoch 186  	Train Loss = 25.84798 Val Loss = 25.38388
2023-05-17 02:00:03.138370 Epoch 187  	Train Loss = 25.84801 Val Loss = 25.38780
2023-05-17 02:02:59.425497 Epoch 188  	Train Loss = 25.83892 Val Loss = 25.40961
2023-05-17 02:05:57.371955 Epoch 189  	Train Loss = 25.84646 Val Loss = 25.38427
2023-05-17 02:09:01.072505 Epoch 190  	Train Loss = 25.83550 Val Loss = 25.40726
2023-05-17 02:12:06.757518 Epoch 191  	Train Loss = 25.83364 Val Loss = 25.37985
2023-05-17 02:15:05.612167 Epoch 192  	Train Loss = 25.83781 Val Loss = 25.36156
2023-05-17 02:18:01.128996 Epoch 193  	Train Loss = 25.83181 Val Loss = 25.35624
2023-05-17 02:20:58.916295 Epoch 194  	Train Loss = 25.82598 Val Loss = 25.36325
2023-05-17 02:24:03.462269 Epoch 195  	Train Loss = 25.83407 Val Loss = 25.35996
2023-05-17 02:27:07.474089 Epoch 196  	Train Loss = 25.81403 Val Loss = 25.39034
2023-05-17 02:30:05.481620 Epoch 197  	Train Loss = 25.82522 Val Loss = 25.39905
2023-05-17 02:33:00.925984 Epoch 198  	Train Loss = 25.81745 Val Loss = 25.36591
2023-05-17 02:35:59.389582 Epoch 199  	Train Loss = 25.81450 Val Loss = 25.37060
2023-05-17 02:39:05.765052 Epoch 200  	Train Loss = 25.81841 Val Loss = 25.35125
Early stopping at epoch: 200
Best at epoch 200:
Train Loss = 25.81841
Train RMSE = 40.67921, MAE = 26.40445, MAPE = 11.63943
Val Loss = 25.35125
Val RMSE = 39.88560, MAE = 25.82852, MAPE = 11.51853
--------- Test ---------
All Steps RMSE = 40.01910, MAE = 26.15130, MAPE = 11.26082
Step 1 RMSE = 28.75873, MAE = 18.62107, MAPE = 8.06893
Step 2 RMSE = 32.12473, MAE = 20.83747, MAPE = 8.97510
Step 3 RMSE = 34.41203, MAE = 22.41081, MAPE = 9.61236
Step 4 RMSE = 36.11416, MAE = 23.58094, MAPE = 10.09289
Step 5 RMSE = 37.67122, MAE = 24.62816, MAPE = 10.52276
Step 6 RMSE = 39.24930, MAE = 25.75823, MAPE = 11.00987
Step 7 RMSE = 40.83663, MAE = 26.93597, MAPE = 11.52076
Step 8 RMSE = 42.28991, MAE = 28.03351, MAPE = 12.01425
Step 9 RMSE = 43.65488, MAE = 29.05367, MAPE = 12.49247
Step 10 RMSE = 45.01232, MAE = 30.06507, MAPE = 12.99203
Step 11 RMSE = 46.59502, MAE = 31.23407, MAPE = 13.56423
Step 12 RMSE = 48.49706, MAE = 32.65343, MAPE = 14.26255
Inference time: 23.59 s
