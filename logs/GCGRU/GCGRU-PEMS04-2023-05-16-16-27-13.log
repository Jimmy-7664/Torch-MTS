PEMS04
Trainset:	x-(10181, 12, 307, 1)	y-(10181, 12, 307, 1)
Valset:  	x-(3394, 12, 307, 1)  	y-(3394, 12, 307, 1)
Testset:	x-(3394, 12, 307, 1)	y-(3394, 12, 307, 1)

--------- GCGRU ---------
{
    "num_nodes": 307,
    "in_steps": 12,
    "out_steps": 12,
    "lr": 0.001,
    "weight_decay": 0,
    "milestones": [
        12,
        50
    ],
    "clip_grad": 0,
    "batch_size": 64,
    "max_epochs": 200,
    "use_cl": false,
    "pass_device": true,
    "model_args": {
        "num_nodes": 307,
        "input_dim": 1,
        "output_dim": 1,
        "horizon": 12,
        "rnn_units": 64,
        "num_layers": 1,
        "cheb_k": 3,
        "adj_path": "../data/PEMS04/adj_PEMS04.pkl",
        "adj_type": "doubletransition",
        "device": "cuda:0"
    }
}
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
GCGRU                                    [64, 12, 307, 1]          --
├─Encoder: 1-1                           [64, 307, 64]             --
│    └─ModuleList: 2-1                   --                        --
│    │    └─GRUCell: 3-1                 [64, 307, 64]             75,072
│    │    └─GRUCell: 3-2                 [64, 307, 64]             (recursive)
│    │    └─GRUCell: 3-3                 [64, 307, 64]             (recursive)
│    │    └─GRUCell: 3-4                 [64, 307, 64]             (recursive)
│    │    └─GRUCell: 3-5                 [64, 307, 64]             (recursive)
│    │    └─GRUCell: 3-6                 [64, 307, 64]             (recursive)
│    │    └─GRUCell: 3-7                 [64, 307, 64]             (recursive)
│    │    └─GRUCell: 3-8                 [64, 307, 64]             (recursive)
│    │    └─GRUCell: 3-9                 [64, 307, 64]             (recursive)
│    │    └─GRUCell: 3-10                [64, 307, 64]             (recursive)
│    │    └─GRUCell: 3-11                [64, 307, 64]             (recursive)
│    │    └─GRUCell: 3-12                [64, 307, 64]             (recursive)
├─Decoder: 1-2                           [64, 307, 64]             --
│    └─ModuleList: 2-24                  --                        (recursive)
│    │    └─GRUCell: 3-13                [64, 307, 64]             75,072
├─Sequential: 1-3                        [64, 307, 1]              --
│    └─Linear: 2-3                       [64, 307, 1]              65
├─Decoder: 1-4                           [64, 307, 64]             (recursive)
│    └─ModuleList: 2-24                  --                        (recursive)
│    │    └─GRUCell: 3-14                [64, 307, 64]             (recursive)
├─Sequential: 1-5                        [64, 307, 1]              (recursive)
│    └─Linear: 2-5                       [64, 307, 1]              (recursive)
├─Decoder: 1-6                           [64, 307, 64]             (recursive)
│    └─ModuleList: 2-24                  --                        (recursive)
│    │    └─GRUCell: 3-15                [64, 307, 64]             (recursive)
├─Sequential: 1-7                        [64, 307, 1]              (recursive)
│    └─Linear: 2-7                       [64, 307, 1]              (recursive)
├─Decoder: 1-8                           [64, 307, 64]             (recursive)
│    └─ModuleList: 2-24                  --                        (recursive)
│    │    └─GRUCell: 3-16                [64, 307, 64]             (recursive)
├─Sequential: 1-9                        [64, 307, 1]              (recursive)
│    └─Linear: 2-9                       [64, 307, 1]              (recursive)
├─Decoder: 1-10                          [64, 307, 64]             (recursive)
│    └─ModuleList: 2-24                  --                        (recursive)
│    │    └─GRUCell: 3-17                [64, 307, 64]             (recursive)
├─Sequential: 1-11                       [64, 307, 1]              (recursive)
│    └─Linear: 2-11                      [64, 307, 1]              (recursive)
├─Decoder: 1-12                          [64, 307, 64]             (recursive)
│    └─ModuleList: 2-24                  --                        (recursive)
│    │    └─GRUCell: 3-18                [64, 307, 64]             (recursive)
├─Sequential: 1-13                       [64, 307, 1]              (recursive)
│    └─Linear: 2-13                      [64, 307, 1]              (recursive)
├─Decoder: 1-14                          [64, 307, 64]             (recursive)
│    └─ModuleList: 2-24                  --                        (recursive)
│    │    └─GRUCell: 3-19                [64, 307, 64]             (recursive)
├─Sequential: 1-15                       [64, 307, 1]              (recursive)
│    └─Linear: 2-15                      [64, 307, 1]              (recursive)
├─Decoder: 1-16                          [64, 307, 64]             (recursive)
│    └─ModuleList: 2-24                  --                        (recursive)
│    │    └─GRUCell: 3-20                [64, 307, 64]             (recursive)
├─Sequential: 1-17                       [64, 307, 1]              (recursive)
│    └─Linear: 2-17                      [64, 307, 1]              (recursive)
├─Decoder: 1-18                          [64, 307, 64]             (recursive)
│    └─ModuleList: 2-24                  --                        (recursive)
│    │    └─GRUCell: 3-21                [64, 307, 64]             (recursive)
├─Sequential: 1-19                       [64, 307, 1]              (recursive)
│    └─Linear: 2-19                      [64, 307, 1]              (recursive)
├─Decoder: 1-20                          [64, 307, 64]             (recursive)
│    └─ModuleList: 2-24                  --                        (recursive)
│    │    └─GRUCell: 3-22                [64, 307, 64]             (recursive)
├─Sequential: 1-21                       [64, 307, 1]              (recursive)
│    └─Linear: 2-21                      [64, 307, 1]              (recursive)
├─Decoder: 1-22                          [64, 307, 64]             (recursive)
│    └─ModuleList: 2-24                  --                        (recursive)
│    │    └─GRUCell: 3-23                [64, 307, 64]             (recursive)
├─Sequential: 1-23                       [64, 307, 1]              (recursive)
│    └─Linear: 2-23                      [64, 307, 1]              (recursive)
├─Decoder: 1-24                          [64, 307, 64]             (recursive)
│    └─ModuleList: 2-24                  --                        (recursive)
│    │    └─GRUCell: 3-24                [64, 307, 64]             (recursive)
├─Sequential: 1-25                       [64, 307, 1]              (recursive)
│    └─Linear: 2-25                      [64, 307, 1]              (recursive)
==========================================================================================
Total params: 150,209
Trainable params: 150,209
Non-trainable params: 0
Total mult-adds (M): 0.05
==========================================================================================
Input size (MB): 0.94
Forward/backward pass size (MB): 726.19
Params size (MB): 0.60
Estimated Total Size (MB): 727.73
==========================================================================================

Loss: HuberLoss

2023-05-16 16:27:39.315447 Epoch 1  	Train Loss = 36.40055 Val Loss = 29.85084
2023-05-16 16:28:03.719136 Epoch 2  	Train Loss = 25.66096 Val Loss = 26.33784
2023-05-16 16:28:27.829588 Epoch 3  	Train Loss = 24.98764 Val Loss = 25.56710
2023-05-16 16:28:52.661671 Epoch 4  	Train Loss = 24.68444 Val Loss = 26.02063
2023-05-16 16:29:17.915312 Epoch 5  	Train Loss = 24.45034 Val Loss = 25.77653
2023-05-16 16:29:42.966749 Epoch 6  	Train Loss = 24.35093 Val Loss = 25.01805
2023-05-16 16:30:08.127673 Epoch 7  	Train Loss = 24.12849 Val Loss = 24.99216
2023-05-16 16:30:33.389970 Epoch 8  	Train Loss = 23.93341 Val Loss = 25.04098
2023-05-16 16:30:58.706996 Epoch 9  	Train Loss = 23.93783 Val Loss = 25.09742
2023-05-16 16:31:24.074565 Epoch 10  	Train Loss = 23.85688 Val Loss = 24.89476
2023-05-16 16:31:49.441409 Epoch 11  	Train Loss = 23.62058 Val Loss = 26.79152
2023-05-16 16:32:14.836856 Epoch 12  	Train Loss = 23.70648 Val Loss = 24.83699
2023-05-16 16:32:40.305205 Epoch 13  	Train Loss = 23.27460 Val Loss = 24.06011
2023-05-16 16:33:05.733698 Epoch 14  	Train Loss = 23.16219 Val Loss = 24.03405
2023-05-16 16:33:31.191296 Epoch 15  	Train Loss = 23.13327 Val Loss = 24.01075
2023-05-16 16:33:56.781976 Epoch 16  	Train Loss = 23.16592 Val Loss = 23.99438
2023-05-16 16:34:22.479990 Epoch 17  	Train Loss = 23.11875 Val Loss = 24.00719
2023-05-16 16:34:48.172408 Epoch 18  	Train Loss = 23.06534 Val Loss = 23.90132
2023-05-16 16:35:13.908210 Epoch 19  	Train Loss = 23.04596 Val Loss = 23.94758
2023-05-16 16:35:39.823172 Epoch 20  	Train Loss = 23.04320 Val Loss = 23.89649
2023-05-16 16:36:05.645207 Epoch 21  	Train Loss = 23.02659 Val Loss = 23.83134
2023-05-16 16:36:31.573598 Epoch 22  	Train Loss = 23.01138 Val Loss = 23.78387
2023-05-16 16:36:57.564174 Epoch 23  	Train Loss = 22.94745 Val Loss = 23.98486
2023-05-16 16:37:23.377731 Epoch 24  	Train Loss = 22.95501 Val Loss = 23.76950
2023-05-16 16:37:49.234345 Epoch 25  	Train Loss = 22.96890 Val Loss = 23.85679
2023-05-16 16:38:14.883511 Epoch 26  	Train Loss = 22.92418 Val Loss = 23.72918
2023-05-16 16:38:40.556240 Epoch 27  	Train Loss = 22.84959 Val Loss = 23.63680
2023-05-16 16:39:06.295400 Epoch 28  	Train Loss = 22.86566 Val Loss = 23.67218
2023-05-16 16:39:31.977021 Epoch 29  	Train Loss = 22.86765 Val Loss = 23.76794
2023-05-16 16:39:57.666015 Epoch 30  	Train Loss = 22.80192 Val Loss = 23.61695
2023-05-16 16:40:23.477332 Epoch 31  	Train Loss = 22.77357 Val Loss = 23.70362
2023-05-16 16:40:49.178027 Epoch 32  	Train Loss = 22.79740 Val Loss = 23.73792
2023-05-16 16:41:14.827859 Epoch 33  	Train Loss = 22.73127 Val Loss = 23.51468
2023-05-16 16:41:40.401197 Epoch 34  	Train Loss = 22.72001 Val Loss = 23.54912
2023-05-16 16:42:05.981450 Epoch 35  	Train Loss = 22.71243 Val Loss = 23.54570
2023-05-16 16:42:31.674391 Epoch 36  	Train Loss = 22.66358 Val Loss = 23.47723
2023-05-16 16:42:57.245320 Epoch 37  	Train Loss = 22.62316 Val Loss = 23.46487
2023-05-16 16:43:22.901106 Epoch 38  	Train Loss = 22.62943 Val Loss = 23.38051
2023-05-16 16:43:49.041277 Epoch 39  	Train Loss = 22.57388 Val Loss = 24.01862
2023-05-16 16:44:15.408880 Epoch 40  	Train Loss = 22.58950 Val Loss = 23.38542
2023-05-16 16:44:41.199534 Epoch 41  	Train Loss = 22.55197 Val Loss = 23.36203
2023-05-16 16:45:06.797160 Epoch 42  	Train Loss = 22.50003 Val Loss = 23.27173
2023-05-16 16:45:32.422261 Epoch 43  	Train Loss = 22.43803 Val Loss = 23.24182
2023-05-16 16:45:58.175905 Epoch 44  	Train Loss = 22.44460 Val Loss = 23.29583
2023-05-16 16:46:23.741775 Epoch 45  	Train Loss = 22.46590 Val Loss = 23.20918
2023-05-16 16:46:49.357306 Epoch 46  	Train Loss = 22.40543 Val Loss = 23.19171
2023-05-16 16:47:14.853660 Epoch 47  	Train Loss = 22.40685 Val Loss = 23.20709
2023-05-16 16:47:40.481174 Epoch 48  	Train Loss = 22.36644 Val Loss = 23.23692
2023-05-16 16:48:06.212957 Epoch 49  	Train Loss = 22.35919 Val Loss = 23.21526
2023-05-16 16:48:31.940662 Epoch 50  	Train Loss = 22.31524 Val Loss = 23.15923
2023-05-16 16:48:57.740282 Epoch 51  	Train Loss = 22.23821 Val Loss = 23.03131
2023-05-16 16:49:23.583838 Epoch 52  	Train Loss = 22.21619 Val Loss = 23.01818
2023-05-16 16:49:49.392831 Epoch 53  	Train Loss = 22.23069 Val Loss = 22.99624
2023-05-16 16:50:15.219984 Epoch 54  	Train Loss = 22.19777 Val Loss = 23.01384
2023-05-16 16:50:41.033562 Epoch 55  	Train Loss = 22.23055 Val Loss = 22.99135
2023-05-16 16:51:06.984229 Epoch 56  	Train Loss = 22.23758 Val Loss = 23.02539
2023-05-16 16:51:32.865844 Epoch 57  	Train Loss = 22.26502 Val Loss = 22.98181
2023-05-16 16:51:58.733575 Epoch 58  	Train Loss = 22.24201 Val Loss = 22.97999
2023-05-16 16:52:24.471043 Epoch 59  	Train Loss = 22.25268 Val Loss = 22.98584
2023-05-16 16:52:50.142932 Epoch 60  	Train Loss = 22.18400 Val Loss = 23.02857
2023-05-16 16:53:15.754112 Epoch 61  	Train Loss = 22.17264 Val Loss = 22.99973
2023-05-16 16:53:41.388588 Epoch 62  	Train Loss = 22.18937 Val Loss = 22.98378
2023-05-16 16:54:07.030797 Epoch 63  	Train Loss = 22.23189 Val Loss = 22.97555
2023-05-16 16:54:32.743819 Epoch 64  	Train Loss = 22.23147 Val Loss = 22.97411
2023-05-16 16:54:58.422238 Epoch 65  	Train Loss = 22.21770 Val Loss = 22.95663
2023-05-16 16:55:23.984697 Epoch 66  	Train Loss = 22.21976 Val Loss = 22.96193
2023-05-16 16:55:49.567912 Epoch 67  	Train Loss = 22.20500 Val Loss = 22.95869
2023-05-16 16:56:15.134731 Epoch 68  	Train Loss = 22.17568 Val Loss = 22.95456
2023-05-16 16:56:40.732733 Epoch 69  	Train Loss = 22.18790 Val Loss = 23.04737
2023-05-16 16:57:06.391625 Epoch 70  	Train Loss = 22.17662 Val Loss = 22.94254
2023-05-16 16:57:32.071221 Epoch 71  	Train Loss = 22.21008 Val Loss = 22.96682
2023-05-16 16:57:57.790491 Epoch 72  	Train Loss = 22.14042 Val Loss = 22.96741
2023-05-16 16:58:23.471873 Epoch 73  	Train Loss = 22.12343 Val Loss = 22.93812
2023-05-16 16:58:49.082475 Epoch 74  	Train Loss = 22.14707 Val Loss = 22.93080
2023-05-16 16:59:14.628610 Epoch 75  	Train Loss = 22.15723 Val Loss = 22.97037
2023-05-16 16:59:40.381513 Epoch 76  	Train Loss = 22.17115 Val Loss = 22.94342
2023-05-16 17:00:05.900402 Epoch 77  	Train Loss = 22.14452 Val Loss = 22.92597
2023-05-16 17:00:31.369268 Epoch 78  	Train Loss = 22.18174 Val Loss = 22.91874
2023-05-16 17:00:56.872236 Epoch 79  	Train Loss = 22.11054 Val Loss = 22.93434
2023-05-16 17:01:22.349071 Epoch 80  	Train Loss = 22.18035 Val Loss = 22.92411
2023-05-16 17:01:47.828227 Epoch 81  	Train Loss = 22.13906 Val Loss = 22.90356
2023-05-16 17:02:13.358543 Epoch 82  	Train Loss = 22.15803 Val Loss = 22.91898
2023-05-16 17:02:38.937834 Epoch 83  	Train Loss = 22.12329 Val Loss = 22.90347
2023-05-16 17:03:04.596317 Epoch 84  	Train Loss = 22.11021 Val Loss = 22.93388
2023-05-16 17:03:30.251517 Epoch 85  	Train Loss = 22.12487 Val Loss = 22.90006
2023-05-16 17:03:56.034605 Epoch 86  	Train Loss = 22.14387 Val Loss = 22.89314
2023-05-16 17:04:21.759973 Epoch 87  	Train Loss = 22.18179 Val Loss = 22.90052
2023-05-16 17:04:47.535754 Epoch 88  	Train Loss = 22.15626 Val Loss = 22.89253
2023-05-16 17:05:13.364039 Epoch 89  	Train Loss = 22.12216 Val Loss = 22.91789
2023-05-16 17:05:39.126365 Epoch 90  	Train Loss = 22.11791 Val Loss = 22.91394
2023-05-16 17:06:04.941231 Epoch 91  	Train Loss = 22.11121 Val Loss = 22.88466
2023-05-16 17:06:30.691168 Epoch 92  	Train Loss = 22.11570 Val Loss = 22.88818
2023-05-16 17:06:56.432088 Epoch 93  	Train Loss = 22.07554 Val Loss = 22.87608
2023-05-16 17:07:22.160423 Epoch 94  	Train Loss = 22.13588 Val Loss = 22.89582
2023-05-16 17:07:47.775370 Epoch 95  	Train Loss = 22.10908 Val Loss = 22.88214
2023-05-16 17:08:13.393772 Epoch 96  	Train Loss = 22.11812 Val Loss = 22.88244
2023-05-16 17:08:38.995638 Epoch 97  	Train Loss = 22.09020 Val Loss = 22.85758
2023-05-16 17:09:04.599002 Epoch 98  	Train Loss = 22.09578 Val Loss = 22.89197
2023-05-16 17:09:30.167464 Epoch 99  	Train Loss = 22.11593 Val Loss = 22.86404
2023-05-16 17:09:55.733002 Epoch 100  	Train Loss = 22.11974 Val Loss = 22.84853
2023-05-16 17:10:21.249654 Epoch 101  	Train Loss = 22.09871 Val Loss = 22.87254
2023-05-16 17:10:46.737640 Epoch 102  	Train Loss = 22.03668 Val Loss = 22.87049
2023-05-16 17:11:12.336593 Epoch 103  	Train Loss = 22.09612 Val Loss = 22.89125
2023-05-16 17:11:37.890527 Epoch 104  	Train Loss = 22.05721 Val Loss = 22.83485
2023-05-16 17:12:03.218762 Epoch 105  	Train Loss = 22.06343 Val Loss = 22.85037
2023-05-16 17:12:28.608911 Epoch 106  	Train Loss = 22.05569 Val Loss = 22.83993
2023-05-16 17:12:54.090701 Epoch 107  	Train Loss = 22.13154 Val Loss = 22.82971
2023-05-16 17:13:19.607899 Epoch 108  	Train Loss = 22.08350 Val Loss = 22.86633
2023-05-16 17:13:45.074447 Epoch 109  	Train Loss = 22.07055 Val Loss = 22.86302
2023-05-16 17:14:10.586544 Epoch 110  	Train Loss = 22.08754 Val Loss = 22.88193
2023-05-16 17:14:36.031244 Epoch 111  	Train Loss = 22.07033 Val Loss = 22.84174
2023-05-16 17:15:01.499057 Epoch 112  	Train Loss = 22.06087 Val Loss = 22.84340
2023-05-16 17:15:26.913883 Epoch 113  	Train Loss = 22.06473 Val Loss = 22.83325
2023-05-16 17:15:52.366396 Epoch 114  	Train Loss = 22.07540 Val Loss = 22.82319
2023-05-16 17:16:17.839088 Epoch 115  	Train Loss = 22.00697 Val Loss = 22.84328
2023-05-16 17:16:43.346233 Epoch 116  	Train Loss = 22.06703 Val Loss = 22.82188
2023-05-16 17:17:08.956105 Epoch 117  	Train Loss = 22.05039 Val Loss = 22.87567
2023-05-16 17:17:34.617789 Epoch 118  	Train Loss = 22.03877 Val Loss = 22.81920
2023-05-16 17:18:00.375568 Epoch 119  	Train Loss = 22.02296 Val Loss = 22.82316
2023-05-16 17:18:28.627429 Epoch 120  	Train Loss = 22.04467 Val Loss = 22.79244
2023-05-16 17:18:55.323545 Epoch 121  	Train Loss = 22.04016 Val Loss = 22.80827
2023-05-16 17:19:21.113798 Epoch 122  	Train Loss = 22.04430 Val Loss = 22.80097
2023-05-16 17:19:46.951509 Epoch 123  	Train Loss = 22.03162 Val Loss = 22.79802
2023-05-16 17:20:12.824288 Epoch 124  	Train Loss = 22.01700 Val Loss = 22.81020
2023-05-16 17:20:38.638641 Epoch 125  	Train Loss = 22.02226 Val Loss = 22.78405
2023-05-16 17:21:04.407364 Epoch 126  	Train Loss = 22.00151 Val Loss = 22.77929
2023-05-16 17:21:30.354420 Epoch 127  	Train Loss = 22.03212 Val Loss = 22.81613
2023-05-16 17:21:56.071404 Epoch 128  	Train Loss = 22.04295 Val Loss = 22.79485
2023-05-16 17:22:22.114780 Epoch 129  	Train Loss = 22.00630 Val Loss = 22.77479
2023-05-16 17:22:47.892129 Epoch 130  	Train Loss = 21.95188 Val Loss = 22.77862
2023-05-16 17:23:13.618406 Epoch 131  	Train Loss = 22.02313 Val Loss = 22.80513
2023-05-16 17:23:39.287808 Epoch 132  	Train Loss = 21.99898 Val Loss = 22.81130
2023-05-16 17:24:05.063350 Epoch 133  	Train Loss = 22.00610 Val Loss = 22.78307
2023-05-16 17:24:30.727410 Epoch 134  	Train Loss = 22.02727 Val Loss = 22.76502
2023-05-16 17:24:56.482225 Epoch 135  	Train Loss = 22.01446 Val Loss = 22.75661
2023-05-16 17:25:22.165959 Epoch 136  	Train Loss = 22.04401 Val Loss = 22.80880
2023-05-16 17:25:47.794000 Epoch 137  	Train Loss = 22.00551 Val Loss = 22.75081
2023-05-16 17:26:13.455573 Epoch 138  	Train Loss = 22.00051 Val Loss = 22.78387
2023-05-16 17:26:39.042214 Epoch 139  	Train Loss = 21.94383 Val Loss = 22.75671
2023-05-16 17:27:04.595588 Epoch 140  	Train Loss = 21.97836 Val Loss = 22.75260
2023-05-16 17:27:30.174682 Epoch 141  	Train Loss = 21.94353 Val Loss = 22.76223
2023-05-16 17:27:55.901505 Epoch 142  	Train Loss = 21.98020 Val Loss = 22.76062
2023-05-16 17:28:21.467979 Epoch 143  	Train Loss = 21.98507 Val Loss = 22.76009
2023-05-16 17:28:47.041372 Epoch 144  	Train Loss = 21.99206 Val Loss = 22.76691
2023-05-16 17:29:12.550126 Epoch 145  	Train Loss = 21.93805 Val Loss = 22.74998
2023-05-16 17:29:38.073912 Epoch 146  	Train Loss = 21.94492 Val Loss = 22.78858
2023-05-16 17:30:03.714141 Epoch 147  	Train Loss = 21.98638 Val Loss = 22.76257
2023-05-16 17:30:29.171627 Epoch 148  	Train Loss = 21.96887 Val Loss = 22.74308
2023-05-16 17:30:54.783480 Epoch 149  	Train Loss = 21.96146 Val Loss = 22.74039
2023-05-16 17:31:20.563566 Epoch 150  	Train Loss = 21.94649 Val Loss = 22.73147
2023-05-16 17:31:46.222368 Epoch 151  	Train Loss = 21.97551 Val Loss = 22.73619
2023-05-16 17:32:13.086528 Epoch 152  	Train Loss = 21.95650 Val Loss = 22.70406
2023-05-16 17:32:38.799435 Epoch 153  	Train Loss = 21.96785 Val Loss = 22.71544
2023-05-16 17:33:04.450218 Epoch 154  	Train Loss = 21.99906 Val Loss = 22.72573
2023-05-16 17:33:31.470357 Epoch 155  	Train Loss = 21.93730 Val Loss = 22.74681
2023-05-16 17:33:57.410488 Epoch 156  	Train Loss = 21.93385 Val Loss = 22.73300
2023-05-16 17:34:23.304679 Epoch 157  	Train Loss = 21.91736 Val Loss = 22.69211
2023-05-16 17:34:50.369188 Epoch 158  	Train Loss = 21.94022 Val Loss = 22.69906
2023-05-16 17:35:16.604635 Epoch 159  	Train Loss = 21.98569 Val Loss = 22.72261
2023-05-16 17:35:43.315350 Epoch 160  	Train Loss = 21.94443 Val Loss = 22.74359
2023-05-16 17:36:09.182665 Epoch 161  	Train Loss = 21.95072 Val Loss = 22.71459
2023-05-16 17:36:34.836509 Epoch 162  	Train Loss = 21.94615 Val Loss = 22.70045
2023-05-16 17:37:00.405593 Epoch 163  	Train Loss = 21.93772 Val Loss = 22.67810
2023-05-16 17:37:25.991425 Epoch 164  	Train Loss = 21.87888 Val Loss = 22.70994
2023-05-16 17:37:51.551919 Epoch 165  	Train Loss = 21.92051 Val Loss = 22.69864
2023-05-16 17:38:17.145386 Epoch 166  	Train Loss = 21.91692 Val Loss = 22.72271
2023-05-16 17:38:42.679597 Epoch 167  	Train Loss = 21.94281 Val Loss = 22.69084
2023-05-16 17:39:08.341515 Epoch 168  	Train Loss = 21.92154 Val Loss = 22.67388
2023-05-16 17:39:34.004719 Epoch 169  	Train Loss = 21.93284 Val Loss = 22.67828
2023-05-16 17:39:59.566477 Epoch 170  	Train Loss = 21.93144 Val Loss = 22.66911
2023-05-16 17:40:25.156159 Epoch 171  	Train Loss = 21.93342 Val Loss = 22.70598
2023-05-16 17:40:50.728651 Epoch 172  	Train Loss = 21.88829 Val Loss = 22.68657
2023-05-16 17:41:16.251050 Epoch 173  	Train Loss = 21.90060 Val Loss = 22.70035
2023-05-16 17:41:41.984693 Epoch 174  	Train Loss = 21.90927 Val Loss = 22.65480
2023-05-16 17:42:07.442295 Epoch 175  	Train Loss = 21.92077 Val Loss = 22.69811
2023-05-16 17:42:32.895387 Epoch 176  	Train Loss = 21.89436 Val Loss = 22.66114
2023-05-16 17:42:58.367992 Epoch 177  	Train Loss = 21.90180 Val Loss = 22.68851
2023-05-16 17:43:23.805840 Epoch 178  	Train Loss = 21.91417 Val Loss = 22.69972
2023-05-16 17:43:49.262229 Epoch 179  	Train Loss = 21.88733 Val Loss = 22.64446
2023-05-16 17:44:14.764689 Epoch 180  	Train Loss = 21.91331 Val Loss = 22.66249
2023-05-16 17:44:40.244323 Epoch 181  	Train Loss = 21.87304 Val Loss = 22.66616
2023-05-16 17:45:05.807177 Epoch 182  	Train Loss = 21.90279 Val Loss = 22.63822
2023-05-16 17:45:31.353606 Epoch 183  	Train Loss = 21.93416 Val Loss = 22.67160
2023-05-16 17:45:56.941126 Epoch 184  	Train Loss = 21.90627 Val Loss = 22.65132
2023-05-16 17:46:22.623759 Epoch 185  	Train Loss = 21.92986 Val Loss = 22.66098
2023-05-16 17:46:48.332239 Epoch 186  	Train Loss = 21.91353 Val Loss = 22.63521
2023-05-16 17:47:13.995896 Epoch 187  	Train Loss = 21.84902 Val Loss = 22.64988
2023-05-16 17:47:39.799861 Epoch 188  	Train Loss = 21.87834 Val Loss = 22.64151
2023-05-16 17:48:05.571005 Epoch 189  	Train Loss = 21.88970 Val Loss = 22.64274
2023-05-16 17:48:31.364850 Epoch 190  	Train Loss = 21.83128 Val Loss = 22.63254
2023-05-16 17:48:57.257685 Epoch 191  	Train Loss = 21.86034 Val Loss = 22.66000
2023-05-16 17:49:23.133257 Epoch 192  	Train Loss = 21.88050 Val Loss = 22.61424
2023-05-16 17:49:48.927432 Epoch 193  	Train Loss = 21.83009 Val Loss = 22.63263
2023-05-16 17:50:14.545640 Epoch 194  	Train Loss = 21.88913 Val Loss = 22.63143
2023-05-16 17:50:40.164367 Epoch 195  	Train Loss = 21.84492 Val Loss = 22.63293
2023-05-16 17:51:05.746523 Epoch 196  	Train Loss = 21.82408 Val Loss = 22.63967
2023-05-16 17:51:31.331854 Epoch 197  	Train Loss = 21.86378 Val Loss = 22.60197
2023-05-16 17:51:57.010960 Epoch 198  	Train Loss = 21.84625 Val Loss = 22.63637
2023-05-16 17:52:22.609213 Epoch 199  	Train Loss = 21.82524 Val Loss = 22.64367
2023-05-16 17:52:48.232870 Epoch 200  	Train Loss = 21.87813 Val Loss = 22.59517
Early stopping at epoch: 200
Best at epoch 200:
Train Loss = 21.87813
Train RMSE = 35.18245, MAE = 22.50723, MAPE = 16.44398
Val Loss = 22.59517
Val RMSE = 36.55227, MAE = 23.47851, MAPE = 15.76089
--------- Test ---------
All Steps RMSE = 35.15109, MAE = 22.70589, MAPE = 15.49378
Step 1 RMSE = 28.33171, MAE = 17.90939, MAPE = 12.08258
Step 2 RMSE = 30.18537, MAE = 19.19324, MAPE = 12.87441
Step 3 RMSE = 31.62236, MAE = 20.22255, MAPE = 13.55881
Step 4 RMSE = 32.70349, MAE = 20.99290, MAPE = 14.10953
Step 5 RMSE = 33.66012, MAE = 21.68076, MAPE = 14.60342
Step 6 RMSE = 34.62950, MAE = 22.40527, MAPE = 15.15141
Step 7 RMSE = 35.66834, MAE = 23.18653, MAPE = 15.75027
Step 8 RMSE = 36.63734, MAE = 23.92457, MAPE = 16.33286
Step 9 RMSE = 37.53987, MAE = 24.60475, MAPE = 16.89369
Step 10 RMSE = 38.40577, MAE = 25.26865, MAPE = 17.47600
Step 11 RMSE = 39.41262, MAE = 26.03884, MAPE = 18.14411
Step 12 RMSE = 40.73631, MAE = 27.04260, MAPE = 18.94768
Inference time: 3.34 s
