METRLA
Trainset:	x-(23974, 12, 207, 3)	y-(23974, 12, 207, 3)
Valset:  	x-(3425, 12, 207, 3)  	y-(3425, 12, 207, 3)
Testset:	x-(6850, 12, 207, 3)	y-(6850, 12, 207, 3)

--------- GMAN ---------
{
    "num_nodes": 207,
    "in_steps": 12,
    "out_steps": 12,
    "pass_device": true,
    "time_of_day": true,
    "day_of_week": true,
    "y_time_of_day": true,
    "y_day_of_week": true,
    "runner": "gman",
    "lr": 0.001,
    "weight_decay": 0.0001,
    "milestones": [
        10,
        15
    ],
    "clip_grad": 5,
    "batch_size": 32,
    "max_epochs": 200,
    "early_stop": 20,
    "model_args": {
        "SE_file_path": "../data/METRLA/SE_metrla.txt",
        "timestep_in": 12,
        "statt_layers": 1,
        "att_heads": 8,
        "att_dims": 8,
        "bn_decay": 0.1,
        "device": "cuda:0"
    }
}
=========================================================================================================
Layer (type:depth-idx)                                  Output Shape              Param #
=========================================================================================================
GMAN                                                    [32, 12, 207, 1]          --
├─FC: 1-1                                               [32, 12, 207, 64]         --
│    └─ModuleList: 2-1                                  --                        --
│    │    └─conv2d_: 3-1                                [32, 12, 207, 64]         256
│    │    └─conv2d_: 3-2                                [32, 12, 207, 64]         4,288
├─STEmbedding: 1-2                                      [32, 24, 207, 64]         --
│    └─FC: 2-2                                          [1, 1, 207, 64]           --
│    │    └─ModuleList: 3-3                             --                        8,576
│    └─FC: 2-3                                          [32, 24, 1, 64]           --
│    │    └─ModuleList: 3-4                             --                        23,360
├─ModuleList: 1-3                                       --                        --
│    └─STAttBlock: 2-4                                  [32, 12, 207, 64]         --
│    │    └─spatialAttention: 3-5                       [32, 12, 207, 64]         29,440
│    │    └─temporalAttention: 3-6                      [32, 12, 207, 64]         29,440
│    │    └─gatedFusion: 3-7                            [32, 12, 207, 64]         17,088
├─transformAttention: 1-4                               [32, 12, 207, 64]         --
│    └─FC: 2-5                                          [32, 12, 207, 64]         --
│    │    └─ModuleList: 3-8                             --                        4,288
│    └─FC: 2-6                                          [32, 12, 207, 64]         --
│    │    └─ModuleList: 3-9                             --                        4,288
│    └─FC: 2-7                                          [32, 12, 207, 64]         --
│    │    └─ModuleList: 3-10                            --                        4,288
│    └─FC: 2-8                                          [32, 12, 207, 64]         --
│    │    └─ModuleList: 3-11                            --                        4,288
├─ModuleList: 1-5                                       --                        --
│    └─STAttBlock: 2-9                                  [32, 12, 207, 64]         --
│    │    └─spatialAttention: 3-12                      [32, 12, 207, 64]         29,440
│    │    └─temporalAttention: 3-13                     [32, 12, 207, 64]         29,440
│    │    └─gatedFusion: 3-14                           [32, 12, 207, 64]         17,088
├─FC: 1-6                                               [32, 12, 207, 1]          --
│    └─ModuleList: 2-10                                 --                        --
│    │    └─conv2d_: 3-15                               [32, 12, 207, 64]         4,288
│    │    └─conv2d_: 3-16                               [32, 12, 207, 1]          67
=========================================================================================================
Total params: 209,923
Trainable params: 209,923
Non-trainable params: 0
Total mult-adds (G): 13.85
=========================================================================================================
Input size (MB): 1.59
Forward/backward pass size (MB): 2526.54
Params size (MB): 0.84
Estimated Total Size (MB): 2528.97
=========================================================================================================

Loss: MaskedMAELoss

2023-09-10 10:59:04.994637 Epoch 1  	Train Loss = 3.96792 Val Loss = 3.30105
2023-09-10 11:00:31.747658 Epoch 2  	Train Loss = 3.32034 Val Loss = 3.19499
2023-09-10 11:01:58.015245 Epoch 3  	Train Loss = 3.18308 Val Loss = 3.07983
2023-09-10 11:03:25.218066 Epoch 4  	Train Loss = 3.10750 Val Loss = 3.00916
2023-09-10 11:04:52.075401 Epoch 5  	Train Loss = 3.06315 Val Loss = 3.05439
2023-09-10 11:06:17.139852 Epoch 6  	Train Loss = 3.02066 Val Loss = 2.97381
2023-09-10 11:07:44.144284 Epoch 7  	Train Loss = 2.98609 Val Loss = 3.03686
2023-09-10 11:09:11.546349 Epoch 8  	Train Loss = 2.94807 Val Loss = 3.03802
2023-09-10 11:10:37.813717 Epoch 9  	Train Loss = 2.92875 Val Loss = 2.95906
2023-09-10 11:12:03.164746 Epoch 10  	Train Loss = 2.91307 Val Loss = 3.00277
2023-09-10 11:13:29.391947 Epoch 11  	Train Loss = 2.80792 Val Loss = 2.89085
2023-09-10 11:14:55.096219 Epoch 12  	Train Loss = 2.78701 Val Loss = 2.88844
2023-09-10 11:16:21.480256 Epoch 13  	Train Loss = 2.78010 Val Loss = 2.89569
2023-09-10 11:17:47.677648 Epoch 14  	Train Loss = 2.77048 Val Loss = 2.86448
2023-09-10 11:19:12.132154 Epoch 15  	Train Loss = 2.76209 Val Loss = 2.88993
2023-09-10 11:20:38.876584 Epoch 16  	Train Loss = 2.75234 Val Loss = 2.91306
2023-09-10 11:22:05.601631 Epoch 17  	Train Loss = 2.75084 Val Loss = 2.87250
2023-09-10 11:23:31.626915 Epoch 18  	Train Loss = 2.74991 Val Loss = 2.88160
2023-09-10 11:24:58.763306 Epoch 19  	Train Loss = 2.74780 Val Loss = 2.86565
2023-09-10 11:26:24.510191 Epoch 20  	Train Loss = 2.74565 Val Loss = 2.90153
2023-09-10 11:27:49.429171 Epoch 21  	Train Loss = 2.73925 Val Loss = 2.87794
2023-09-10 11:29:16.902203 Epoch 22  	Train Loss = 2.74939 Val Loss = 2.93445
2023-09-10 11:30:43.826252 Epoch 23  	Train Loss = 2.73922 Val Loss = 2.87188
2023-09-10 11:32:09.972441 Epoch 24  	Train Loss = 2.74397 Val Loss = 2.87790
2023-09-10 11:33:36.212053 Epoch 25  	Train Loss = 2.74092 Val Loss = 2.89951
2023-09-10 11:35:03.092152 Epoch 26  	Train Loss = 2.74751 Val Loss = 2.90306
2023-09-10 11:36:28.949779 Epoch 27  	Train Loss = 2.74506 Val Loss = 2.86878
2023-09-10 11:37:54.328358 Epoch 28  	Train Loss = 2.73984 Val Loss = 2.88347
2023-09-10 11:39:18.994848 Epoch 29  	Train Loss = 2.74233 Val Loss = 2.87386
2023-09-10 11:40:43.457465 Epoch 30  	Train Loss = 2.74535 Val Loss = 2.88455
2023-09-10 11:42:08.940810 Epoch 31  	Train Loss = 2.74137 Val Loss = 2.88666
2023-09-10 11:43:35.115255 Epoch 32  	Train Loss = 2.74131 Val Loss = 2.88536
2023-09-10 11:45:01.886534 Epoch 33  	Train Loss = 2.73885 Val Loss = 2.89008
2023-09-10 11:46:28.415162 Epoch 34  	Train Loss = 2.73753 Val Loss = 2.87647
Early stopping at epoch: 34
Best at epoch 14:
Train Loss = 2.77048
Train RMSE = 5.38185, MAE = 2.68101, MAPE = 7.21354
Val Loss = 2.86448
Val RMSE = 6.10585, MAE = 2.89534, MAPE = 8.23270
--------- Test ---------
All Steps RMSE = 6.35670, MAE = 3.08703, MAPE = 8.77437
Step 1 RMSE = 4.78995, MAE = 2.54103, MAPE = 6.69815
Step 2 RMSE = 5.23958, MAE = 2.69536, MAPE = 7.21745
Step 3 RMSE = 5.58273, MAE = 2.81675, MAPE = 7.65127
Step 4 RMSE = 5.87627, MAE = 2.92207, MAPE = 8.06129
Step 5 RMSE = 6.13660, MAE = 3.01642, MAPE = 8.43926
Step 6 RMSE = 6.36829, MAE = 3.10075, MAPE = 8.78520
Step 7 RMSE = 6.57763, MAE = 3.17631, MAPE = 9.10215
Step 8 RMSE = 6.75592, MAE = 3.24391, MAPE = 9.39006
Step 9 RMSE = 6.91047, MAE = 3.30459, MAPE = 9.64452
Step 10 RMSE = 7.04254, MAE = 3.35847, MAPE = 9.87540
Step 11 RMSE = 7.16732, MAE = 3.41031, MAPE = 10.10231
Step 12 RMSE = 7.27710, MAE = 3.45848, MAPE = 10.32558
Inference time: 7.10 s
