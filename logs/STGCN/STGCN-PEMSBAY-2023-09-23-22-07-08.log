PEMSBAY
Trainset:	x-(36465, 12, 325, 1)	y-(36465, 12, 325, 1)
Valset:  	x-(5209, 12, 325, 1)  	y-(5209, 12, 325, 1)
Testset:	x-(10419, 12, 325, 1)	y-(10419, 12, 325, 1)

--------- STGCN ---------
{
    "num_nodes": 325,
    "in_steps": 12,
    "out_steps": 12,
    "lr": 0.001,
    "weight_decay": 0.0001,
    "milestones": [
        30,
        50
    ],
    "clip_grad": 5,
    "batch_size": 64,
    "max_epochs": 200,
    "early_stop": 20,
    "model_args": {
        "n_vertex": 325,
        "adj_path": "../data/PEMSBAY/adj_mx_bay.pkl",
        "Kt": 3,
        "Ks": 3,
        "blocks": [
            [
                1
            ],
            [
                64,
                16,
                64
            ],
            [
                64,
                16,
                64
            ],
            [
                128,
                128
            ],
            [
                12
            ]
        ],
        "T": 12,
        "act_func": "glu",
        "graph_conv_type": "cheb_graph_conv",
        "bias": true,
        "droprate": 0.5
    }
}
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
STGCN                                    [64, 12, 325, 1]          --
├─Sequential: 1-1                        [64, 64, 4, 325]          --
│    └─STConvBlock: 2-1                  [64, 64, 8, 325]          --
│    │    └─TemporalConvLayer: 3-1       [64, 64, 10, 325]         640
│    │    └─GraphConvLayer: 3-2          [64, 16, 10, 325]         1,824
│    │    └─ReLU: 3-3                    [64, 16, 10, 325]         --
│    │    └─TemporalConvLayer: 3-4       [64, 64, 8, 325]          7,360
│    │    └─LayerNorm: 3-5               [64, 8, 325, 64]          41,600
│    │    └─Dropout: 3-6                 [64, 64, 8, 325]          --
│    └─STConvBlock: 2-2                  [64, 64, 4, 325]          --
│    │    └─TemporalConvLayer: 3-7       [64, 64, 6, 325]          28,864
│    │    └─GraphConvLayer: 3-8          [64, 16, 6, 325]          1,824
│    │    └─ReLU: 3-9                    [64, 16, 6, 325]          --
│    │    └─TemporalConvLayer: 3-10      [64, 64, 4, 325]          7,360
│    │    └─LayerNorm: 3-11              [64, 4, 325, 64]          41,600
│    │    └─Dropout: 3-12                [64, 64, 4, 325]          --
├─OutputBlock: 1-2                       [64, 12, 1, 325]          --
│    └─TemporalConvLayer: 2-3            [64, 128, 1, 325]         --
│    │    └─Align: 3-13                  [64, 128, 4, 325]         8,320
│    │    └─CausalConv2d: 3-14           [64, 256, 1, 325]         65,792
│    │    └─Sigmoid: 3-15                [64, 128, 1, 325]         --
│    └─LayerNorm: 2-4                    [64, 1, 325, 128]         83,200
│    └─Linear: 2-5                       [64, 1, 325, 128]         16,512
│    └─ReLU: 2-6                         [64, 1, 325, 128]         --
│    └─Linear: 2-7                       [64, 1, 325, 12]          1,548
==========================================================================================
Total params: 306,444
Trainable params: 306,444
Non-trainable params: 0
Total mult-adds (G): 7.00
==========================================================================================
Input size (MB): 1.00
Forward/backward pass size (MB): 896.56
Params size (MB): 1.17
Estimated Total Size (MB): 898.73
==========================================================================================

Loss: MaskedMAELoss

2023-09-23 22:08:24.798923 Epoch 1  	Train Loss = 2.18240 Val Loss = 2.11815
2023-09-23 22:09:37.472326 Epoch 2  	Train Loss = 1.89070 Val Loss = 1.97805
2023-09-23 22:10:33.496054 Epoch 3  	Train Loss = 1.80664 Val Loss = 1.90538
2023-09-23 22:11:46.051432 Epoch 4  	Train Loss = 1.75854 Val Loss = 1.91460
2023-09-23 22:12:57.854097 Epoch 5  	Train Loss = 1.72264 Val Loss = 1.87005
2023-09-23 22:14:10.726047 Epoch 6  	Train Loss = 1.70293 Val Loss = 1.85403
2023-09-23 22:15:23.170036 Epoch 7  	Train Loss = 1.68266 Val Loss = 1.79519
2023-09-23 22:16:35.935264 Epoch 8  	Train Loss = 1.66727 Val Loss = 1.81536
2023-09-23 22:17:49.086398 Epoch 9  	Train Loss = 1.65287 Val Loss = 1.80120
2023-09-23 22:19:01.268920 Epoch 10  	Train Loss = 1.64776 Val Loss = 1.85836
2023-09-23 22:20:14.238313 Epoch 11  	Train Loss = 1.63761 Val Loss = 1.77356
2023-09-23 22:21:09.809041 Epoch 12  	Train Loss = 1.62706 Val Loss = 1.74371
2023-09-23 22:22:21.652029 Epoch 13  	Train Loss = 1.62046 Val Loss = 1.74385
2023-09-23 22:23:32.669467 Epoch 14  	Train Loss = 1.61255 Val Loss = 1.77834
2023-09-23 22:24:45.405223 Epoch 15  	Train Loss = 1.60937 Val Loss = 1.76670
2023-09-23 22:25:58.005420 Epoch 16  	Train Loss = 1.60125 Val Loss = 1.74979
2023-09-23 22:27:11.015188 Epoch 17  	Train Loss = 1.60010 Val Loss = 1.72330
2023-09-23 22:28:23.500075 Epoch 18  	Train Loss = 1.59250 Val Loss = 1.74873
2023-09-23 22:29:34.861731 Epoch 19  	Train Loss = 1.58720 Val Loss = 1.74783
2023-09-23 22:30:47.073880 Epoch 20  	Train Loss = 1.58465 Val Loss = 1.77084
2023-09-23 22:31:59.695675 Epoch 21  	Train Loss = 1.57679 Val Loss = 1.72231
2023-09-23 22:33:12.110686 Epoch 22  	Train Loss = 1.57489 Val Loss = 1.73432
2023-09-23 22:34:24.804235 Epoch 23  	Train Loss = 1.57378 Val Loss = 1.69709
2023-09-23 22:35:37.296617 Epoch 24  	Train Loss = 1.56682 Val Loss = 1.75948
2023-09-23 22:36:49.577417 Epoch 25  	Train Loss = 1.56639 Val Loss = 1.73415
2023-09-23 22:38:02.671974 Epoch 26  	Train Loss = 1.56297 Val Loss = 1.80850
2023-09-23 22:39:15.347252 Epoch 27  	Train Loss = 1.56167 Val Loss = 1.70762
2023-09-23 22:40:10.355963 Epoch 28  	Train Loss = 1.55603 Val Loss = 1.75907
2023-09-23 22:41:21.713078 Epoch 29  	Train Loss = 1.55548 Val Loss = 1.70969
2023-09-23 22:42:33.784331 Epoch 30  	Train Loss = 1.55470 Val Loss = 1.76700
2023-09-23 22:43:45.367884 Epoch 31  	Train Loss = 1.52309 Val Loss = 1.68035
2023-09-23 22:44:40.249661 Epoch 32  	Train Loss = 1.51944 Val Loss = 1.67925
2023-09-23 22:45:52.102692 Epoch 33  	Train Loss = 1.51840 Val Loss = 1.67342
2023-09-23 22:47:03.723772 Epoch 34  	Train Loss = 1.51759 Val Loss = 1.69929
2023-09-23 22:48:17.077413 Epoch 35  	Train Loss = 1.51656 Val Loss = 1.66593
2023-09-23 22:49:28.363015 Epoch 36  	Train Loss = 1.51569 Val Loss = 1.67319
2023-09-23 22:50:24.358980 Epoch 37  	Train Loss = 1.51550 Val Loss = 1.67644
2023-09-23 22:51:38.833238 Epoch 38  	Train Loss = 1.51404 Val Loss = 1.68269
2023-09-23 22:52:52.948542 Epoch 39  	Train Loss = 1.51341 Val Loss = 1.67937
2023-09-23 22:54:07.782397 Epoch 40  	Train Loss = 1.51282 Val Loss = 1.67323
2023-09-23 22:55:22.669009 Epoch 41  	Train Loss = 1.51267 Val Loss = 1.68217
2023-09-23 22:56:36.892597 Epoch 42  	Train Loss = 1.51185 Val Loss = 1.69059
2023-09-23 22:57:32.909918 Epoch 43  	Train Loss = 1.51177 Val Loss = 1.67930
2023-09-23 22:58:47.287302 Epoch 44  	Train Loss = 1.51174 Val Loss = 1.68733
2023-09-23 23:00:01.509126 Epoch 45  	Train Loss = 1.51079 Val Loss = 1.66281
2023-09-23 23:01:15.401130 Epoch 46  	Train Loss = 1.50985 Val Loss = 1.68760
2023-09-23 23:02:29.608830 Epoch 47  	Train Loss = 1.50974 Val Loss = 1.67334
2023-09-23 23:03:43.976024 Epoch 48  	Train Loss = 1.50935 Val Loss = 1.67396
2023-09-23 23:04:57.497156 Epoch 49  	Train Loss = 1.50859 Val Loss = 1.66934
2023-09-23 23:06:10.643596 Epoch 50  	Train Loss = 1.50823 Val Loss = 1.68488
2023-09-23 23:07:25.061703 Epoch 51  	Train Loss = 1.50457 Val Loss = 1.67151
2023-09-23 23:08:38.676964 Epoch 52  	Train Loss = 1.50343 Val Loss = 1.67795
2023-09-23 23:09:52.159267 Epoch 53  	Train Loss = 1.50405 Val Loss = 1.67731
2023-09-23 23:11:05.850891 Epoch 54  	Train Loss = 1.50373 Val Loss = 1.67379
2023-09-23 23:12:20.267348 Epoch 55  	Train Loss = 1.50336 Val Loss = 1.67355
2023-09-23 23:13:34.511191 Epoch 56  	Train Loss = 1.50308 Val Loss = 1.67486
2023-09-23 23:14:47.986223 Epoch 57  	Train Loss = 1.50340 Val Loss = 1.67282
2023-09-23 23:16:02.789165 Epoch 58  	Train Loss = 1.50310 Val Loss = 1.66981
2023-09-23 23:17:19.284506 Epoch 59  	Train Loss = 1.50297 Val Loss = 1.67433
2023-09-23 23:18:33.487346 Epoch 60  	Train Loss = 1.50313 Val Loss = 1.67007
2023-09-23 23:19:49.862857 Epoch 61  	Train Loss = 1.50283 Val Loss = 1.67280
2023-09-23 23:21:04.256207 Epoch 62  	Train Loss = 1.50278 Val Loss = 1.67168
2023-09-23 23:22:19.316448 Epoch 63  	Train Loss = 1.50270 Val Loss = 1.67583
2023-09-23 23:23:33.144877 Epoch 64  	Train Loss = 1.50267 Val Loss = 1.67482
2023-09-23 23:24:47.277823 Epoch 65  	Train Loss = 1.50253 Val Loss = 1.67526
Early stopping at epoch: 65
Best at epoch 45:
Train Loss = 1.51079
Train RMSE = 3.26472, MAE = 1.47782, MAPE = 3.15060
Val Loss = 1.66281
Val RMSE = 3.78015, MAE = 1.66471, MAPE = 3.76285
--------- Test ---------
All Steps RMSE = 3.70352, MAE = 1.63855, MAPE = 3.65562
Step 1 RMSE = 1.70805, MAE = 0.93722, MAPE = 1.90601
Step 2 RMSE = 2.35436, MAE = 1.18506, MAPE = 2.44633
Step 3 RMSE = 2.86854, MAE = 1.36889, MAPE = 2.89328
Step 4 RMSE = 3.26394, MAE = 1.50743, MAPE = 3.26035
Step 5 RMSE = 3.56532, MAE = 1.61314, MAPE = 3.55125
Step 6 RMSE = 3.79587, MAE = 1.69735, MAPE = 3.78762
Step 7 RMSE = 3.97621, MAE = 1.76723, MAPE = 3.98871
Step 8 RMSE = 4.12113, MAE = 1.82526, MAPE = 4.15697
Step 9 RMSE = 4.24249, MAE = 1.87491, MAPE = 4.29905
Step 10 RMSE = 4.34878, MAE = 1.91916, MAPE = 4.41858
Step 11 RMSE = 4.44698, MAE = 1.96117, MAPE = 4.52508
Step 12 RMSE = 4.54427, MAE = 2.00580, MAPE = 4.63430
Inference time: 8.91 s
