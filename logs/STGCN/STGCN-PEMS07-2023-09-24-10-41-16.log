    PEMS07
Trainset:	x-(16921, 12, 883, 1)	y-(16921, 12, 883, 1)
Valset:  	x-(5640, 12, 883, 1)  	y-(5640, 12, 883, 1)
Testset:	x-(5640, 12, 883, 1)	y-(5640, 12, 883, 1)

--------- STGCN ---------
{
    "num_nodes": 883,
    "in_steps": 12,
    "out_steps": 12,
    "lr": 0.001,
    "weight_decay": 0.0001,
    "milestones": [
        30,
        50
    ],
    "clip_grad": 5,
    "batch_size": 64,
    "max_epochs": 200,
    "early_stop": 20,
    "model_args": {
        "n_vertex": 883,
        "adj_path": "../data/PEMS07/adj_PEMS07.pkl",
        "Kt": 3,
        "Ks": 3,
        "blocks": [
            [
                1
            ],
            [
                64,
                16,
                64
            ],
            [
                64,
                16,
                64
            ],
            [
                128,
                128
            ],
            [
                12
            ]
        ],
        "T": 12,
        "act_func": "glu",
        "graph_conv_type": "cheb_graph_conv",
        "bias": true,
        "droprate": 0.5
    }
}
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
STGCN                                    [64, 12, 883, 1]          --
├─Sequential: 1-1                        [64, 64, 4, 883]          --
│    └─STConvBlock: 2-1                  [64, 64, 8, 883]          --
│    │    └─TemporalConvLayer: 3-1       [64, 64, 10, 883]         640
│    │    └─GraphConvLayer: 3-2          [64, 16, 10, 883]         1,824
│    │    └─ReLU: 3-3                    [64, 16, 10, 883]         --
│    │    └─TemporalConvLayer: 3-4       [64, 64, 8, 883]          7,360
│    │    └─LayerNorm: 3-5               [64, 8, 883, 64]          113,024
│    │    └─Dropout: 3-6                 [64, 64, 8, 883]          --
│    └─STConvBlock: 2-2                  [64, 64, 4, 883]          --
│    │    └─TemporalConvLayer: 3-7       [64, 64, 6, 883]          28,864
│    │    └─GraphConvLayer: 3-8          [64, 16, 6, 883]          1,824
│    │    └─ReLU: 3-9                    [64, 16, 6, 883]          --
│    │    └─TemporalConvLayer: 3-10      [64, 64, 4, 883]          7,360
│    │    └─LayerNorm: 3-11              [64, 4, 883, 64]          113,024
│    │    └─Dropout: 3-12                [64, 64, 4, 883]          --
├─OutputBlock: 1-2                       [64, 12, 1, 883]          --
│    └─TemporalConvLayer: 2-3            [64, 128, 1, 883]         --
│    │    └─Align: 3-13                  [64, 128, 4, 883]         8,320
│    │    └─CausalConv2d: 3-14           [64, 256, 1, 883]         65,792
│    │    └─Sigmoid: 3-15                [64, 128, 1, 883]         --
│    └─LayerNorm: 2-4                    [64, 1, 883, 128]         226,048
│    └─Linear: 2-5                       [64, 1, 883, 128]         16,512
│    └─ReLU: 2-6                         [64, 1, 883, 128]         --
│    └─Linear: 2-7                       [64, 1, 883, 12]          1,548
==========================================================================================
Total params: 592,140
Trainable params: 592,140
Non-trainable params: 0
Total mult-adds (G): 19.03
==========================================================================================
Input size (MB): 2.71
Forward/backward pass size (MB): 2435.89
Params size (MB): 2.31
Estimated Total Size (MB): 2440.92
==========================================================================================

Loss: HuberLoss

2023-09-24 10:43:49.503786 Epoch 1  	Train Loss = 40.08544 Val Loss = 29.63991
2023-09-24 10:46:15.526323 Epoch 2  	Train Loss = 30.95412 Val Loss = 29.48898
2023-09-24 10:48:36.845651 Epoch 3  	Train Loss = 29.51713 Val Loss = 29.53976
2023-09-24 10:51:01.189592 Epoch 4  	Train Loss = 28.34701 Val Loss = 26.48541
2023-09-24 10:53:22.102388 Epoch 5  	Train Loss = 27.72509 Val Loss = 27.70688
2023-09-24 10:55:45.548075 Epoch 6  	Train Loss = 27.47284 Val Loss = 25.55561
2023-09-24 10:58:07.711211 Epoch 7  	Train Loss = 26.70656 Val Loss = 28.31131
2023-09-24 11:00:29.734177 Epoch 8  	Train Loss = 26.46105 Val Loss = 25.40942
2023-09-24 11:02:52.178873 Epoch 9  	Train Loss = 25.52214 Val Loss = 25.83733
2023-09-24 11:05:11.728589 Epoch 10  	Train Loss = 25.09775 Val Loss = 26.41337
2023-09-24 11:07:29.909825 Epoch 11  	Train Loss = 24.88710 Val Loss = 25.70276
2023-09-24 11:09:34.928894 Epoch 12  	Train Loss = 24.33974 Val Loss = 26.18303
2023-09-24 11:11:39.824818 Epoch 13  	Train Loss = 24.19916 Val Loss = 24.56234
2023-09-24 11:13:44.368113 Epoch 14  	Train Loss = 23.80576 Val Loss = 23.68739
2023-09-24 11:15:49.380763 Epoch 15  	Train Loss = 23.66043 Val Loss = 24.57165
2023-09-24 11:17:54.253385 Epoch 16  	Train Loss = 23.54892 Val Loss = 24.99929
2023-09-24 11:19:59.564722 Epoch 17  	Train Loss = 23.42923 Val Loss = 24.01648
2023-09-24 11:22:03.801219 Epoch 18  	Train Loss = 23.46147 Val Loss = 24.04437
2023-09-24 11:24:09.762829 Epoch 19  	Train Loss = 23.11605 Val Loss = 24.02567
2023-09-24 11:26:15.394817 Epoch 20  	Train Loss = 22.96967 Val Loss = 23.58645
2023-09-24 11:28:20.029484 Epoch 21  	Train Loss = 22.69398 Val Loss = 24.43098
2023-09-24 11:30:24.735487 Epoch 22  	Train Loss = 22.75268 Val Loss = 23.04433
2023-09-24 11:32:28.757227 Epoch 23  	Train Loss = 22.49751 Val Loss = 23.73603
2023-09-24 11:34:33.086275 Epoch 24  	Train Loss = 22.45033 Val Loss = 23.00678
2023-09-24 11:36:38.356766 Epoch 25  	Train Loss = 22.46405 Val Loss = 23.78755
2023-09-24 11:38:43.434337 Epoch 26  	Train Loss = 22.25758 Val Loss = 23.03730
2023-09-24 11:40:50.106326 Epoch 27  	Train Loss = 22.18552 Val Loss = 22.40732
2023-09-24 11:42:57.104310 Epoch 28  	Train Loss = 22.25626 Val Loss = 23.04174
2023-09-24 11:45:02.157767 Epoch 29  	Train Loss = 22.04932 Val Loss = 22.80330
2023-09-24 11:47:08.465199 Epoch 30  	Train Loss = 21.99170 Val Loss = 22.61131
2023-09-24 11:49:14.586401 Epoch 31  	Train Loss = 21.34612 Val Loss = 22.23973
2023-09-24 11:51:20.173644 Epoch 32  	Train Loss = 21.26582 Val Loss = 22.36986
2023-09-24 11:53:27.411559 Epoch 33  	Train Loss = 21.22041 Val Loss = 22.37347
2023-09-24 11:55:32.525496 Epoch 34  	Train Loss = 21.19091 Val Loss = 22.33860
2023-09-24 11:57:38.786482 Epoch 35  	Train Loss = 21.16588 Val Loss = 22.32633
2023-09-24 11:59:47.617364 Epoch 36  	Train Loss = 21.14492 Val Loss = 22.19187
2023-09-24 12:01:57.003402 Epoch 37  	Train Loss = 21.13104 Val Loss = 22.38073
2023-09-24 12:04:06.686024 Epoch 38  	Train Loss = 21.11000 Val Loss = 22.23108
2023-09-24 12:06:12.472169 Epoch 39  	Train Loss = 21.09087 Val Loss = 22.33270
2023-09-24 12:08:16.816432 Epoch 40  	Train Loss = 21.07955 Val Loss = 22.23509
2023-09-24 12:10:21.855120 Epoch 41  	Train Loss = 21.06118 Val Loss = 22.38002
2023-09-24 12:12:28.506407 Epoch 42  	Train Loss = 21.05420 Val Loss = 22.20309
2023-09-24 12:14:35.377829 Epoch 43  	Train Loss = 21.03445 Val Loss = 22.40896
2023-09-24 12:16:41.571381 Epoch 44  	Train Loss = 21.01923 Val Loss = 21.92809
2023-09-24 12:18:48.273810 Epoch 45  	Train Loss = 21.01970 Val Loss = 22.16325
2023-09-24 12:20:57.495784 Epoch 46  	Train Loss = 20.99540 Val Loss = 22.04596
2023-09-24 12:23:06.299574 Epoch 47  	Train Loss = 20.98051 Val Loss = 22.03853
2023-09-24 12:25:15.909854 Epoch 48  	Train Loss = 20.97432 Val Loss = 22.05087
2023-09-24 12:27:24.221472 Epoch 49  	Train Loss = 20.95963 Val Loss = 21.93561
2023-09-24 12:29:31.889473 Epoch 50  	Train Loss = 20.94424 Val Loss = 22.04002
2023-09-24 12:31:40.088554 Epoch 51  	Train Loss = 20.88840 Val Loss = 22.06476
2023-09-24 12:33:48.675292 Epoch 52  	Train Loss = 20.88181 Val Loss = 22.00489
2023-09-24 12:35:56.337353 Epoch 53  	Train Loss = 20.87327 Val Loss = 22.08875
2023-09-24 12:38:04.289471 Epoch 54  	Train Loss = 20.87110 Val Loss = 22.03314
2023-09-24 12:40:11.195258 Epoch 55  	Train Loss = 20.87206 Val Loss = 22.04550
2023-09-24 12:42:17.441913 Epoch 56  	Train Loss = 20.86968 Val Loss = 22.02612
2023-09-24 12:44:23.564341 Epoch 57  	Train Loss = 20.86666 Val Loss = 22.02298
2023-09-24 12:46:31.644935 Epoch 58  	Train Loss = 20.86772 Val Loss = 22.04983
2023-09-24 12:48:39.168010 Epoch 59  	Train Loss = 20.87389 Val Loss = 21.98193
2023-09-24 12:50:47.545697 Epoch 60  	Train Loss = 20.86476 Val Loss = 21.95608
2023-09-24 12:52:55.979710 Epoch 61  	Train Loss = 20.86079 Val Loss = 21.99620
2023-09-24 12:55:01.841900 Epoch 62  	Train Loss = 20.86131 Val Loss = 21.97545
2023-09-24 12:57:07.363318 Epoch 63  	Train Loss = 20.85710 Val Loss = 21.95689
2023-09-24 12:59:12.225330 Epoch 64  	Train Loss = 20.85160 Val Loss = 22.04728
Early stopping at epoch: 64
Best at epoch 44:
Train Loss = 21.01923
Train RMSE = 34.11955, MAE = 21.74051, MAPE = 10.59309
Val Loss = 21.92809
Val RMSE = 35.61394, MAE = 22.54836, MAPE = 10.66427
--------- Test ---------
All Steps RMSE = 36.14347, MAE = 23.07937, MAPE = 10.52424
Step 1 RMSE = 29.91393, MAE = 19.55873, MAPE = 9.28931
Step 2 RMSE = 31.87086, MAE = 20.63124, MAPE = 9.69433
Step 3 RMSE = 33.23747, MAE = 21.41949, MAPE = 9.95131
Step 4 RMSE = 34.27473, MAE = 21.99263, MAPE = 10.11752
Step 5 RMSE = 35.17237, MAE = 22.49719, MAPE = 10.29978
Step 6 RMSE = 36.02888, MAE = 23.03135, MAPE = 10.52673
Step 7 RMSE = 36.83583, MAE = 23.53484, MAPE = 10.69367
Step 8 RMSE = 37.56072, MAE = 23.97553, MAPE = 10.84582
Step 9 RMSE = 38.23597, MAE = 24.37935, MAPE = 10.98785
Step 10 RMSE = 38.86456, MAE = 24.76702, MAPE = 11.10475
Step 11 RMSE = 39.59870, MAE = 25.25079, MAPE = 11.28224
Step 12 RMSE = 40.52908, MAE = 25.91150, MAPE = 11.49610
Inference time: 16.21 s
