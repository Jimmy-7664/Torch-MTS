PEMS07
Trainset:	x-(16921, 12, 883, 1)	y-(16921, 12, 883, 1)
Valset:  	x-(5640, 12, 883, 1)  	y-(5640, 12, 883, 1)
Testset:	x-(5640, 12, 883, 1)	y-(5640, 12, 883, 1)

--------- StemGNN ---------
{
    "num_nodes": 883,
    "in_steps": 12,
    "out_steps": 12,
    "lr": 0.001,
    "weight_decay": 0,
    "milestones": [
        10
    ],
    "clip_grad": 0,
    "batch_size": 64,
    "max_epochs": 200,
    "use_cl": false,
    "model_args": {
        "units": 883,
        "stack_cnt": 2,
        "time_step": 12,
        "horizon": 12,
        "multi_layer": 5,
        "dropout_rate": 0.5,
        "leaky_rate": 0.2
    }
}
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
StemGNN                                  [64, 12, 883, 1]          1,766
├─GRU: 1-1                               [883, 64, 883]            2,376,153
├─LeakyReLU: 1-2                         [64, 883, 883]            --
├─Dropout: 1-3                           [64, 883, 883]            --
├─ModuleList: 1-4                        --                        --
│    └─StockBlockLayer: 2-1              [64, 883, 12]             14,400
│    │    └─ModuleList: 3-1              --                        509,760
│    │    └─Linear: 3-2                  [64, 1, 883, 60]          3,660
│    │    └─Linear: 3-3                  [64, 883, 12]             732
│    │    └─Linear: 3-4                  [64, 1, 1, 883, 12]       156
│    │    └─Linear: 3-5                  [64, 1, 883, 12]          732
│    └─StockBlockLayer: 2-2              [64, 883, 12]             14,556
│    │    └─ModuleList: 3-6              --                        509,760
│    │    └─Linear: 3-7                  [64, 1, 883, 60]          3,660
│    │    └─Linear: 3-8                  [64, 883, 12]             732
├─Sequential: 1-5                        [64, 883, 12]             --
│    └─Linear: 2-3                       [64, 883, 12]             156
│    └─LeakyReLU: 2-4                    [64, 883, 12]             --
│    └─Linear: 2-5                       [64, 883, 12]             156
==========================================================================================
Total params: 3,436,379
Trainable params: 3,436,379
Non-trainable params: 0
Total mult-adds (G): 134.35
==========================================================================================
Input size (MB): 2.71
Forward/backward pass size (MB): 3090.08
Params size (MB): 13.62
Estimated Total Size (MB): 3106.41
==========================================================================================

Loss: HuberLoss

2023-06-02 17:15:53.928670 Epoch 1  	Train Loss = 56.19835 Val Loss = 80.70403
2023-06-02 17:16:40.872186 Epoch 2  	Train Loss = 31.57731 Val Loss = 60.45713
2023-06-02 17:17:28.064497 Epoch 3  	Train Loss = 29.75579 Val Loss = 52.77524
2023-06-02 17:18:15.309373 Epoch 4  	Train Loss = 27.60178 Val Loss = 29.22002
2023-06-02 17:19:02.471951 Epoch 5  	Train Loss = 27.01375 Val Loss = 29.49258
2023-06-02 17:19:49.578937 Epoch 6  	Train Loss = 26.42502 Val Loss = 27.83662
2023-06-02 17:20:36.713259 Epoch 7  	Train Loss = 25.93612 Val Loss = 27.49216
2023-06-02 17:21:23.845970 Epoch 8  	Train Loss = 25.65662 Val Loss = 27.35946
2023-06-02 17:22:11.152459 Epoch 9  	Train Loss = 25.35781 Val Loss = 28.56109
2023-06-02 17:22:58.308882 Epoch 10  	Train Loss = 25.16450 Val Loss = 27.93544
2023-06-02 17:23:45.474832 Epoch 11  	Train Loss = 24.27463 Val Loss = 27.49148
2023-06-02 17:24:32.617899 Epoch 12  	Train Loss = 24.15879 Val Loss = 27.19267
2023-06-02 17:25:19.752165 Epoch 13  	Train Loss = 24.09502 Val Loss = 27.39868
2023-06-02 17:26:07.074789 Epoch 14  	Train Loss = 24.01697 Val Loss = 27.18838
2023-06-02 17:26:54.318391 Epoch 15  	Train Loss = 23.95536 Val Loss = 27.55608
2023-06-02 17:27:41.514529 Epoch 16  	Train Loss = 23.90285 Val Loss = 27.23088
2023-06-02 17:28:28.631126 Epoch 17  	Train Loss = 23.85334 Val Loss = 26.86465
2023-06-02 17:29:15.733026 Epoch 18  	Train Loss = 23.75733 Val Loss = 27.00863
2023-06-02 17:30:02.779282 Epoch 19  	Train Loss = 23.70774 Val Loss = 26.87745
2023-06-02 17:30:49.820710 Epoch 20  	Train Loss = 23.68783 Val Loss = 26.59610
2023-06-02 17:31:36.936945 Epoch 21  	Train Loss = 23.60179 Val Loss = 26.71548
2023-06-02 17:32:24.010737 Epoch 22  	Train Loss = 23.57378 Val Loss = 26.38351
2023-06-02 17:33:11.471702 Epoch 23  	Train Loss = 23.51774 Val Loss = 26.23034
2023-06-02 17:33:58.614225 Epoch 24  	Train Loss = 23.44319 Val Loss = 26.77108
2023-06-02 17:34:45.788890 Epoch 25  	Train Loss = 23.39199 Val Loss = 26.16860
2023-06-02 17:35:32.915989 Epoch 26  	Train Loss = 23.33360 Val Loss = 26.37404
2023-06-02 17:36:20.278811 Epoch 27  	Train Loss = 23.30764 Val Loss = 26.00178
2023-06-02 17:37:07.498269 Epoch 28  	Train Loss = 23.24584 Val Loss = 26.55531
2023-06-02 17:37:54.674306 Epoch 29  	Train Loss = 23.21086 Val Loss = 26.11943
2023-06-02 17:38:41.984946 Epoch 30  	Train Loss = 23.18208 Val Loss = 25.62011
2023-06-02 17:39:29.010420 Epoch 31  	Train Loss = 23.13392 Val Loss = 26.17279
2023-06-02 17:40:16.011700 Epoch 32  	Train Loss = 23.14418 Val Loss = 25.59774
2023-06-02 17:41:03.062148 Epoch 33  	Train Loss = 23.04567 Val Loss = 25.73174
2023-06-02 17:41:50.183806 Epoch 34  	Train Loss = 23.03519 Val Loss = 25.65732
2023-06-02 17:42:37.171949 Epoch 35  	Train Loss = 22.99369 Val Loss = 25.52615
2023-06-02 17:43:24.139644 Epoch 36  	Train Loss = 22.96495 Val Loss = 25.76995
2023-06-02 17:44:11.159177 Epoch 37  	Train Loss = 22.91261 Val Loss = 25.53888
2023-06-02 17:44:58.163885 Epoch 38  	Train Loss = 22.90736 Val Loss = 25.21364
2023-06-02 17:45:45.177924 Epoch 39  	Train Loss = 22.87238 Val Loss = 25.12995
2023-06-02 17:46:32.175131 Epoch 40  	Train Loss = 22.83757 Val Loss = 25.06009
2023-06-02 17:47:19.184053 Epoch 41  	Train Loss = 22.83367 Val Loss = 25.39264
2023-06-02 17:48:06.583324 Epoch 42  	Train Loss = 22.79095 Val Loss = 25.03902
2023-06-02 17:48:53.730172 Epoch 43  	Train Loss = 22.76878 Val Loss = 25.34685
2023-06-02 17:49:40.783270 Epoch 44  	Train Loss = 22.74739 Val Loss = 25.10365
2023-06-02 17:50:27.881664 Epoch 45  	Train Loss = 22.70230 Val Loss = 25.12545
2023-06-02 17:51:15.195346 Epoch 46  	Train Loss = 22.67102 Val Loss = 25.18273
2023-06-02 17:52:02.311714 Epoch 47  	Train Loss = 22.63314 Val Loss = 25.46896
2023-06-02 17:52:49.400291 Epoch 48  	Train Loss = 22.63369 Val Loss = 24.89535
2023-06-02 17:53:36.566182 Epoch 49  	Train Loss = 22.59648 Val Loss = 24.73704
2023-06-02 17:54:23.710486 Epoch 50  	Train Loss = 22.58361 Val Loss = 24.94509
2023-06-02 17:55:10.732397 Epoch 51  	Train Loss = 22.56331 Val Loss = 24.89998
2023-06-02 17:55:57.903349 Epoch 52  	Train Loss = 22.52825 Val Loss = 24.18119
2023-06-02 17:56:45.100949 Epoch 53  	Train Loss = 22.52243 Val Loss = 24.90668
2023-06-02 17:57:32.212611 Epoch 54  	Train Loss = 22.48273 Val Loss = 24.67963
2023-06-02 17:58:19.321188 Epoch 55  	Train Loss = 22.47138 Val Loss = 24.93472
2023-06-02 17:59:06.343573 Epoch 56  	Train Loss = 22.43771 Val Loss = 24.71832
2023-06-02 17:59:53.633032 Epoch 57  	Train Loss = 22.42973 Val Loss = 24.72733
2023-06-02 18:00:40.750429 Epoch 58  	Train Loss = 22.41349 Val Loss = 24.64794
2023-06-02 18:01:27.806743 Epoch 59  	Train Loss = 22.39426 Val Loss = 24.16560
2023-06-02 18:02:14.851910 Epoch 60  	Train Loss = 22.35779 Val Loss = 24.12977
2023-06-02 18:03:01.890885 Epoch 61  	Train Loss = 22.37490 Val Loss = 25.05017
2023-06-02 18:03:49.029329 Epoch 62  	Train Loss = 22.32332 Val Loss = 24.88322
2023-06-02 18:04:36.232807 Epoch 63  	Train Loss = 22.32085 Val Loss = 24.64066
2023-06-02 18:05:23.348469 Epoch 64  	Train Loss = 22.30980 Val Loss = 24.33921
2023-06-02 18:06:10.528828 Epoch 65  	Train Loss = 22.29603 Val Loss = 24.62058
2023-06-02 18:06:57.632969 Epoch 66  	Train Loss = 22.26228 Val Loss = 23.99330
2023-06-02 18:07:44.728331 Epoch 67  	Train Loss = 22.25642 Val Loss = 24.48077
2023-06-02 18:08:31.840774 Epoch 68  	Train Loss = 22.22732 Val Loss = 24.50441
2023-06-02 18:09:18.881243 Epoch 69  	Train Loss = 22.21997 Val Loss = 24.07006
2023-06-02 18:10:05.972131 Epoch 70  	Train Loss = 22.22581 Val Loss = 25.07128
2023-06-02 18:10:53.022487 Epoch 71  	Train Loss = 22.22110 Val Loss = 24.27810
2023-06-02 18:11:40.167292 Epoch 72  	Train Loss = 22.15400 Val Loss = 24.99655
2023-06-02 18:12:27.414998 Epoch 73  	Train Loss = 22.17126 Val Loss = 24.45063
2023-06-02 18:13:14.436709 Epoch 74  	Train Loss = 22.12381 Val Loss = 24.18435
2023-06-02 18:14:01.459406 Epoch 75  	Train Loss = 22.14374 Val Loss = 24.37032
2023-06-02 18:14:48.494371 Epoch 76  	Train Loss = 22.11764 Val Loss = 24.09971
Early stopping at epoch: 76
Best at epoch 66:
Train Loss = 22.26228
Train RMSE = 36.00636, MAE = 22.70298, MAPE = 10.07955
Val Loss = 23.99330
Val RMSE = 37.97655, MAE = 24.57630, MAPE = 12.09864
--------- Test ---------
All Steps RMSE = 39.46363, MAE = 25.86745, MAPE = 12.52144
Step 1 RMSE = 31.69852, MAE = 20.74174, MAPE = 10.55728
Step 2 RMSE = 33.79752, MAE = 22.05316, MAPE = 10.93222
Step 3 RMSE = 35.42859, MAE = 23.16172, MAPE = 11.35255
Step 4 RMSE = 36.72047, MAE = 24.09962, MAPE = 11.71628
Step 5 RMSE = 37.85976, MAE = 24.91658, MAPE = 12.12373
Step 6 RMSE = 39.05671, MAE = 25.70709, MAPE = 12.37967
Step 7 RMSE = 40.19296, MAE = 26.51199, MAPE = 12.82358
Step 8 RMSE = 41.16636, MAE = 27.21251, MAPE = 13.06127
Step 9 RMSE = 42.27480, MAE = 27.88450, MAPE = 13.31945
Step 10 RMSE = 43.16025, MAE = 28.58232, MAPE = 13.64882
Step 11 RMSE = 44.17605, MAE = 29.31806, MAPE = 14.04197
Step 12 RMSE = 45.46697, MAE = 30.21611, MAPE = 14.29846
Inference time: 5.80 s
