METRLA
Trainset:	x-(23974, 12, 207, 3)	y-(23974, 12, 207, 1)
Valset:  	x-(3425, 12, 207, 3)  	y-(3425, 12, 207, 1)
Testset:	x-(6850, 12, 207, 3)	y-(6850, 12, 207, 1)

--------- STMetaAttention ---------
{
    "num_nodes": 207,
    "in_steps": 12,
    "out_steps": 12,
    "time_of_day": true,
    "day_of_week": true,
    "lr": 0.001,
    "weight_decay": 0,
    "milestones": [
        10,
        20
    ],
    "clip_grad": false,
    "batch_size": 64,
    "max_epochs": 200,
    "use_cl": false,
    "pass_device": true,
    "model_args": {
        "num_nodes": 207,
        "node_emb_file": "../data/METRLA/spatial_embeddings.npz",
        "in_steps": 12,
        "out_steps": 12,
        "input_dim": 1,
        "output_dim": 1,
        "model_dim": 32,
        "tod_embedding_dim": 24,
        "dow_embedding_dim": 7,
        "node_embedding_dim": 64,
        "learner_hidden_dim": 96,
        "z_dim": 32,
        "feed_forward_dim": 64,
        "num_heads": 4,
        "num_layers": 1,
        "dropout": 0,
        "with_spatial": true,
        "device": "cuda:0"
    }
}
===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
STMetaAttention                               [64, 12, 207, 1]          13,248
├─Linear: 1-1                                 [64, 12, 207, 32]         64
├─Sequential: 1-2                             [64, 207, 32]             --
│    └─Linear: 2-1                            [64, 207, 32]             416
│    └─Tanh: 2-2                              [64, 207, 32]             --
│    └─Linear: 2-3                            [64, 207, 32]             1,056
│    └─Tanh: 2-4                              [64, 207, 32]             --
│    └─Linear: 2-5                            [64, 207, 32]             1,056
├─Sequential: 1-3                             [64, 207, 32]             --
│    └─Linear: 2-6                            [64, 207, 32]             416
│    └─Tanh: 2-7                              [64, 207, 32]             --
│    └─Linear: 2-8                            [64, 207, 32]             1,056
│    └─Tanh: 2-9                              [64, 207, 32]             --
│    └─Linear: 2-10                           [64, 207, 32]             1,056
├─ModuleList: 1-4                             --                        --
│    └─STMetaSelfAttentionLayer: 2-11         [64, 12, 207, 32]         --
│    │    └─Sequential: 3-1                   [64, 207, 3072]           310,272
│    │    └─Sequential: 3-2                   [64, 207, 96]             21,600
│    │    └─STMetaAttentionLayer: 3-3         [64, 207, 12, 32]         1,056
│    │    └─Dropout: 3-4                      [64, 207, 12, 32]         --
│    │    └─LayerNorm: 3-5                    [64, 207, 12, 32]         64
│    │    └─Sequential: 3-6                   [64, 207, 12, 32]         4,192
│    │    └─Dropout: 3-7                      [64, 207, 12, 32]         --
│    │    └─LayerNorm: 3-8                    [64, 207, 12, 32]         64
├─ModuleList: 1-5                             --                        --
│    └─STMetaSelfAttentionLayer: 2-12         [64, 12, 207, 32]         --
│    │    └─Sequential: 3-9                   [64, 207, 3072]           310,272
│    │    └─Sequential: 3-10                  [64, 207, 96]             21,600
│    │    └─STMetaAttentionLayer: 3-11        [64, 207, 12, 32]         1,056
│    │    └─Dropout: 3-12                     [64, 207, 12, 32]         --
│    │    └─LayerNorm: 3-13                   [64, 207, 12, 32]         64
│    │    └─Sequential: 3-14                  [64, 207, 12, 32]         4,192
│    │    └─Dropout: 3-15                     [64, 207, 12, 32]         --
│    │    └─LayerNorm: 3-16                   [64, 207, 12, 32]         64
├─Linear: 1-6                                 [64, 32, 207, 12]         156
├─Linear: 1-7                                 [64, 12, 207, 1]          33
===============================================================================================
Total params: 693,053
Trainable params: 693,053
Non-trainable params: 0
Total mult-adds (M): 43.51
===============================================================================================
Input size (MB): 1.91
Forward/backward pass size (MB): 1303.60
Params size (MB): 2.72
Estimated Total Size (MB): 1308.23
===============================================================================================

Loss: MaskedMAELoss

2023-04-17 10:30:48.600671 Epoch 1  	Train Loss = 5.01625 Val Loss = 3.38015
2023-04-17 10:31:17.850998 Epoch 2  	Train Loss = 3.51797 Val Loss = 3.36022
2023-04-17 10:31:47.343488 Epoch 3  	Train Loss = 3.41364 Val Loss = 3.20668
2023-04-17 10:32:17.147806 Epoch 4  	Train Loss = 3.32216 Val Loss = 3.14439
2023-04-17 10:32:47.643126 Epoch 5  	Train Loss = 3.25243 Val Loss = 3.13430
2023-04-17 10:33:18.445647 Epoch 6  	Train Loss = 3.19216 Val Loss = 3.07475
2023-04-17 10:33:49.440873 Epoch 7  	Train Loss = 3.13001 Val Loss = 3.01426
2023-04-17 10:34:20.507985 Epoch 8  	Train Loss = 3.05366 Val Loss = 2.96628
2023-04-17 10:34:51.699099 Epoch 9  	Train Loss = 2.98182 Val Loss = 2.95386
2023-04-17 10:35:22.975649 Epoch 10  	Train Loss = 2.92962 Val Loss = 2.94987
2023-04-17 10:35:54.342522 Epoch 11  	Train Loss = 2.84861 Val Loss = 2.90338
2023-04-17 10:36:25.802793 Epoch 12  	Train Loss = 2.83035 Val Loss = 2.89455
2023-04-17 10:36:57.075464 Epoch 13  	Train Loss = 2.81971 Val Loss = 2.90376
2023-04-17 10:37:28.467407 Epoch 14  	Train Loss = 2.81162 Val Loss = 2.90650
2023-04-17 10:37:59.956771 Epoch 15  	Train Loss = 2.80218 Val Loss = 2.89635
2023-04-17 10:38:31.484004 Epoch 16  	Train Loss = 2.79482 Val Loss = 2.90408
2023-04-17 10:39:02.845979 Epoch 17  	Train Loss = 2.78692 Val Loss = 2.90205
2023-04-17 10:39:34.179107 Epoch 18  	Train Loss = 2.77885 Val Loss = 2.90896
2023-04-17 10:40:05.603231 Epoch 19  	Train Loss = 2.77160 Val Loss = 2.91141
2023-04-17 10:40:37.000589 Epoch 20  	Train Loss = 2.76338 Val Loss = 2.90289
2023-04-17 10:41:08.391105 Epoch 21  	Train Loss = 2.75189 Val Loss = 2.90095
2023-04-17 10:41:39.850182 Epoch 22  	Train Loss = 2.74926 Val Loss = 2.90308
Early stopping at epoch: 22
Best at epoch 12:
Train Loss = 2.83035
Train RMSE = 5.41366, MAE = 2.74815, MAPE = 7.24107
Val Loss = 2.89455
Val RMSE = 6.08511, MAE = 2.93881, MAPE = 8.29829
--------- Test ---------
All Steps RMSE = 6.43386, MAE = 3.18532, MAPE = 8.82014
Step 1 RMSE = 4.73058, MAE = 2.56411, MAPE = 6.55700
Step 2 RMSE = 5.25307, MAE = 2.74438, MAPE = 7.15017
Step 3 RMSE = 5.63361, MAE = 2.89350, MAPE = 7.68348
Step 4 RMSE = 5.88739, MAE = 2.99503, MAPE = 8.07546
Step 5 RMSE = 6.17204, MAE = 3.10082, MAPE = 8.48333
Step 6 RMSE = 6.47686, MAE = 3.20862, MAPE = 8.90622
Step 7 RMSE = 6.64170, MAE = 3.29629, MAPE = 9.26353
Step 8 RMSE = 6.84919, MAE = 3.36515, MAPE = 9.54349
Step 9 RMSE = 7.00497, MAE = 3.41767, MAPE = 9.71250
Step 10 RMSE = 7.15340, MAE = 3.48065, MAPE = 9.92295
Step 11 RMSE = 7.28516, MAE = 3.53599, MAPE = 10.14330
Step 12 RMSE = 7.48223, MAE = 3.62164, MAPE = 10.40045
Inference time: 2.73 s
